{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "| <h1> Hands-on Activity 6.2 </h1> | <h1> Training Neural Networks </h1> |\n",
        "|--- | --- |\n",
        "Name: Buan, Danilo Jr. G. <br>\n",
        "Course and Section: CPE019/CPE32S3 <br>\n",
        "Date Submitted: 04/02/24 <br>\n",
        "Instructor: Engr. Roman M. Richard\n",
        "Date Performed: 04/02/24\n"
      ],
      "metadata": {
        "id": "tTbHf7ZcN-7X"
      },
      "id": "tTbHf7ZcN-7X"
    },
    {
      "cell_type": "markdown",
      "id": "floppy-teens",
      "metadata": {
        "id": "floppy-teens"
      },
      "source": [
        "#### Objective(s):\n",
        "\n",
        "This activity aims to demonstrate how to train neural networks using keras"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "engaged-modem",
      "metadata": {
        "id": "engaged-modem"
      },
      "source": [
        "#### Intended Learning Outcomes (ILOs):\n",
        "* Demonstrate how to build and train neural networks\n",
        "* Demonstrate how to evaluate and plot the model using training and validation loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "structured-april",
      "metadata": {
        "id": "structured-april"
      },
      "source": [
        "#### Resources:\n",
        "* Jupyter Notebook\n",
        "\n",
        "CI Pima Diabetes Dataset\n",
        "\n",
        "* pima-indians-diabetes.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cutting-fountain",
      "metadata": {
        "id": "cutting-fountain"
      },
      "source": [
        "#### Procedures"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "entertaining-therapist",
      "metadata": {
        "id": "entertaining-therapist"
      },
      "source": [
        "Load the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "differential-native",
      "metadata": {
        "id": "differential-native"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "other-married",
      "metadata": {
        "id": "other-married"
      },
      "outputs": [],
      "source": [
        "## Import Keras objects for Deep Learning\n",
        "\n",
        "from keras.models  import Sequential\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam, SGD, RMSprop"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mexican-newsletter",
      "metadata": {
        "id": "mexican-newsletter"
      },
      "source": [
        "Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "studied-twelve",
      "metadata": {
        "id": "studied-twelve"
      },
      "outputs": [],
      "source": [
        "\n",
        "filepath = \"pima-indians-diabetes.csv\"\n",
        "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\",\n",
        "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
        "diabetes_df = pd.read_csv(filepath, names=names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "photographic-carnival",
      "metadata": {
        "id": "photographic-carnival"
      },
      "source": [
        "Check the top 5 samples of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "undefined-inventory",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "undefined-inventory",
        "outputId": "f8f1bf61-729d-4666-87c5-52ad4ed563a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(768, 9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
              "381               0                     105              68              22   \n",
              "757               0                     123              72               0   \n",
              "642               6                     147              80               0   \n",
              "63                2                     141              58              34   \n",
              "375              12                     140              82              43   \n",
              "\n",
              "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
              "381        0  20.0              0.236   22             0  \n",
              "757        0  36.3              0.258   52             1  \n",
              "642        0  29.5              0.178   50             1  \n",
              "63       128  25.4              0.699   24             0  \n",
              "375      325  39.2              0.528   58             1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-502cb45c-c3a6-4f8f-8e92-2633c6d38d62\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>times_pregnant</th>\n",
              "      <th>glucose_tolerance_test</th>\n",
              "      <th>blood_pressure</th>\n",
              "      <th>skin_thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>pedigree_function</th>\n",
              "      <th>age</th>\n",
              "      <th>has_diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>381</th>\n",
              "      <td>0</td>\n",
              "      <td>105</td>\n",
              "      <td>68</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.236</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>757</th>\n",
              "      <td>0</td>\n",
              "      <td>123</td>\n",
              "      <td>72</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>36.3</td>\n",
              "      <td>0.258</td>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>642</th>\n",
              "      <td>6</td>\n",
              "      <td>147</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29.5</td>\n",
              "      <td>0.178</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>2</td>\n",
              "      <td>141</td>\n",
              "      <td>58</td>\n",
              "      <td>34</td>\n",
              "      <td>128</td>\n",
              "      <td>25.4</td>\n",
              "      <td>0.699</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375</th>\n",
              "      <td>12</td>\n",
              "      <td>140</td>\n",
              "      <td>82</td>\n",
              "      <td>43</td>\n",
              "      <td>325</td>\n",
              "      <td>39.2</td>\n",
              "      <td>0.528</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-502cb45c-c3a6-4f8f-8e92-2633c6d38d62')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-502cb45c-c3a6-4f8f-8e92-2633c6d38d62 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-502cb45c-c3a6-4f8f-8e92-2633c6d38d62');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b8ccda0a-d745-48d2-b754-6c83054d492d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b8ccda0a-d745-48d2-b754-6c83054d492d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b8ccda0a-d745-48d2-b754-6c83054d492d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"diabetes_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"times_pregnant\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 0,\n        \"max\": 12,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          6,\n          12,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"glucose_tolerance_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17,\n        \"min\": 105,\n        \"max\": 147,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          123,\n          140,\n          147\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"blood_pressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 58,\n        \"max\": 82,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          72,\n          82,\n          80\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"skin_thickness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19,\n        \"min\": 0,\n        \"max\": 43,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0,\n          43,\n          22\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"insulin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 142,\n        \"min\": 0,\n        \"max\": 325,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          128,\n          325\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bmi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.837537878696345,\n        \"min\": 20.0,\n        \"max\": 39.2,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          36.3,\n          39.2,\n          29.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pedigree_function\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22365643295018364,\n        \"min\": 0.178,\n        \"max\": 0.699,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.258,\n          0.528,\n          0.178\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16,\n        \"min\": 22,\n        \"max\": 58,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          52,\n          58,\n          50\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"has_diabetes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "\n",
        "print(diabetes_df.shape)\n",
        "diabetes_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "systematic-motorcycle",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "systematic-motorcycle",
        "outputId": "701569cd-cd4f-4b39-b126-5dae4974a8bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "times_pregnant              int64\n",
              "glucose_tolerance_test      int64\n",
              "blood_pressure              int64\n",
              "skin_thickness              int64\n",
              "insulin                     int64\n",
              "bmi                       float64\n",
              "pedigree_function         float64\n",
              "age                         int64\n",
              "has_diabetes                int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "diabetes_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "collected-lafayette",
      "metadata": {
        "id": "collected-lafayette"
      },
      "outputs": [],
      "source": [
        "X = diabetes_df.iloc[:, :-1].values\n",
        "y = diabetes_df[\"has_diabetes\"].values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acquired-parallel",
      "metadata": {
        "id": "acquired-parallel"
      },
      "source": [
        "Split the data to Train, and Test (75%, 25%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "rational-hollow",
      "metadata": {
        "id": "rational-hollow"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "acceptable-equity",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acceptable-equity",
        "outputId": "b5bf8f34-a719-484d-b3b9-364b0c693f6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3489583333333333, 0.6510416666666666)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "np.mean(y), np.mean(1-y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "thick-reconstruction",
      "metadata": {
        "id": "thick-reconstruction"
      },
      "source": [
        "Build a single hidden layer neural network using 12 nodes.\n",
        "Use the sequential model with single layer network and input shape to 8.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dramatic-zealand",
      "metadata": {
        "id": "dramatic-zealand"
      },
      "source": [
        "Normalize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "painted-mathematics",
      "metadata": {
        "id": "painted-mathematics"
      },
      "outputs": [],
      "source": [
        "normalizer = StandardScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "previous-electricity",
      "metadata": {
        "id": "previous-electricity"
      },
      "source": [
        "Define the model:\n",
        "* Input size is 8-dimensional\n",
        "* 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
        "* Final layer with one node and sigmoid activation (standard for binary classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "found-bowling",
      "metadata": {
        "id": "found-bowling"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "model  = Sequential([\n",
        "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "level-terminal",
      "metadata": {
        "id": "level-terminal"
      },
      "source": [
        "View the model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "correct-kingdom",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "correct-kingdom",
        "outputId": "f98507cc-5d19-4221-f18f-9782428c329e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 12)                108       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 13        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121 (484.00 Byte)\n",
            "Trainable params: 121 (484.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "herbal-anderson",
      "metadata": {
        "id": "herbal-anderson"
      },
      "source": [
        "Train the model\n",
        "* Compile the model with optimizer, loss function and metrics\n",
        "* Use the fit function to return the run history.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "happy-prompt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "happy-prompt",
        "outputId": "c9d5d10f-ab72-4252-8663-83264005f9fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "18/18 [==============================] - 1s 23ms/step - loss: 0.8650 - accuracy: 0.3958 - val_loss: 0.8467 - val_accuracy: 0.4167\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.8154 - accuracy: 0.4115 - val_loss: 0.8052 - val_accuracy: 0.4479\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7750 - accuracy: 0.4549 - val_loss: 0.7707 - val_accuracy: 0.5208\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7411 - accuracy: 0.5104 - val_loss: 0.7418 - val_accuracy: 0.5573\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7124 - accuracy: 0.5816 - val_loss: 0.7170 - val_accuracy: 0.5938\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6877 - accuracy: 0.6128 - val_loss: 0.6955 - val_accuracy: 0.6406\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6664 - accuracy: 0.6337 - val_loss: 0.6766 - val_accuracy: 0.6510\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6601 - val_accuracy: 0.6615\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6313 - accuracy: 0.6649 - val_loss: 0.6456 - val_accuracy: 0.6562\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6169 - accuracy: 0.6649 - val_loss: 0.6328 - val_accuracy: 0.6615\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6039 - accuracy: 0.6719 - val_loss: 0.6214 - val_accuracy: 0.6667\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5924 - accuracy: 0.6858 - val_loss: 0.6113 - val_accuracy: 0.6510\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5822 - accuracy: 0.6892 - val_loss: 0.6024 - val_accuracy: 0.6510\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5730 - accuracy: 0.6979 - val_loss: 0.5943 - val_accuracy: 0.6562\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.7031 - val_loss: 0.5870 - val_accuracy: 0.6667\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5572 - accuracy: 0.7014 - val_loss: 0.5804 - val_accuracy: 0.6771\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5504 - accuracy: 0.7014 - val_loss: 0.5744 - val_accuracy: 0.6823\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5441 - accuracy: 0.6979 - val_loss: 0.5689 - val_accuracy: 0.6927\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5384 - accuracy: 0.7066 - val_loss: 0.5638 - val_accuracy: 0.6927\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7101 - val_loss: 0.5592 - val_accuracy: 0.7031\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5283 - accuracy: 0.7222 - val_loss: 0.5550 - val_accuracy: 0.7031\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.7292 - val_loss: 0.5512 - val_accuracy: 0.7188\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.7344 - val_loss: 0.5477 - val_accuracy: 0.7135\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7378 - val_loss: 0.5446 - val_accuracy: 0.7135\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5125 - accuracy: 0.7465 - val_loss: 0.5417 - val_accuracy: 0.7135\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5092 - accuracy: 0.7448 - val_loss: 0.5390 - val_accuracy: 0.7188\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7517 - val_loss: 0.5366 - val_accuracy: 0.7240\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7587 - val_loss: 0.5344 - val_accuracy: 0.7240\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5010 - accuracy: 0.7604 - val_loss: 0.5323 - val_accuracy: 0.7240\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4986 - accuracy: 0.7587 - val_loss: 0.5305 - val_accuracy: 0.7292\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4964 - accuracy: 0.7622 - val_loss: 0.5288 - val_accuracy: 0.7396\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4944 - accuracy: 0.7622 - val_loss: 0.5272 - val_accuracy: 0.7396\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4926 - accuracy: 0.7604 - val_loss: 0.5257 - val_accuracy: 0.7396\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4907 - accuracy: 0.7552 - val_loss: 0.5243 - val_accuracy: 0.7396\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4891 - accuracy: 0.7552 - val_loss: 0.5231 - val_accuracy: 0.7396\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4875 - accuracy: 0.7535 - val_loss: 0.5219 - val_accuracy: 0.7344\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4860 - accuracy: 0.7552 - val_loss: 0.5208 - val_accuracy: 0.7448\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4847 - accuracy: 0.7587 - val_loss: 0.5197 - val_accuracy: 0.7448\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4833 - accuracy: 0.7604 - val_loss: 0.5187 - val_accuracy: 0.7448\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4820 - accuracy: 0.7639 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4808 - accuracy: 0.7656 - val_loss: 0.5169 - val_accuracy: 0.7500\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4797 - accuracy: 0.7656 - val_loss: 0.5160 - val_accuracy: 0.7500\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4786 - accuracy: 0.7674 - val_loss: 0.5152 - val_accuracy: 0.7500\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.7656 - val_loss: 0.5145 - val_accuracy: 0.7448\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4765 - accuracy: 0.7674 - val_loss: 0.5138 - val_accuracy: 0.7500\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4757 - accuracy: 0.7691 - val_loss: 0.5131 - val_accuracy: 0.7500\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.7726 - val_loss: 0.5125 - val_accuracy: 0.7500\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4739 - accuracy: 0.7726 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.7743 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.7743 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4715 - accuracy: 0.7726 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7726 - val_loss: 0.5098 - val_accuracy: 0.7500\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4700 - accuracy: 0.7726 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7726 - val_loss: 0.5089 - val_accuracy: 0.7500\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.7726 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7743 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.7743 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7743 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7726 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7726 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.7743 - val_loss: 0.5063 - val_accuracy: 0.7448\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7743 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.7708 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7726 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7743 - val_loss: 0.5051 - val_accuracy: 0.7396\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7726 - val_loss: 0.5048 - val_accuracy: 0.7396\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7743 - val_loss: 0.5046 - val_accuracy: 0.7396\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.7743 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7743 - val_loss: 0.5041 - val_accuracy: 0.7396\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7743 - val_loss: 0.5039 - val_accuracy: 0.7396\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7708 - val_loss: 0.5036 - val_accuracy: 0.7396\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7726 - val_loss: 0.5034 - val_accuracy: 0.7396\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7708 - val_loss: 0.5032 - val_accuracy: 0.7396\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7726 - val_loss: 0.5030 - val_accuracy: 0.7396\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.7691 - val_loss: 0.5028 - val_accuracy: 0.7396\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7708 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7726 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4579 - accuracy: 0.7726 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.7726 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7760 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7726 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7726 - val_loss: 0.5017 - val_accuracy: 0.7396\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7743 - val_loss: 0.5016 - val_accuracy: 0.7396\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.7743 - val_loss: 0.5014 - val_accuracy: 0.7396\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7708 - val_loss: 0.5013 - val_accuracy: 0.7396\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.7708 - val_loss: 0.5012 - val_accuracy: 0.7396\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.7708 - val_loss: 0.5011 - val_accuracy: 0.7448\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4548 - accuracy: 0.7726 - val_loss: 0.5010 - val_accuracy: 0.7448\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.7708 - val_loss: 0.5009 - val_accuracy: 0.7500\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7726 - val_loss: 0.5009 - val_accuracy: 0.7500\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.7726 - val_loss: 0.5008 - val_accuracy: 0.7500\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7708 - val_loss: 0.5007 - val_accuracy: 0.7500\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.7691 - val_loss: 0.5007 - val_accuracy: 0.7500\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7674 - val_loss: 0.5006 - val_accuracy: 0.7500\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.7691 - val_loss: 0.5006 - val_accuracy: 0.7500\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4528 - accuracy: 0.7691 - val_loss: 0.5006 - val_accuracy: 0.7500\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.7708 - val_loss: 0.5005 - val_accuracy: 0.7552\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4524 - accuracy: 0.7691 - val_loss: 0.5005 - val_accuracy: 0.7552\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.7674 - val_loss: 0.5005 - val_accuracy: 0.7552\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7708 - val_loss: 0.5005 - val_accuracy: 0.7552\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.7708 - val_loss: 0.5005 - val_accuracy: 0.7552\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.7691 - val_loss: 0.5004 - val_accuracy: 0.7552\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7691 - val_loss: 0.5004 - val_accuracy: 0.7552\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4513 - accuracy: 0.7674 - val_loss: 0.5004 - val_accuracy: 0.7552\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.7691 - val_loss: 0.5003 - val_accuracy: 0.7552\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.7674 - val_loss: 0.5003 - val_accuracy: 0.7552\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.7691 - val_loss: 0.5003 - val_accuracy: 0.7552\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7674 - val_loss: 0.5002 - val_accuracy: 0.7552\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7708 - val_loss: 0.5002 - val_accuracy: 0.7552\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7726 - val_loss: 0.5002 - val_accuracy: 0.7552\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7708 - val_loss: 0.5002 - val_accuracy: 0.7552\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.7726 - val_loss: 0.5001 - val_accuracy: 0.7552\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.7708 - val_loss: 0.5001 - val_accuracy: 0.7552\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.7726 - val_loss: 0.5001 - val_accuracy: 0.7552\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7708 - val_loss: 0.5001 - val_accuracy: 0.7552\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7708 - val_loss: 0.5001 - val_accuracy: 0.7552\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7726 - val_loss: 0.5000 - val_accuracy: 0.7552\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.7726 - val_loss: 0.5000 - val_accuracy: 0.7552\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7708 - val_loss: 0.5000 - val_accuracy: 0.7552\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.7708 - val_loss: 0.5000 - val_accuracy: 0.7552\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4481 - accuracy: 0.7726 - val_loss: 0.5000 - val_accuracy: 0.7552\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.7726 - val_loss: 0.4999 - val_accuracy: 0.7552\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7726 - val_loss: 0.4999 - val_accuracy: 0.7552\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7726 - val_loss: 0.4999 - val_accuracy: 0.7552\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7708 - val_loss: 0.4999 - val_accuracy: 0.7552\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7708 - val_loss: 0.5000 - val_accuracy: 0.7552\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.7691 - val_loss: 0.5000 - val_accuracy: 0.7552\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7708 - val_loss: 0.5000 - val_accuracy: 0.7604\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4468 - accuracy: 0.7726 - val_loss: 0.5000 - val_accuracy: 0.7604\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4467 - accuracy: 0.7726 - val_loss: 0.5000 - val_accuracy: 0.7604\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7726 - val_loss: 0.5000 - val_accuracy: 0.7604\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.7743 - val_loss: 0.5000 - val_accuracy: 0.7604\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.7726 - val_loss: 0.5000 - val_accuracy: 0.7604\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.7743 - val_loss: 0.5000 - val_accuracy: 0.7604\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4459 - accuracy: 0.7743 - val_loss: 0.5000 - val_accuracy: 0.7604\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7743 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4455 - accuracy: 0.7743 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4454 - accuracy: 0.7726 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4452 - accuracy: 0.7743 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4452 - accuracy: 0.7726 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4450 - accuracy: 0.7743 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4448 - accuracy: 0.7760 - val_loss: 0.5002 - val_accuracy: 0.7604\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4447 - accuracy: 0.7778 - val_loss: 0.5002 - val_accuracy: 0.7604\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4446 - accuracy: 0.7778 - val_loss: 0.5003 - val_accuracy: 0.7604\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4445 - accuracy: 0.7778 - val_loss: 0.5003 - val_accuracy: 0.7604\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4444 - accuracy: 0.7760 - val_loss: 0.5003 - val_accuracy: 0.7604\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7778 - val_loss: 0.5003 - val_accuracy: 0.7604\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4440 - accuracy: 0.7726 - val_loss: 0.5004 - val_accuracy: 0.7604\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4439 - accuracy: 0.7760 - val_loss: 0.5004 - val_accuracy: 0.7604\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4438 - accuracy: 0.7778 - val_loss: 0.5004 - val_accuracy: 0.7604\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4437 - accuracy: 0.7760 - val_loss: 0.5005 - val_accuracy: 0.7604\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4435 - accuracy: 0.7743 - val_loss: 0.5005 - val_accuracy: 0.7604\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4434 - accuracy: 0.7743 - val_loss: 0.5005 - val_accuracy: 0.7604\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4432 - accuracy: 0.7743 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4431 - accuracy: 0.7743 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4429 - accuracy: 0.7743 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4429 - accuracy: 0.7726 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4427 - accuracy: 0.7760 - val_loss: 0.5007 - val_accuracy: 0.7604\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4426 - accuracy: 0.7760 - val_loss: 0.5007 - val_accuracy: 0.7552\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4425 - accuracy: 0.7760 - val_loss: 0.5007 - val_accuracy: 0.7552\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.7778 - val_loss: 0.5007 - val_accuracy: 0.7552\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.7726 - val_loss: 0.5008 - val_accuracy: 0.7552\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.7760 - val_loss: 0.5008 - val_accuracy: 0.7552\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7760 - val_loss: 0.5008 - val_accuracy: 0.7552\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.7760 - val_loss: 0.5008 - val_accuracy: 0.7552\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7760 - val_loss: 0.5008 - val_accuracy: 0.7552\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7760 - val_loss: 0.5008 - val_accuracy: 0.7552\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7760 - val_loss: 0.5009 - val_accuracy: 0.7552\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7743 - val_loss: 0.5009 - val_accuracy: 0.7552\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7760 - val_loss: 0.5009 - val_accuracy: 0.7552\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7743 - val_loss: 0.5009 - val_accuracy: 0.7552\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.7743 - val_loss: 0.5009 - val_accuracy: 0.7552\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.7743 - val_loss: 0.5009 - val_accuracy: 0.7552\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7760 - val_loss: 0.5010 - val_accuracy: 0.7552\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7760 - val_loss: 0.5010 - val_accuracy: 0.7552\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7743 - val_loss: 0.5010 - val_accuracy: 0.7552\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7743 - val_loss: 0.5010 - val_accuracy: 0.7552\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7743 - val_loss: 0.5011 - val_accuracy: 0.7552\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7743 - val_loss: 0.5011 - val_accuracy: 0.7552\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7743 - val_loss: 0.5011 - val_accuracy: 0.7552\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7726 - val_loss: 0.5011 - val_accuracy: 0.7552\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7760 - val_loss: 0.5012 - val_accuracy: 0.7552\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7760 - val_loss: 0.5012 - val_accuracy: 0.7552\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7726 - val_loss: 0.5013 - val_accuracy: 0.7552\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7743 - val_loss: 0.5013 - val_accuracy: 0.7552\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7760 - val_loss: 0.5014 - val_accuracy: 0.7552\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7726 - val_loss: 0.5014 - val_accuracy: 0.7552\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7760 - val_loss: 0.5014 - val_accuracy: 0.7552\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7743 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7760 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7778 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7743 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.7743 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7778 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7760 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7760 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7778 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7760 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4383 - accuracy: 0.7778 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7760 - val_loss: 0.5021 - val_accuracy: 0.7552\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_1 = model.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "unsigned-nevada",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unsigned-nevada",
        "outputId": "b517705d-13f5-4d69-b9fc-dd2dc4656a8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 4ms/step\n",
            "6/6 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "## Like we did for the Random Forest, we generate two kinds of predictions\n",
        "#  One is a hard decision, the other is a probabilitistic score.\n",
        "\n",
        "y_pred_prob_nn_1 = model.predict(X_test_norm)\n",
        "y_pred_class_nn_1 = (model.predict(X_test_norm) > 0.5).astype('int32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "tough-catering",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tough-catering",
        "outputId": "ce8dd152-8472-4706-be9b-a7338f622311"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Let's check out the outputs to get a feel for how keras apis work.\n",
        "y_pred_class_nn_1[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "combined-zimbabwe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "combined-zimbabwe",
        "outputId": "ef23b2a9-6212-4562-993b-e90df69282b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.6332816 ],\n",
              "       [0.556432  ],\n",
              "       [0.3881246 ],\n",
              "       [0.29449975],\n",
              "       [0.16094974],\n",
              "       [0.49249297],\n",
              "       [0.02398692],\n",
              "       [0.4036895 ],\n",
              "       [0.9366343 ],\n",
              "       [0.12252731]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "y_pred_prob_nn_1[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation: The initial code given has encountered errors such as model_1 is not defined, and solved it by removing the _1 part of the code. Another problem encountered was the \"'Sequential' object has no attribute 'predict_classes'\", and solved it without using predict_classes and used (model.predict(X_test_norm) > 0.5).astype('int32') as it compares the predicted probabilities against a threshold of 0.5 and converts them to binary decisions."
      ],
      "metadata": {
        "id": "J72jCgKnPjMo"
      },
      "id": "J72jCgKnPjMo"
    },
    {
      "cell_type": "markdown",
      "id": "going-estonia",
      "metadata": {
        "id": "going-estonia"
      },
      "source": [
        "Create the plot_roc function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "supposed-moderator",
      "metadata": {
        "id": "supposed-moderator"
      },
      "outputs": [],
      "source": [
        "def plot_roc(y_test, y_pred, model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "second-festival",
      "metadata": {
        "id": "second-festival"
      },
      "source": [
        "Evaluate the model performance and plot the ROC CURVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "eleven-nebraska",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "eleven-nebraska",
        "outputId": "e3b8dac4-7733-4f60-e534-8c9ddd33ba4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.755\n",
            "roc-auc is 0.820\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqQAAAKqCAYAAADsTEzZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABuv0lEQVR4nO3deVhV5f7+8RuQwY0iljhmTg1qdrI0PQamlUplnjxl4pBT5pDaRGVOaWqGZZoNjuVQKYJ5rKw8KmmeMi3LoazUHDNTUXNA2QIbeH5/9GX/RAaZ1x7er+viqr1Ya68PPBu5+TxrPdvHGGMEAAAAWMTX6gIAAADg3QikAAAAsBSBFAAAAJYikAIAAMBSBFIAAABYikAKAAAASxFIAQAAYCkCKQAAACxFIAUAAIClCKQA8jRlyhTVr19ffn5+atq0qdXlwIX07dtXdevWzbbNx8dHL774YqGfa+HChfLx8dEPP/xQMsV5kbZt26pJkyaX3e/gwYPy8fHRwoULS78ooAgIpHBZWb+ksj7KlSunWrVqqW/fvvrzzz9zPcYYow8++EC33367QkNDZbPZdOONN2rChAlKTk7O81wfffSR7rnnHlWpUkUBAQGqWbOmunbtqnXr1hWo1pSUFL3++utq2bKlKlWqpKCgIF133XUaNmyYfvvttyJ9/VZbs2aNhg8frvDwcC1YsEAvv/xyqZ6vb9++8vHx0T/+8Q/l9o7GPj4+GjZsmPNx1i9YHx8f/ec//8mx/4svvigfHx+dPHmyVOsuqKx6sj5sNpsaN26sMWPGKCkpyblfbuEs61hfX1/98ccfOZ47KSlJ5cuXz/E9utjOnTvl4+OjoKAgnTlzpsS/PlezcuXKIoVjANYoZ3UBwOVMmDBB9erVU0pKir799lstXLhQGzZs0M8//6ygoCDnfhkZGerRo4eWLl2q1q1b68UXX5TNZtPXX3+t8ePH68MPP9QXX3yhatWqOY8xxuiRRx7RwoULdfPNNys6OlrVq1fX0aNH9dFHH+muu+7SN998o9tuuy3P+k6ePKm7775bW7Zs0X333acePXqoQoUK2r17t+Li4jR37lylpaWV6veoNKxbt06+vr6aN2+eAgICyuy8O3bs0PLly/Xggw8W+JgJEybogQcekI+PTylWVjJmzZqlChUq6Pz581qzZo0mTZqkdevW6Ztvvrls/YGBgVqyZImGDx+ebfvy5csve95FixapevXqOn36tJYtW6ZHH320WF9Hbi5cuKBy5Vzj18rKlSs1Y8YMQingJlzjXw4gH/fcc4+aN28uSXr00UdVpUoVvfLKK1qxYoW6du3q3O/VV1/V0qVL9eyzz2rKlCnO7QMHDlTXrl3VuXNn9e3bV//973+dn5s6daoWLlyop556StOmTcsWCEaPHq0PPvjgsr9g+/btq23btmnZsmU5QtTEiRM1evToYn39WdLT05WZmVlm4fD48eMqX758iZ3PGKOUlBSVL18+z33Kly+v2rVrFypgNm3aVNu3b9dHH32kBx54oERqLU1dunRRlSpVJEmDBw/Wgw8+qOXLl+vbb79Vq1at8j323nvvzTWQxsbGqmPHjrl2iqW/v/exsbHq0aOHDhw4oMWLF5dKIL34D0QUTXJysoKDg60uAyhzTNnD7bRu3VqStG/fPue2CxcuaMqUKbruuusUExOT45hOnTqpT58+WrVqlb799lvnMTExMWrYsKFee+21XMNPr1691KJFizxr+e677/T555+rf//+uXb0AgMD9dprrzkft23bVm3bts2x36XX42VNR7/22muaPn26GjRooMDAQG3btk3lypXT+PHjczzH7t275ePjo7ffftu57cyZM3rqqadUu3ZtBQYG6pprrtErr7yizMzMPL8m6e/p8QULFig5Odk5xZx17Vl6eromTpzorKlu3boaNWqUUlNTsz1H3bp1dd9992n16tVq3ry5ypcvrzlz5uR7Xl9fX40ZM0Y//fSTPvroo3z3zdKtWzddd911mjBhQq5T/QWxbds23XPPPQoJCVGFChV01113OV8nWbKm0r/55htFR0crLCxMwcHB+ve//60TJ04U6bySdOedd0qSDhw4cNl9e/Tooe3bt2vXrl3ObceOHdO6devUo0ePPI/75ptvdPDgQXXr1k3dunXTV199pcOHDxe4xo8//lhNmjRRUFCQmjRpkufYXHoN6e+//64hQ4bo+uuvV/ny5XXllVfqoYce0sGDB3M93m63a9CgQbryyisVEhKi3r176/Tp0zn2++9//6vWrVsrODhYFStWVMeOHfXLL784P9+3b1/NmDHDWVPWR5bMzExNnz5dN9xwg4KCglStWjUNGjQox7l++OEHRUZGqkqVKipfvrzq1aunRx555LLfr6zX/po1a9S0aVMFBQWpcePGOTrZWa+p//3vfxoyZIiqVq2qq666yvn5mTNn6oYbblBgYKBq1qypoUOH5nm5xZYtW3Tbbbc565w9e/Zl65SkXbt2qUuXLrriiisUFBSk5s2ba8WKFbnWuWHDBj3xxBMKCwtTaGioBg0apLS0NJ05c0a9e/dW5cqVVblyZQ0fPrzIP4vwXgRSuJ2sX2aVK1d2btuwYYNOnz6tHj165NnR7N27tyTps88+cx5z6tQp9ejRQ35+fkWqJesf7l69ehXp+MtZsGCB3nrrLQ0cOFBTp05VjRo11KZNGy1dujTHvvHx8fLz89NDDz0k6e9f7m3atNGiRYvUu3dvvfnmmwoPD9fIkSMVHR2d73k/+OADtW7dWoGBgfrggw+c1+VKf3epx44dq1tuuUWvv/662rRpo5iYGHXr1i3H8+zevVvdu3dX+/bt9cYbbxToxqgePXro2muvLXDA9PPz05gxY/Tjjz8WOMRe7JdfflHr1q31448/avjw4XrhhRd04MABtW3bVt99912O/R9//HH9+OOPGjdunB577DF9+umneV63WRBZf1hdeeWVl9339ttv11VXXaXY2Fjntvj4eFWoUEEdO3bM87jFixerQYMGuvXWW9WpUyfZbDYtWbKkQPWtWbNGDz74oHx8fBQTE6POnTurX79+BboB6fvvv9fGjRvVrVs3vfnmmxo8eLDWrl2rtm3bym6359h/2LBh2rlzp1588UX17t1bixcvVufOnbO9Dj744AN17NhRFSpU0CuvvKIXXnhBv/76qyIiIpz/NgwaNEjt27d37p/1kWXQoEF67rnnFB4erjfeeEP9+vXT4sWLFRkZKYfDIenvGYIOHTro4MGDGjFihN566y317Nkzxx8qedmzZ4+ioqJ0zz33KCYmRuXKldNDDz2khISEHPsOGTJEv/76q8aOHasRI0ZI+vu64aFDh6pmzZqaOnWqHnzwQc2ZM0cdOnRw1pjl9OnTuvfee9WsWTO9+uqruuqqq/TYY49p/vz5+db4yy+/6J///Kd27typESNGaOrUqQoODlbnzp1z/Vl6/PHHtWfPHo0fP17/+te/NHfuXL3wwgvq1KmTMjIy9PLLLysiIkJTpkzJ9v0GCsQALmrBggVGkvniiy/MiRMnzB9//GGWLVtmwsLCTGBgoPnjjz+c+06fPt1IMh999FGez3fq1CkjyTzwwAPGGGPeeOONyx5zOf/+97+NJHP69OkC7d+mTRvTpk2bHNv79Olj6tSp43x84MABI8mEhISY48ePZ9t3zpw5RpLZsWNHtu2NGzc2d955p/PxxIkTTXBwsPntt9+y7TdixAjj5+dnDh06lG+tffr0McHBwdm2bd++3Ugyjz76aLbtzz77rJFk1q1b59xWp04dI8msWrUq3/Pkdr733nvPSDLLly93fl6SGTp0qPNx1vdoypQpJj093Vx77bXmpptuMpmZmcYYY8aNG2ckmRMnTuR73s6dO5uAgACzb98+57YjR46YihUrmttvv925Lev12K5dO+c5jDHm6aefNn5+fubMmTP5niernt27d5sTJ06YAwcOmDlz5pjAwEBTrVo1k5ycnO0833//fY5jT5w4YZ599llzzTXXOD936623mn79+uX6PTLGmLS0NHPllVea0aNHO7f16NHD3HTTTfnWm6Vp06amRo0a2b6+NWvWGEnZXrNZ5x83bpzzsd1uz/F8mzZtMpLM+++/79yW9TU3a9bMpKWlObe/+uqrRpL55JNPjDHGnDt3zoSGhpoBAwZke85jx46ZSpUqZds+dOhQk9uvuK+//tpIMosXL862fdWqVdm2f/TRRznGoaCyXvv/+c9/nNvOnj1ratSoYW6++eYcX3dERIRJT093bj9+/LgJCAgwHTp0MBkZGc7tb7/9tpFk5s+f79zWpk0bI8lMnTrVuS01NdU0bdrUVK1a1fn9zPp5WbBggXO/u+66y9x4440mJSXFuS0zM9Pcdttt5tprr81RZ2RkZLbXfqtWrYyPj48ZPHiwc1t6erq56qqrcv13DsgPHVK4vHbt2iksLEy1a9dWly5dFBwcrBUrVmSb2jp37pwkqWLFink+T9bnsu5ozvpvfsdcTkk8R34efPBBhYWFZdv2wAMPqFy5coqPj3du+/nnn/Xrr78qKirKue3DDz9U69atVblyZZ08edL50a5dO2VkZOirr74qdD0rV66UpBwd1meeeUaS9Pnnn2fbXq9ePUVGRhb6PD179ixyl/Tjjz8u8HkyMjK0Zs0ade7cWfXr13dur1Gjhnr06KENGzZkuwNe+vua5Iunf1u3bq2MjAz9/vvvBTrn9ddfr7CwMNWrV0+DBg3SNddco88//1w2m61Ax/fo0UN79+7V999/7/xvftP1//3vf/XXX3+pe/fuzm3du3fXjz/+mG2aOzdHjx7V9u3b1adPH1WqVMm5vX379mrcuPFla734emGHw6G//vpL11xzjUJDQ7V169Yc+w8cOFD+/v7Ox4899pjKlSvnfN0lJCTozJkz6t69e7bXtJ+fn1q2bKkvv/zysjV9+OGHqlSpktq3b5/tOZo1a6YKFSo4nyM0NFTS3zMql3YkC6JmzZr697//7XycdQnCtm3bdOzYsWz7DhgwINsszRdffKG0tDQ99dRT8vX1zbZfSEhIjp+zcuXKadCgQc7HAQEBGjRokI4fP64tW7bkWt+pU6e0bt06de3aVefOnXN+H/766y9FRkZqz549OVYz6d+/f7bXfsuWLWWMUf/+/Z3b/Pz81Lx5c+3fv78g3ybAiUAKlzdjxgwlJCRo2bJluvfee3Xy5EkFBgZm2ycrEGYF09xcGlpDQkIue8zllMRz5KdevXo5tlWpUkV33XVXtmn7+Ph4lStXLttNPXv27NGqVasUFhaW7aNdu3aS/p6SLKzff/9dvr6+uuaaa7Jtr169ukJDQ3OEstzqL4isgLl9+/YCB8yePXvqmmuuKdS1pCdOnJDdbtf111+f43ONGjVSZmZmjmWWrr766myPsy4dye1ax9z85z//UUJCgtavX6+9e/fq559/VrNmzQp0rCTdfPPNatiwoWJjY7V48WJVr17deR1qbhYtWqR69eopMDBQe/fu1d69e9WgQQPZbDYtXrw433Nljee1116b43O5fc8udeHCBY0dO9Z5DXOVKlUUFhamM2fO6OzZszn2v/Q8FSpUUI0aNZxT8Xv27JH093W3l76u16xZU6DX9J49e3T27FlVrVo1x3OcP3/e+Rxt2rTRgw8+qPHjx6tKlSq6//77tWDBghzXSuflmmuuyXFd+nXXXSdJOa6hvfTnJOv7fun3OCAgQPXr18/xc1azZs0cN0Llda4se/fulTFGL7zwQo7vw7hx4yTl/Dfi0td+1h8ptWvXzrG9oD8PQBbusofLa9GihfMu+86dOysiIkI9evTQ7t27VaFCBUl/hwdJ+umnn9S5c+dcn+enn36SJGdnp2HDhpL+XmYor2Mu5+LnyLrZKj8+Pj65hqWMjIxc98/rjvRu3bqpX79+2r59u5o2baqlS5fqrrvuct69Lf1940b79u1z3JGdJesXVlEUdHml/O6ov5yePXtq4sSJmjBhQoHGJyvE9u3bV5988kmRz1uQ8+SmoCH49ttvzzZORdGjRw/NmjVLFStWVFRUVLYu2sWSkpL06aefKiUlJddQGRsbq0mTJpXaclmPP/64FixYoKeeekqtWrVSpUqV5OPjo27dul32xrrcZB3zwQcfqHr16jk+X5AlpzIzM1W1atU8w3jWjISPj4+WLVumb7/9Vp9++qlWr16tRx55RFOnTtW3337r/LenJBTn56Sosr6Xzz77bJ6zGJf+4ZnXaz+37QX9eQCyEEjhVvz8/BQTE6M77rhDb7/9tvMGgIiICIWGhio2NlajR4/O9R/I999/X5J03333OY+pXLmylixZolGjRhXpxqZOnTopJiZGixYtKlAgrVy5cq5TWQWd7s3SuXNnDRo0yDlt/9tvv2nkyJHZ9mnQoIHOnz/v7IiWhDp16igzM1N79uxx/hEgSYmJiTpz5ozq1KlTYucqSsB8+OGH9dJLLzlvuricsLAw2Ww27d69O8fndu3aJV9f3xzdH1fQo0cPjR07VkePHs335pHly5crJSVFs2bNyhGCd+/erTFjxuibb75RRERErsdnjWdWZ/LS4y9n2bJl6tOnj6ZOnerclpKSkued4nv27NEdd9zhfHz+/HkdPXpU9957r6S/X9OSVLVq1cu+rvMK2Q0aNNAXX3yh8PDwAgXBf/7zn/rnP/+pSZMmKTY2Vj179lRcXNxll83K6kBeXEfWm2Rc+g5Xl8r6vu/evTvbpSRpaWk6cOBAjq/9yJEjOZaLuty5sp7X39+/RP+NAIqKKXu4nbZt26pFixaaPn26UlJSJEk2m03PPvusdu/eneu6n59//rkWLlyoyMhI/fOf/3Qe8/zzz2vnzp16/vnnc/2LftGiRdq8eXOetbRq1Up333233n333VynltPS0vTss886Hzdo0EC7du3KtkzQjz/+qG+++abAX7/09/VtkZGRWrp0qeLi4hQQEJCji9i1a1dt2rRJq1evznH8mTNnlJ6eXqhzSnIGg+nTp2fbPm3aNEnK907vonj44Yd1zTXX5LrMVW4unuq/dOmavPbv0KGDPvnkk2xTm4mJiYqNjVVERITzsgxX0qBBA02fPl0xMTH5Lku2aNEi1a9fX4MHD1aXLl2yfTz77LOqUKFCvtP2NWrUUNOmTfXee+9lm2JPSEjQr7/+etk6/fz8cvxcvfXWW3nOCMydOzfb9ZqzZs1Senq67rnnHklSZGSkQkJC9PLLL+d6XefFP1dZ4ezS8Nu1a1dlZGRo4sSJOY5PT0937n/69OkctWetElGQafsjR45ku1M9KSlJ77//vpo2bZprd/di7dq1U0BAgN58881sNcybN09nz57N8XOWnp6ebUm1tLQ0zZkzR2FhYXleDlK1alW1bdtWc+bM0dGjR3N8vjhLmQFFQYcUbum5557TQw89pIULF2rw4MGSpBEjRmjbtm165ZVXtGnTJj344IMqX768NmzYoEWLFqlRo0Z67733cjzPL7/8oqlTp+rLL79Uly5dVL16dR07dkwff/yxNm/erI0bN+Zby/vvv68OHTrogQceUKdOnXTXXXcpODhYe/bsUVxcnI4ePepci/SRRx7RtGnTFBkZqf79++v48eOaPXu2brjhhhw3z1xOVFSUHn74Yc2cOVORkZHOmzAu/tpWrFih++67T3379lWzZs2UnJysHTt2aNmyZTp48GChp45vuukm9enTR3PnztWZM2fUpk0bbd68We+99546d+6crbtVEvz8/DR69Gj169evwMdkTfVv3769QPu/9NJLSkhIUEREhIYMGaJy5cppzpw5Sk1N1auvvlrEykvfk08+me/njxw5oi+//FJPPPFErp8PDAxUZGSkPvzwQ7355pvZbia6WExMjDp27KiIiAg98sgjOnXqlN566y3dcMMNOn/+fL413Hffffrggw9UqVIlNW7cWJs2bdIXX3yR5xJXaWlpuuuuu9S1a1ft3r1bM2fOVEREhLPbHRISolmzZqlXr1665ZZb1K1bN4WFhenQoUP6/PPPFR4e7lyHNyuIPfHEE4qMjJSfn5+6deumNm3aaNCgQYqJidH27dvVoUMH+fv7a8+ePfrwww/1xhtvqEuXLnrvvfc0c+ZM/fvf/1aDBg107tw5vfPOOwoJCXH+YZaf6667Tv3799f333+vatWqaf78+UpMTNSCBQsue2xYWJhGjhyp8ePH6+6779a//vUv5/fj1ltv1cMPP5xt/5o1a+qVV17RwYMHdd111yk+Pl7bt2/X3Llz8xxX6e/r8yMiInTjjTdqwIABql+/vhITE7Vp0yYdPnxYP/7442VrBUqMNTf3A5eX2/I3WTIyMkyDBg1MgwYNsi2XkpGRYRYsWGDCw8NNSEiICQoKMjfccIMZP368OX/+fJ7nWrZsmenQoYO54oorTLly5UyNGjVMVFSUWb9+fYFqtdvt5rXXXjO33nqrqVChggkICDDXXnutefzxx83evXuz7bto0SJTv359ExAQYJo2bWpWr16d57JPU6ZMyfOcSUlJpnz58kaSWbRoUa77nDt3zowcOdJcc801JiAgwFSpUsXcdttt5rXXXsu2vE5uclv2yRhjHA6HGT9+vKlXr57x9/c3tWvXNiNHjsy2dIwxfy9907Fjx3zPUdDzNWjQIN9lny6V9dpRAZZ9MsaYrVu3msjISFOhQgVjs9nMHXfcYTZu3Jjrc176evzyyy+NJPPll1/me46CLkN1uWWf8nPx92jq1KlGklm7dm2e+y9cuDDbskp5+c9//mMaNWpkAgMDTePGjc3y5ctzvGazzn/xsk+nT582/fr1M1WqVDEVKlQwkZGRZteuXaZOnTqmT58+Ob7m//3vf2bgwIGmcuXKpkKFCqZnz57mr7/+ylHPl19+aSIjI02lSpVMUFCQadCggenbt6/54YcfnPukp6ebxx9/3ISFhRkfH58cS0DNnTvXNGvWzJQvX95UrFjR3HjjjWb48OHmyJEjxpi/XxPdu3c3V199tQkMDDRVq1Y19913X7Zz5CXrtb969Wrzj3/8wwQGBpqGDRuaDz/8MNt++f0bZ8zfyzw1bNjQ+Pv7m2rVqpnHHnssxxJzbdq0MTfccIP54YcfTKtWrUxQUJCpU6eOefvtt7Ptl9uyT8YYs2/fPtO7d29TvXp14+/vb2rVqmXuu+8+s2zZssvWmdfrMq+fZSA/PsZw5TEAACWlbt26atKkifNNOABcHteQAgAAwFIEUgAAAFiKQAoAAABLcQ0pAAAALEWHFAAAAJYikAIAAMBSbrEwfmZmpo4cOaKKFSuW2nsuAwAAoOiMMTp37pxq1qwpX9/C9TzdIpAeOXLEJd9PGgAAANn98ccfuuqqqwp1jFsE0ooVK0r6+wu8+H2lHQ6H1qxZ43zrN3gextg7MM7egXH2fIyxd8hrnJOSklS7dm1nbiuMQgfSr776SlOmTNGWLVt09OhRffTRR+rcuXO+x6xfv17R0dH65ZdfVLt2bY0ZM0Z9+/Yt8DmzpulDQkJyBFKbzaaQkBBe+B6KMfYOjLN3YJw9H2PsHS43zkW5vLLQNzUlJyfrpptu0owZMwq0/4EDB9SxY0fdcccd2r59u5566ik9+uijWr16daGLBQAAgOcpdIf0nnvu0T333FPg/WfPnq169epp6tSpkqRGjRppw4YNev311xUZGVnY0wMAACAPxhjZ7fZSPYfD4VBKSopKcin7Ur+GdNOmTWrXrl22bZGRkXrqqafyPCY1NVWpqanOx0lJSZL+/gY4HA7n9qz/v3gbPAtj7B0YZ+/AOHs+xthaxhi1bdtWmzZtKpPzHT9+XKGhoc7HxRn3Ug+kx44dU7Vq1bJtq1atmpKSknThwgWVL18+xzExMTEaP358ju1r1qyRzWbLsT0hIaHkCoZLYoy9A+PsHRhnz8cYWyMlJaXMwqgkrVu3TkFBQc7HxenMuuRd9iNHjlR0dLTzcdZdWx06dMhxU1NCQoLat2/PxdMeijH2Doyzd2CcPR9jbK3k5GTn/x8+fFjBwcEl+vx79+5VdHS0ZsyYoV9//VX33XefAgICnJ/PmtEuilIPpNWrV1diYmK2bYmJiQoJCcm1OypJgYGBCgwMzLHd398/1xd4XtvhORhj78A4ewfG2fMxxta4+HseGhpaooHUGKMjR44oPj5eVapU0f79+xUQEJDtnMUZ81J/69BWrVpp7dq12bYlJCSoVatWpX1qAAAAFNOuXbvUs2dP/etf/1KNGjVK5RyFDqTnz5/X9u3btX37dkl/L+u0fft2HTp0SNLf0+29e/d27j948GDt379fw4cP165duzRz5kwtXbpUTz/9dMl8BQAAACgVR48e1dChQzVt2rRSPU+hA+kPP/ygm2++WTfffLMkKTo6WjfffLPGjh0r6e/Cs8KpJNWrV0+ff/65EhISdNNNN2nq1Kl69913WfIJAADAhe3evVuBgYFavny5qlevXqrnKvQ1pG3bts133amFCxfmesy2bdsKeyoAAABY4JdfftGTTz6p2NhYXXHFFaV+Ppe8yx4AAOBiZbHgu7u7+C774lq6dKliY2NVtWrVEnvO/BBIAQCASzPGKCIiQhs3brS6FI+3Y8cOJSQk5LoefGkikAIAAJdmt9sJo4UQHh6e6xsJXc6OHTsUHR2tJUuWlEJV+SOQAgAAt5GYmFjiC757GpvNJh8fn0Idc/LkSYWGhmrJkiWqUqVKKVWWNwIpAABwG8HBwQTSErZ9+3Y999xz+uyzz3J9Y6KyUOoL4wMAAMA1paWlaeLEiYqPj7csjEp0SAEAALzS1q1blZycrGXLlhV6ir+k0SEFAADwMlu2bNGIESPUpEkTy8OoRIcUAADAq2RmZurw4cNaunSpQkNDrS5HEoEUAAAUQn4L1DscDqWkpCg5OVn+/v4lds6SXPDd233//feaOXOmFixYYHUp2RBIAQBAgbBAvXvbv3+/XnjhBcXHx1tdSg5cQwoAAArE6gXqi7rgO6Rt27bpiiuu0H/+8x9VqlTJ6nJyoEMKAAAKLbcF6h0Oh1avXq3IyMgSnbLPUpQF3yFt2rRJEyZMUHx8vMuu4UogBQAAhZbbAvUOh0NBQUEKDg4ulUCKolm1apXi4+MVEhJidSl5IpACAAB4oI0bN2rr1q0aP3681aVcFoEUAADAw2zatEmTJk1SXFyc1aUUCIEUAADAgxw7dkw1a9ZUfHy8KlSoYHU5BcJd9gAAAB7iq6++0oABA1SrVi23CaMSHVIAAIotv8XiPQkL1Lu25ORkzZgxQ3FxcSpXzr0inntVCwCAi2GxeLiC9evXy2azueSi9wXBlD0AAMVg9WLxVmCBetfy5Zdfatq0aWrSpInVpRQZHVIAAEpIbovFeyIWqHcd6enpOnfunOLi4tz6jwQCKQAAJSS3xeKB0vLFF19o+fLlmjlzptWlFBuBFAAAwM38/PPPevvtt7VkyRKrSykRXEMKAADgRjZu3Kirr75acXFxKl++vNXllAgCKQAAgJtYvXq1XnvtNQUEBCgoKMjqckoMU/YAALfkKmt/sjYnyooxRps2bVJsbKxHhVGJQAoAcEOs/Qlvs3LlSh05ckQvvvii1aWUCgIpAMDtuOLan6zNidKyevVqLViwQIsWLbK6lFJDIAUAuDVXWfuTtTlRGv744w81atRIixYtUmBgoNXllBoCKQDArbH2JzzVihUrFBsbqyVLlnj8HzvcZQ8AAOBiTp06peXLl+v999/3+DAq0SEFAABwKR9//LHq1aunhQsXWl1KmaFDCgAA4CKWL1+u+Ph4NW7c2OpSyhSBFAAAwAWkpaUpICBA77//vvz9/a0up0wxZQ8AKBPGGKWkpCg5ObnYv2xZjB6eZtmyZfruu+80ZcoUq0uxBIEUAFDqjDFq27atNm3aZHUpgMv59ttv9fHHH3vVNaOXYsoeAFDq7HZ7qYRRFqOHu/viiy90ww03aOHChSpXznv7hN77lQMALHH48GGFhoaWyHOxGD3c2ZIlS/Tf//5Xbdu29eowKhFIAQBljIXsASkjI0MHDhzQ/PnzvT6MSgRSAACAMrV48WL5+Pho1KhRVpfiMriGFAAAoIzEx8dr7dq1ioqKsroUl0KHFAAAoAzs379f4eHh6tKli/z8/Kwux6XQIQUAAChlCxcu1OTJk3XVVVcRRnNBhxQAUGzGGNnt9jw/z0L28GZHjx7V999/r9mzZ1tdissikAIAisUYo4iICG3cuNHqUgCX895776lVq1aaMWOG1aW4NKbsAQDFYrfbCxxGGzVqxEL28BrvvvuuNm3apGuuucbqUlweHVIAQIlJTEzMc41Rh8Oh9evXs5A9vEJKSoquuuoqPfLII/L1pf93OQRSAECJyW/Re4fDQRiFV5gzZ44SExM1duxYq0txGwRSAACAEpKQkKAdO3borbfesroUt0IgBQAAKAGffPKJ2rdvr3bt2jEbUEhc1AAAAFBMM2bM0Lp161S+fHnCaBEQSAEAAIohLS1NKSkpmj59OmG0iJiyB4Biutyi8J6ORe/hzd544w3VrVtXzzzzjNWluDUCKQAUA4vCA95rzpw5OnTokJ544gmrS3F7BFIAKIbCLArv6cLDw1n0Hl5j165d6tSpk2rUqME0fQkgkAJACclvUXhvYLPZ+MUMrzB16lSdOHFCkydPtroUj0EgBYASkt+i8AA8w759+3Tq1CnFxMRYXYpH4S57AACAApg+fboCAgI0adIkZgNKGB1SAACAy5g8ebLOnTunq666yupSPBKBFAAAIB/Jyclq2bKl2rZtS2e0lBBIAeD/FGU9UdbgBDzbSy+9pJCQEJZ2KmUEUgAQ64kCyGnZsmVyOBx6/PHHrS7F4xFIAUDFX0+UNTgBz7JkyRI9+OCD6tKli9WleAUCKQBcoijribIGJ+A5XnzxRfn6+iogIMDqUrwGgRQALsF6ooB3yrqOvEaNGho0aJDV5XgV1iEFAABezxijsWPHavPmzYRRCxBIAQCA15s8ebJsNpvuuOMOq0vxSkzZAwAAr2WM0Y4dO/Too48qLCzM6nK8Fh1SAADglYwxGjlypFavXk0YtRgdUgAA4JV27NihsLAwPfPMM1aX4vXokAIAAK9ijNH48eNVo0YNwqiLIJACAACvYYzRc889p5CQEKbpXQhT9gAAwCsYY3Tu3Dk98MADuu2226wuBxehQwoAADyeMUbR0dH65JNPCKMuiEAKAAA83oIFC1S/fn316tXL6lKQC6bsAQCAxzLGaP78+erbt6/8/PysLgd5oEMKAAA8kjFGTzzxhNLS0gijLo4OKQAA8DjGGJ09e1atWrVSjx49rC4Hl0EgBeByjDGy2+1les7k5OQyPR+A0pOZmalhw4bpkUceIYy6CQIpAJdijFFERIQ2btxodSkA3NSIESN08803q3nz5laXggIikAJwKXa73dIwGh4eLpvNZtn5ARRdZmamtm7dqhEjRuiKK66wuhwUAoEUgMtKTExUcHBwmZ7TZrPJx8enTM8JoPgyMzM1ePBgtWrVis6oGyKQAnBZwcHBZR5IAbin7777Tq1atVK/fv2sLgVFwLJPAADAbWVkZOjZZ5/VDTfcQBh1YwRSAADgljIzMzVw4EDddNNNCgkJsbocFANT9gAAwO1kZGTo3LlzGjJkiJo1a2Z1OSgmOqQAAMCtZGRkqH///vr6668Jox6CDimAUlGYxe0dDodSUlKUnJystLS0Uq4MgLt7++231aFDB3Xq1MnqUlBCCKQAShyL2wMoDenp6XrnnXf0xBNPsDybh2HKHkCJK4nF7VmgHsDF0tPT1a9fP11xxRWEUQ9EhxRAqSrI4vYOh0OrV69WZGSk/P39JbFAPYD/LzMzU6dPn1bXrl2ZpvdQdEgBlKqsxe0v9xEUFJTtMWEUgPT3H6y9evXSX3/9RRj1YARSAADgsh5//HE98MADatiwodWloBQxZQ8AAFyOw+HQ1q1b9eqrr7LovRegQwoAAFxKWlqaHn74YR09epQw6iXokAJeqDBrhBZFcnJyqT03AM/39ddfq0ePHrr//vutLgVlhEAKeBnWCAXgqtLS0vT0009r6tSpCgoKsroclCGm7AEvUxJrhBYUa4kCKCiHw6GHH35Y99xzD2HUC9EhBbxYQdYILQ7WEgVQEKmpqbLb7Ro7dqyaNGlidTmwAIEU8GJZa34CgFVSUlLUs2dPPf7442rbtq3V5cAiTNkDAADLvP7663r00UcJo16ODikAAChzKSkpmjdvnkaMGMGlPaBDCgAAylZKSoq6d++ua6+9ljAKSXRIAQBAGcrIyNCpU6f0xBNP6I477rC6HLgIOqSAhzPGKDk5OdsHAFjBbrfrgQceUHp6OmEU2dAhBTwYi+ADcCUDBw7Uk08+qauvvtrqUuBiCKSAB8tvEXwWrQdQVux2u7Zv3645c+aw1BxyxZQ94CUSExN1/vx558fXX3/NzQQASl1ycrKioqLkcDgIo8gTHVLAS7AIPgArfPnll3r22WfVpk0bq0uBCytSh3TGjBmqW7eugoKC1LJlS23evDnf/adPn67rr79e5cuXV+3atfX0008rJSWlSAUDAADXd/78eQ0YMEB33303YRSXVehAGh8fr+joaI0bN05bt27VTTfdpMjISB0/fjzX/WNjYzVixAiNGzdOO3fu1Lx58xQfH69Ro0YVu3gAAOB6Lly4oG7duqlPnz4qV47JWFxeoQPptGnTNGDAAPXr10+NGzfW7NmzZbPZNH/+/Fz337hxo8LDw9WjRw/VrVtXHTp0UPfu3S/bVQUAAO7nwoULSk1N1bRp0xQREWF1OXAThfqzJS0tTVu2bNHIkSOd23x9fdWuXTtt2rQp12Nuu+02LVq0SJs3b1aLFi20f/9+rVy5Ur169crzPKmpqUpNTXU+TkpKkiQ5HA45HA7n9qz/v3gbPAtjXDyX/ry46veRcfYOjLPnO3XqlKZMmaLatWurRYsWjLWHyutnuTjjXahAevLkSWVkZKhatWrZtlerVk27du3K9ZgePXro5MmTioiIkDFG6enpGjx4cL5T9jExMRo/fnyO7WvWrMl1mZqEhITCfBlwQ54yxsaYbH9slbaLr9VevXq1goKCyuzcReEp44z8Mc6ea8mSJeratatOnjyplStXWl0OStmlP8t2u73Iz1XqF3asX79eL7/8smbOnKmWLVtq7969evLJJzVx4kS98MILuR4zcuRIRUdHOx8nJSWpdu3a6tChg0JCQpzbHQ6HEhIS1L59e/n7+5f2lwILeNIYG2PUtm3bPGcTSltkZKTL3mXvSeOMvDHOnuvs2bNatGiR5s+fzxh7gbx+lrNmtIuiUIG0SpUq8vPzU2JiYrbtiYmJql69eq7HvPDCC+rVq5ceffRRSdKNN96o5ORkDRw4UKNHj5avb87LWAMDAxUYGJhju7+/f64v8Ly2w3N4whgnJydbFkbDw8NVqVIll1931BPGGZfHOHuWs2fP6uGHH9aECROc48oYe4dLx7k4Y16oQBoQEKBmzZpp7dq16ty5syQpMzNTa9eu1bBhw3I9xm635widfn5+kv7uGAHeKDExsUy7lTabzeXDKAD343A4dObMGb300ktq3rw514yiyAo9ZR8dHa0+ffqoefPmatGihaZPn67k5GT169dPktS7d2/VqlVLMTExkqROnTpp2rRpuvnmm51T9i+88II6derkDKaAt2GRegDu7syZM4qKitKiRYvUvHlzq8uBmyt0II2KitKJEyc0duxYHTt2TE2bNtWqVaucNzodOnQoW0d0zJgx8vHx0ZgxY/Tnn38qLCxMnTp10qRJk0ruqwAAAGXGGKNHHnlEkyZNUlhYmNXlwAMU6aamYcOG5TlFv379+uwnKFdO48aN07hx44pyKgAA4EJOnz6tnTt3KjY21uVX7oD7KNJbhwIAAO9z6tQpRUVFKSgoiDCKEsX7eQEAgAJZv369XnnlFd18881WlwIPQyAFAAD5+uuvv/Tcc89p3rx5rNiBUsGUPQAAyNPZs2fVrVs3PfXUU4RRlBo6pAAAIFcnT56Uv7+/3n33XdWpU8fqcuDB6JACAIAcTpw4oW7duuno0aOEUZQ6AikAAMjh9ddf1/Tp09WwYUOrS4EXYMoeAAA4HT9+XEuXLtXLL79sdSnwInRIAQCAJCkxMVHdu3fXnXfeaXUp8DJ0SAEAgFJTU3X+/Hm9/fbbatSokdXlwMvQIQUAwMsdPXpUHTt2VFhYGGEUliCQAgDgxTIzMzVgwADNmDFDISEhVpcDL8WUPQAAXurIkSP6/ffftXz5cgUEBFhdDrwYHVIAALzQn3/+qYcfflhVqlQhjMJyBFIAALzQhg0bNGfOHF177bVWlwIQSAEA8CaHDx9W//791bVrV8IoXAbXkAIA4CWOHz+u3r1765133pGPj4/V5QBOBFIAALzA4cOHFRISosWLF6tGjRpWlwNkw5Q9AAAe7vfff1fv3r115swZwihcEh1SoAQYY2S32/PdJzk5uYyqAYDs3n77bc2fP19XX3211aUAuSKQAsVkjFFERIQ2btxodSkAkM3Bgwe1cuVKTZkyxepSgHwxZQ8Uk91uL1QYDQ8Pl81mK8WKAEA6cOCAHnnkEd13331WlwJcFh1SoAQlJiYqODg4331sNht3twIoVXa7XWlpaVq4cCHT9HALBFKgBAUHB182kAJAadq3b58GDRqkzz77TEFBQVaXAxQIU/YAAHgIh8Ohxx9/XAsXLiSMwq3QIQUAwAPs2bNHp0+f1ooVK1SuHL/e4V7okAIA4Ob27NmjQYMGqVatWoRRuCVetQAAuDFjjL7//nstWrRINWvWtLocoEgIpHALxhiXXVjeVesC4Pl2796tqVOnau7cuVaXAhQLgRQuzxijtm3batOmTVaXAgAu49ChQxoyZIgWL15sdSlAsXENKVxeamqqW4RRFrwHUFb27dunypUra+nSpapevbrV5QDFRocUbqUgC89bhQXvAZSFX3/9VY8//rji4uIUFhZmdTlAiSCQwq2w8DwAbzdv3jwtWbKEMAqPQiAFAMAN/Pzzz9q0aZOmTp1qdSlAieMaUgAAXNyOHTv01FNPqXPnzlaXApQKOqQAALiwc+fOqVy5coqLi1OVKlWsLgcoFXRIAQBwUT/++KO6dOmia6+9ljAKj0aHFJYyxshut+f5eYfDoZSUlDKsCABcg91u16hRoxQbG8vbgcLj8QqHZYwxioiI0MaNG60uBQBcyrZt2yRJn376qXx9mcyE5+NVDsvY7fZChVEWngfgDbZu3arnn39ederUIYzCa9AhhUvIa8F7h8Oh1atXKzIyUpUqVWLheQAezRijX3/9VfHx8apcubLV5QBlhkAKl5DXgvcOh0NBQUEKDg4mjALwaD/88IMWLFigGTNmWF0KUOYIpAAAWGzXrl0aPXq04uPjrS4FsAQXpwAAYKFffvlFtWrV0ocffqjQ0FCrywEsQSAFAMAi3333nZ599lkZYxQSEmJ1OYBlCKQAAFjAGKP4+HjFx8cTRuH1uIYUAIAytmnTJu3evVvTpk2zuhTAJdAhBQCgDG3cuFETJ07Ugw8+aHUpgMsgkAIAUEZOnz6t0NBQxcfHq2LFilaXA7gMAikAAGXg66+/Vt++fdWwYUPCKHAJAikAAKXszJkzmjZtmhYvXszbgQK54KYmAABK0f/+9z9VqVJFy5cv5x3ngDzwZxoAAKVk/fr1eu2111S3bl3CKJAPOqQAAJSCzMxM/fnnn4qPj5fNZrO6HMClEUhRaowxstvteX4+OTm5DKsBgLKzdu1arVy5UlOnTrW6FMAtEEhRKowxioiI0MaNG60uBQDK1JYtW/Tmm28qLi7O6lIAt8E1pCgVdru9wGE0PDyc6SwAHuGHH37Q9ddfr7i4OJUvX97qcgC3QYcUpS4xMVHBwcF5ft5ms3GxPwC3t3r1as2ePVtLlixRUFCQ1eUAboVAilIXHBycbyAFAHeXmZmpL774gjAKFBGBFACAYli1apXOnDmjKVOmWF0K4La4hhQAgCL673//q3fffVf//ve/rS4FcGsEUgAAiuDEiROqW7euFi9erMDAQKvLAdwagRQAgEL69NNP9eSTT6phw4aEUaAEEEgBACiEY8eOacmSJVq4cCErhAAlhEAKAEABffbZZzp//rwWL16sgIAAq8sBPAaBFACAAvjoo4+0aNEi1alTh84oUMIIpAAAXEZGRoZSUlL0wQcfyN/f3+pyAI/DOqQAAOTjP//5j7Zv366JEydaXQrgsQikAADk4X//+5+WL1+uhQsXWl0K4NEIpAAA5GLDhg1q1qyZ3nvvPZUrx69LoDRxDSkAAJeIj4/X3LlzFRQURBgFygCBFACAizgcDv3000+aP38+YRQoI/ykoUQYY2S3252Pk5OTLawGAIomNjZWFSpU0KRJk6wuBfAqdEhRbMYYRUREqEKFCs6PatWqWV0WABTKkiVLlJCQoI4dO1pdCuB16JCi2Ox2uzZu3Jjr58LDw2Wz2cq4IgAonCNHjuiWW25R165d5efnZ3U5gNchkKJEJSYmKjg42PnYZrPxjiYAXNr777+vjRs3avbs2VaXAngtAilKVHBwcLZACgCu7MCBA/rmm280c+ZMq0sBvBrXkAIAvNLixYtVrlw5zZkzh2l6wGIEUgCA15k/f76+/vpr1apVy+pSAIhACgDwMunp6QoJCdHMmTPl68uvQcAVcA0pAMBrzJ07V2fOnNHw4cOtLgXARQikAACv8Omnn+rHH3/UW2+9ZXUpAC5BIAUAeLyEhATdeeed6tixI9P0gAvipxIA4NFmzpypFStWyGazEUYBF8VPJgDAY9ntdp0+fVpvvvkmb9IBuDCm7AEAHuntt99Wo0aNNHr0aKtLAXAZdEgBAB5n5syZ2r9/v+68806rSwFQAHRIAQAe5dChQ4qMjNRjjz3GND3gJuiQAgA8xuuvv67Zs2erQYMGhFHAjdAhBQB4hJ9//lmJiYmKiYmxuhQAhUSHFADg9mbNmqWqVatq8uTJdEYBN0SHFADg1l599VWdPn1aYWFhVpcCoIgIpAAAt5WamqqGDRuqU6dOdEYBN0YgBQC4pZdffllXXnmlBg0aZHUpAIqJa0gBAG7ngw8+UEpKigYOHGh1KQBKAB1SAIBbWbFihR566CEFBgYyTQ94CDqkAAC3MWHCBG3btk1BQUGEUcCD0CEFALiFM2fOqFKlSnryySetLgVACaNDCgBwacYYvfjii/rtt98Io4CHIpACAFzapEmT5O/vrxYtWlhdCoBSwpQ9AMAlGWO0b98+9e7dW1dffbXV5QAoRXRIAQAuxxij0aNH65NPPiGMAl6AQAoAcDnfffedQkND9cwzz1hdCoAyQCAFALgMY4wmT56sRo0aafjw4VaXA6CMEEgBAC7BGKPnn39eAQEBqlSpktXlAChD3NQEALCcMUYXLlxQu3bt1KFDB6vLAVDGCKQAAEsZY/TMM8+oZcuWioqKsrocABYgkCJfxhjZ7fZ890lOTi6jagB4ohkzZqhu3bqEUcCLEUiRJ2OMIiIitHHjRqtLAeCBjDH68MMPNXjwYJUrx68jwJsV6aamrL9mg4KC1LJlS23evDnf/c+cOaOhQ4eqRo0aCgwM1HXXXaeVK1cWqWCUHbvdXqgwGh4eLpvNVooVAfAUxhg9+eSTOnHiBGEUQOE7pPHx8YqOjtbs2bPVsmVLTZ8+XZGRkdq9e7eqVq2aY/+0tDS1b99eVatW1bJly1SrVi39/vvvCg0NLYn6UUYSExMVHByc7z42m00+Pj5lVBEAd3b8+HHdfPPN6tevn9WlAHABhQ6k06ZN04ABA5z/iMyePVuff/655s+frxEjRuTYf/78+Tp16pQ2btwof39/SVLdunWLVzXKXHBw8GUDKQBcTmZmpp566ikNHTqUMArAqVBT9mlpadqyZYvatWv3/5/A11ft2rXTpk2bcj1mxYoVatWqlYYOHapq1aqpSZMmevnll5WRkVG8ygEAbmfhwoVq0qSJGjdubHUpAFxIoTqkJ0+eVEZGhqpVq5Zte7Vq1bRr165cj9m/f7/WrVunnj17auXKldq7d6+GDBkih8OhcePG5XpMamqqUlNTnY+TkpIkSQ6HQw6Hw7k96/8v3oaSc+n32orvM2PsHRhnz5eZmalff/1VnTt3VlRUFGPtofhZ9g55jXNxxr3UryTPzMxU1apVNXfuXPn5+alZs2b6888/NWXKlDwDaUxMjMaPH59j+5o1a3K9aSYhIaHE64aUkpLi/P/Vq1crKCjIsloYY+/AOHumzMxMzZkzR9ddd53uuusuxtkLMMbe4dJxvtwykfkpVCCtUqWK/Pz8lJiYmG17YmKiqlevnusxNWrUkL+/v/z8/JzbGjVqpGPHjiktLU0BAQE5jhk5cqSio6Odj5OSklS7dm116NBBISEhzu0Oh0MJCQlq37698/pUlJyL1xeNjIy05BpSxtg7MM6ebe3atXrwwQfVs2dPxtnD8bPsHfIa56wZ7aIoVCANCAhQs2bNtHbtWnXu3FnS33/5rl27VsOGDcv1mPDwcMXGxiozM1O+vn9fsvrbb7+pRo0auYZRSQoMDFRgYGCO7f7+/rm+wPPajuK5+Htq9ffY6vOjbDDOniUzM1Pjxo3TqFGjVL58eed0HuPs+Rhj73DpOBdnzAu9Dml0dLTeeecdvffee9q5c6cee+wxJScnO++W7N27t0aOHOnc/7HHHtOpU6f05JNP6rffftPnn3+ul19+WUOHDi1y0QAA15aRkaGBAwfqmmuuUfny5a0uB4CLK/Q1pFFRUTpx4oTGjh2rY8eOqWnTplq1apXzRqdDhw45O6GSVLt2ba1evVpPP/20/vGPf6hWrVp68skn9fzzz5fcVwEAcBkZGRm6cOGC+vTpo9atW1tdDgA3UKSbmoYNG5bnFP369etzbGvVqpW+/fbbopwKAOBGMjIy9OijjyoqKkp333231eUAcBNFeutQAABy8+qrr6pdu3aEUQCFwhsIAwCKLT09XfHx8Ro+fHi2VVUAoCDokAIAiiU9PV2PPPKI/Pz8CKMAioQOKQCgyIwxOnr0qO6//349+OCDVpcDwE3RIYWTMUbJycnZPgAgL+np6erTp48yMzMJowCKhQ4pJP0dRiMiIrRx40arSwHgJgYNGqR//etfqlOnjtWlAHBzBFJI+vv9Z/MKo+Hh4bLZbGVcEQBX5XA49Ntvv2ny5MkKCwuzuhwAHoBAihwSExOzvW+9zWaTj4+PhRUBcBUOh0O9e/dWVFSUbrjhBqvLAeAhCKTIITg4OFsgBYAsK1euVFRUlDp37mx1KQA8CIEUAHBZaWlpGjVqlCZPnqxy5fjVAaBkcZc9ACBfaWlpevjhh9WmTRvCKIBSwb8sAIA8paamKi0tTc8995xuvfVWq8sB4KHokAIAcpWamqqePXvqp59+IowCKFUEUgBAriZOnKhHHnlE4eHhVpcCwMMxZQ8AyCYlJUXx8fGaOHEiS74BKBN0SAEATikpKerevbuqV69OGAVQZuiQAgAk/f0WwocPH9aQIUPUvn17q8sB4EXokAIAdOHCBXXp0kUhISGEUQBljkAKAF7OGKM+ffpoyJAhqlq1qtXlAPBCTNkDgBez2+3at2+f5s6dq9DQUKvLAeCl6JACgJdKTk5WVFSUTp48SRgFYCk6pADgpT799FM988wzatu2rdWlAPByBFI3ZoyR3W4vkedKTk4ukecB4PqSk5M1evRoTZs2Tb6+TJQBsB6B1E0ZYxQREaGNGzdaXQoAN5I1Tf/8888TRgG4DAKpm7Lb7aUSRsPDw2Wz2Ur8eQFY7/z585KkmJgY3XjjjRZXAwD/H4HUAyQmJio4OLhEnstms/HuLIAHOnfunKKiohQTE6ObbrrJ6nIAIBsCqQcIDg4usUAKwDONHz9eY8aMIYwCcEkEUgDwYElJSVq+fLmmTJnC7AcAl8UV7QDgoc6ePauuXbuqYcOGhFEALo0OKQB4oMzMTP35558aP368WrZsaXU5AJAvOqRuwhij5OTkbB8AkJszZ86oU6dOqlWrFmEUgFugQ+oGWHMUQEFlZmbq4Ycf1osvvqhKlSpZXQ4AFAiB1A3kt+Yo64YCyHL69Gn98ccfWrJkiSpWrGh1OQBQYEzZu5nExESdP3/e+fH1119zswIAnT59WlFRUUpPTyeMAnA7dEjdDGuOAsjNihUrNHnyZN1yyy1WlwIAhUYgBQA3durUKb344ot64403mC0B4LaYsgcAN3X69Gl169ZN/fv3J4wCcGt0SAHADZ06dUr+/v6aMWOGrr32WqvLAYBioUMKAG7m5MmT6tq1q44dO0YYBeAR6JBazBgju92e7z4sgg/gYuPHj9frr79OGAXgMQikFmLBewCFcfz4ca1cuVJvvvkm14wC8ChM2VsovwXvc8Mi+ID3On78uLp3764WLVoQRgF4HDqkLiIxMfGy64vabDZ+EQFeKD09XUePHtVbb72lxo0bW10OAJQ4AqmLYMF7ALk5duyY+vTpo48//ljly5e3uhwAKBVM2QOAi3I4HOrTp4/eeOMNwigAj0aHFABc0NGjR/XXX3/po48+4tpxAB6PDikAuJgjR46oZ8+eCggIIIwC8Ap0SAHAxaxcuVJz5sxhnVEAXoNAWoYuXQSfBe8BXOzPP//Uq6++qjfeeMPqUgCgTBFIywiL4APIz9GjR9WrVy/NnTvX6lIAoMwRSMtIfovgs+A94N2OHTumChUqaOHChbr66qutLgcAyhw3NVkgMTFR58+fd358/fXXLHgPeKlDhw6pe/fuSkpKIowC8Fp0SC3AIvgAssTExGj+/PmqVauW1aUAgGUIpABggd9//11fffWVZs2aZXUpAGA5puwBoIwdPHhQ/fr10+233251KQDgEgikAFCG0tLS9Ndff2nBggWqU6eO1eUAgEsgkAJAGdm/f7/+9a9/6R//+AdhFAAuwjWkpYRF8AFc7MKFCxo0aJDmz58vf39/q8sBAJdCIC0FLIIP4GJ79+6Vw+HQZ599psDAQKvLAQCXw5R9KWARfABZ9u7dq0GDBikkJIQwCgB5oENayhITE7OtOWqz2VgEH/Aia9eu1fvvv886owCQDwJpKWMRfMA7/fbbb5ozZ46mTp1qdSkA4PIIpABQwvbv36/HHntMixYtsroUAHALBFIAKEGHDh1SWFiYYmNjVa1aNavLAQC3wE1NAFBCdu7cqX79+iktLY0wCgCFQIe0BLDmKABjjF5//XXFxsbqyiuvtLocAHArBNJiYs1RAL/88ot++uknzZ071+pSAMAtMWVfTKw5Cni3n3/+WU8++aTatWtndSkA4LbokJYg1hwFvEtKSorsdruWLFmisLAwq8sBALdFh7QEZa05mvVBGAU8108//aQuXbqoefPmhFEAKCY6pABQSGfPntVzzz2n2NhY+frydz0AFBeBFAAKYfv27QoODtZnn30mf39/q8sBAI/An/YAUEDbtm3T8OHDdeWVVxJGAaAEEUgBoIC+++47xcXF6YorrrC6FADwKEzZA8BlbNmyRR9++KEmT55sdSkA4JEIpACQj59//lmjRo1SfHy81aUAgMdiyh4A8rBnzx5dffXVio+PV2hoqNXlAIDHIpACQC42b96sYcOGycfHhzAKAKWMQAoAl8jMzNS8efO0dOlSVaxY0epyAMDjcQ0pAFzk22+/1Z9//qk5c+ZYXQoAeA06pADwfzZt2qQJEyaoffv2VpcCAF6FDikASEpOTpafn5/i4+OZpgeAMkaHFIDX27Bhg/r06aNbb72VMAoAFqBDehnGGNnt9jw/n5ycXIbVAChpx48f1yuvvKIlS5bIx8fH6nIAwCsRSPNhjFFERIQ2btxodSkASsGGDRt01VVX6eOPP5afn5/V5QCA12LKPh92u73AYTQ8PFw2m62UKwJQUv73v//plVdeUVhYGGEUACxGh7SAEhMTFRwcnOfnbTYb032AmzDGaOfOnYqLi8v35xoAUDYIpAUUHBzMLy7AA3z55Zdav369xo8fb3UpAID/QyAF4DW+/fZbTZ8+XUuWLLG6FADARbiGFIBX+Pnnn9WoUSMtWbKE670BwMUQSAF4vISEBL3wwgsKDAwkjAKACyKQAvBo6enp+vjjj7VkyRIFBQVZXQ4AIBdcQwrAY61evVoOh0MzZsywuhQAQD7okALwSKtWrdLcuXPVrl07q0sBAFwGHVIAHicpKUlXXnmlYmNjFRgYaHU5AIDLoEMKwKN89tlnevzxx3XrrbcSRgHATdAhBeAxfv/9d73//vv64IMPrC4FAFAIdEgBeIT//ve/KleunOLi4uiMAoCbIZACcHuffPKJ3nvvPYWFhcnXl3/WAMDd8C83ALdmjFFiYqLef/99BQQEWF0OAKAIuIYUgNtavny5fvvtN40YMcLqUgAAxUAgBeCWEhIStGzZMr333ntWlwIAKCYCKQC3s2XLFrVo0UJt27aVv7+/1eUAAIqJa0gBuJWlS5fq9ddfV3BwMGEUADwEgRSA27hw4YK+/fZbLVy4UOXKMcEDAJ6Cf9EBuIW4uDhVrVpV06ZNs7oUAEAJo0MKwOUtWbJEq1at0u233251KQCAUkCHFIBLO3XqlBo2bKiuXbvKz8/P6nIAAKWAQArAZX3wwQf67rvv9Pbbb1tdCgCgFBFIAbikX3/9VevXr9fcuXOtLgUAUMqKdA3pjBkzVLduXQUFBally5bavHlzgY6Li4uTj4+POnfuXJTTAvASH374ocLCwvTuu+8yTQ8AXqDQgTQ+Pl7R0dEaN26ctm7dqptuukmRkZE6fvx4vscdPHhQzz77rFq3bl3kYgF4vgULFighIUFXXnmlfHx8rC4HAFAGCh1Ip02bpgEDBqhfv35q3LixZs+eLZvNpvnz5+d5TEZGhnr27Knx48erfv36xSoYgOfKzMyUJM2ePVu+viwCAgDeolD/4qelpWnLli1q167d/38CX1+1a9dOmzZtyvO4CRMmqGrVqurfv3/RKwXg0RISEjRr1iz169ePMAoAXqZQNzWdPHlSGRkZqlatWrbt1apV065du3I9ZsOGDZo3b562b99e4POkpqYqNTXV+TgpKUmS5HA45HA4nNuz/v/ibSXp0nOV1nmQt9IeY7iGpUuXat++fZo8eTJj7cH4efZ8jLF3yGucizPupXqX/blz59SrVy+98847qlKlSoGPi4mJ0fjx43NsX7NmjWw2W47tCQkJxaozLykpKc7/X716tYKCgkrlPLi80hpjWG/Xrl26+uqrNXDgQK1du9bqclAG+Hn2fIyxd7h0nO12e5Gfy8cYYwq6c1pammw2m5YtW5btTvk+ffrozJkz+uSTT7Ltv337dt18883Z7pLNukbM19dXu3fvVoMGDXKcJ7cOae3atXXy5EmFhIQ4tzscDiUkJKh9+/by9/cv6JdRYMnJyapcubIk6fTp0woODi7xcyB/pT3GsNbcuXP1yy+/aMqUKfriiy8YZw/Hz7PnY4y9Q17jnJSUpCpVqujs2bPZ8lpBFKpDGhAQoGbNmmnt2rXOQJqZmam1a9dq2LBhOfZv2LChduzYkW3bmDFjdO7cOb3xxhuqXbt2rucJDAxUYGBgju3+/v65vsDz2l5cFz9naZ0DBcP33/OcPXtWR48e1YwZM5Seni6JcfYWjLPnY4y9w6XjXJwxL/SUfXR0tPr06aPmzZurRYsWmj59upKTk9WvXz9JUu/evVWrVi3FxMQoKChITZo0yXZ8aGioJOXYDsB7zJw5U82aNdNLL71kdSkAABdQ6EAaFRWlEydOaOzYsTp27JiaNm2qVatWOW90OnToEHfIAsjTjBkztGfPHj322GNWlwIAcBFFuqlp2LBhuU7RS9L69evzPXbhwoVFOSUAD3D8+HG1bt1aQ4YMYdF7AIAT72UPoExMnz5dJ0+eZJoeAJADgRRAqdu8ebMOHz6sKVOmWF0KAMAFcbEngFI1b948XX/99ZoyZQrT9ACAXNEhBVBqpkyZor/++kshISGEUQBAngikAEpFenq6atasqWeffZYwCgDIF4EUQImbPHmyatSooT59+lhdCgDADRBIL2KMyfY+rMnJyRZWA7inefPmKTk5Wb1797a6FACAmyCQ/h9jjCIiIrRx40arSwHc1rp169StWzfZbDam6QEABUYg/T92uz3PMBoeHi6bzVbGFQHuZeLEicrIyNCdd95pdSkAADdDIM1FYmKigoODnY/p9gD5O378uAIDAzV8+HCrSwEAuCHWIc1FcHBwtg/CKJC3CRMm6Pjx44RRAECREUgBFNmECRPk6+urJk2aWF0KAMCNMWUPoNCMMTp69Ki6du2qhg0bWl0OAMDN0SEFUCjGGL3wwguKi4sjjAIASgSBFEChrF27VhUqVFB0dLTVpQAAPART9gAKxBijN954Q4MGDVK7du2sLgcA4EHokAK4LGOMRowYofT0dJUvX97qcgAAHoYOKYB8GWOUmpqqVq1aqXPnzlaXAwDwQARSAHkyxui5555TREQEYRQAUGqYsgeQp2nTpql27dqEUQBAqaJDCiAHY4xWrVqloUOHKigoyOpyAAAejg4pgGyMMXrqqae0b98+wigAoEzQIQWQzaFDh3TDDTdo4MCBVpcCAPASdEgBSPq7M/r0008rMzOTMAoAKFMEUgCSpKefflrXX3+96tWrZ3UpAAAvw5Q94OUyMzN1+PBhPfHEE6pfv77V5QAAvBAdUsCLZWZmaujQoVq3bh1hFABgGQIp4MVWrFihZs2aqW/fvlaXAgDwYkzZA14oMzNTMTExGj58uPz9/a0uBwDg5eiQAl4mMzNTgwYNUq1atQijAACXQIcU8CIZGRlKSUlRly5dFBkZaXU5AABIokMKeI2MjAwNGDBAmzdvJowCAFwKgRTwEuPHj9edd96pO+64w+pSAADIhil7wMNlZGTo888/15gxYxQQEGB1OQAA5ECHFPBg6enpeuSRR5ScnEwYBQC4LDqkgAfbt2+fOnbsqK5du1pdCgAAeaJDCnig9PR09e/fX5UqVSKMAgBcHoEU8DDGGPXv31933323qlevbnU5AABcFlP2gAdxOBw6fPiwXnrpJdWuXdvqcgAAKBA6pICHcDgc6t27t3788UfCKADArRBIAQ+xdOlSPfTQQ+rcubPVpQAAUCheO2VvjJHdbnc+Tk5OtrAaoOjS0tI0adIkjRs3Tr6+/I0JAHA/XvnbyxijiIgIVahQwflRrVo1q8sCCi0tLU29evXSLbfcQhgFALgtr+yQ2u12bdy4MdfPhYeHy2azlXFFQOGlpaUpNTVVw4YNU+vWra0uBwCAIvP6lkpiYqLOnz/v/Pj666/l4+NjdVlAvlJTU9WzZ0/t2rWLMAoAcHte2SG9WHBwsIKDg60uAyiUUaNGqW/fvrr11lutLgUAgGLz+kAKuJOUlBStXLlSr7zyisqV48cXAOAZvH7KHnAXKSkp6tGjh2w2G2EUAOBR+K0GuInffvtNgwYNUmRkpNWlAABQouiQAi7uwoUL6tatm66++mrCKADAIxFIAReWmZmpnj17qn///goNDbW6HAAASgVT9oCLstvtOnbsmGbOnKnq1atbXQ4AAKWGDinggux2u7p3767ff/+dMAoA8HgEUsAFxcbG6sknn9Qdd9xhdSkAAJQ6puwBF5KcnKyXX35ZL730Eu8YBgDwGnRIAReRnJysqKgodejQgTAKAPAqdEgBF2C325WRkaEXX3xRzZs3t7ocAADKFB1SwGLnz5/XQw89pD///JMwCgDwSgRSwGLPPfecRo0apUaNGlldCgAAlmDKHrDIuXPntGbNGs2YMUO+vvxtCADwXvwWBCyQlJSkrl27qmbNmoRRAIDXo0MKlDFjjHbt2qVx48bpn//8p9XlAABgOVozQBk6e/asHnjgATVp0oQwCgDA/yGQAmUkPT1d3bp108iRI2Wz2awuBwAAl8GUPVAGzpw5o1OnTumDDz5QlSpVrC4HAACXQocUKGWnT59W165dderUKcIoAAC5oEMKlLIlS5YoJiZGzZo1s7oUAABcEoEUKCWnTp3S1KlTNWnSJKtLAQDApTFlD5SCU6dOqVu3burSpYvVpQAA4PLokAIlLCkpSX5+fpo+fboaN25sdTkAALg8OqRACTp58qQeeOABnT59mjAKAEABEUiBEjR8+HBNmzZNdevWtboUAADcBlP2QAk4ceKEvvrqK82bN08+Pj5WlwMAgFuhQwoU0/Hjx9WtWzddf/31hFEAAIqADilQDMYY/fbbb3rzzTd1ww03WF0OAABuiQ4pUESJiYm6//771bJlS8IoAADFQIcUKIKUlBT17NlTb731lvz9/a0uBwAAt0YgBQrp6NGjSk1N1bJlyxQaGmp1OQAAuD2m7IFCOHr0qHr27KnU1FTCKAAAJYRAChRCfHy8Zs2apeuvv97qUgAA8BhM2QMF8Oeff2rWrFl66aWXrC4FAACPQ4cUuIwjR46od+/e6tu3r9WlAADgkeiQAvn466+/VL58eb3zzjuqX7++1eUAAOCR6JACefjjjz/00EMPKS0tjTAKAEApIpACuTDGaNSoUXr33XdVrVo1q8sBAMCjMWUPXOL333/X1q1b9f777/Pe9AAAlAE6pMBFDh48qH79+unmm28mjAIAUEYIpMD/ycjI0MGDBzV//nzVrVvX6nIAAPAaBFJA0oEDB/TAAw/o9ttvJ4wCAFDGuIYUXi8pKUn9+/fXwoUL5evL32gAAJQ1Aim82r59+xQQEKAVK1aoQoUKVpcDAIBXoh0Er7V3714NHDhQvr6+hFEAACxEIIXX+uSTT/T++++rVq1aVpcCAIBX84ope2OM7Ha783FycrKF1cBqe/bs0aJFizR+/HirSwEAAPKCQGqMUUREhDZu3Gh1KXABe/fu1eDBg/XBBx9YXQoAAPg/Hh9I7XZ7nmE0PDxcNputjCuCVY4dO6YrrrhCixYtUo0aNawuBwAA/B+vuoY0MTFR58+fd358/fXXvBuPl9i1a5d69OghX19fwigAAC7G4zukFwsODlZwcLDVZaCMGWM0ceJExcbGKjQ01OpyAADAJbwqkML7/Prrr9q3b58WL15sdSkAACAPXjVlD+/yyy+/6IknnlDLli2tLgUAAOSDQAqPlJ6ersTERMXGxqpq1apWlwMAAPJBIIXH2bFjh7p166Y77riDMAoAgBvgGlJ4lBMnTig6OlpLlixhBQUAANwEHVJ4jB07dsjhcGjFihWqUqWK1eUAAIACIpDCI2zfvl3PPPOMAgMDVb58eavLAQAAhcCUPTxCQkKC4uLidMUVV1hdCgAAKCQCKdza1q1btXLlSo0ZM8bqUgAAQBERSOG2fvzxR40cOVJxcXFWlwIAAIqBa0jhlv744w/VrFlTcXFxqly5stXlAACAYiCQwu18//33evTRRxUcHEwYBQDAAxQpkM6YMUN169ZVUFCQWrZsqc2bN+e57zvvvKPWrVurcuXKqly5stq1a5fv/kB+0tPT9cYbb2jp0qWy2WxWlwMAAEpAoQNpfHy8oqOjNW7cOG3dulU33XSTIiMjdfz48Vz3X79+vbp3764vv/xSmzZtUu3atdWhQwf9+eefxS4e3uW7777T2rVrtWjRIlWqVMnqcgAAQAkpdCCdNm2aBgwYoH79+qlx48aaPXu2bDab5s+fn+v+ixcv1pAhQ9S0aVM1bNhQ7777rjIzM7V27dpiFw/v8d133+nFF19Uq1atrC4FAACUsELdZZ+WlqYtW7Zo5MiRzm2+vr5q166dNm3aVKDnsNvtcjgc+a4XmZqaqtTUVOfjpKQkSZLD4ZDD4XBuz/r/i7dd6tL989sXridrzM6ePatFixapfPnyjKEHKsjPMtwf4+z5GGPvkNc4F2fcCxVIT548qYyMDFWrVi3b9mrVqmnXrl0Feo7nn39eNWvWVLt27fLcJyYmRuPHj8+xfc2aNbleN5iQkJDnc6WkpDj/f/Xq1QoKCipQnXANu3bt0sqVKxUdHa0NGzZYXQ5KWX4/y/AcjLPnY4y9w6XjbLfbi/xcZboO6eTJkxUXF6f169fnGwxHjhyp6Oho5+OkpCTntachISHO7Q6HQwkJCWrfvr38/f1zfa7k5GTn/0dGRio4OLgEvhKUhUOHDmnWrFl67LHH8h1juL+C/CzD/THOno8x9g55jXPWjHZRFCqQVqlSRX5+fkpMTMy2PTExUdWrV8/32Ndee02TJ0/WF198oX/84x/57hsYGKjAwMAc2/39/XN9gee1PetzBdkPruXbb79V/fr1tWzZMq1du5ax8xKMs3dgnD0fY+wdLh3n4ox5oW5qCggIULNmzbLdkJR1g1J+N5u8+uqrmjhxolatWqXmzZsXuVh4h6+++kqTJk1ScHBwrn+YAAAAz1LoKfvo6Gj16dNHzZs3V4sWLTR9+nQlJyerX79+kqTevXurVq1aiomJkSS98sorGjt2rGJjY1W3bl0dO3ZMklShQgVVqFChBL8UeIrNmzcrLi5OwcHBXBgPAIAXKHQgjYqK0okTJzR27FgdO3ZMTZs21apVq5w3Oh06dEi+vv+/8Tpr1iylpaWpS5cu2Z5n3LhxevHFF4tXPTzK+vXr9f333+u5556zuhQAAFCGinRT07BhwzRs2LBcP7d+/fpsjw8ePFiUU8DLbNiwQdOmTVNcXJzVpQAAgDLGe9nDcvv27dP111+vuLg43g4UAAAvRCCFpb744gtFR0crNDSUMAoAgJcikMIyKSkpio2NVVxcHMuDAADgxcp0YXwgy5o1axQYGKj58+dbXQoAALAYHVKUudWrV2v27Nlq2bKl1aUAAAAXQCBFmUpJSVFAQIBiY2PzfftYAADgPZiyR5lZuXKlPv74Y82dO9fqUgAAgAshkKJM7Nq1SwsWLNCiRYusLgUAALgYpuxR6tauXauwsDAtWbKE96YHAAA5EEhRqlasWKE5c+aoYsWKKleOhjwAAMiJQIpSY4zR3r17tWjRIgUEBFhdDgAAcFG0rFAqPv74Y/3xxx+Kjo62uhQAAODiCKQocStXrlR8fLzef/99q0sBAABugECKErVz507deuutat++PW8HCgAACoRrSFFili1bppdeeklXXnklYRQAABQYgRQlIikpSevWrdN7770nX19eVgAAoOCYskexxcfHq169epo5c6bVpQAAADdEKwvFEhcXp88//1y33HKL1aUAAAA3RSBFkZ0/f141a9bU/PnzWfQeAAAUGSkCRbJo0SJt3bpV06ZNs7oUAADg5gikKLQffvhB69at0zvvvGN1KQAAwAMwZY9C+eSTT3TttdfqnXfekZ+fn9XlAAAAD0AgRYEtXLhQn332mSpWrEgYBQAAJYZAigLJzMxUUlKS5syZwzqjAACgRHENKS5r/vz5kqQnnnjC4koAAIAnotWFfC1ZskSbN29W3759rS4FAAB4KDqkyNOPP/6o9u3bKyoqiml6AABQakgZyNWcOXM0d+5cXXnllYRRAABQqkgayOHEiRPat2+f3n77bfn4+FhdDgAA8HAEUmQze/ZsHTt2TK+++iphFAAAlAkCKZxmzJihnTt3qkmTJlaXAgAAvAg3NUGSdPbsWd1yyy0aMmQInVEAAFCmCKTQG2+8oTNnzmjcuHFWlwIAALwQgdTLffnllzp06JBee+01q0sBAABeikDqxRYvXqzOnTurbdu2TNMDAADLcFOTl5o6dap+/PFH2Ww2wigAALAUHVIv5HA4FBISoujoaMIoAACwHIHUy7z66quqV6+eBgwYYHUpAAAAkpiy9yqzZs3S2bNn1aVLF6tLAQAAcKJD6iW+//57devWTaGhoUzTAwAAl0KH1AtMmjRJK1asUOXKlQmjAADA5RBIPdyhQ4ckSRMmTLC4EgAAgNwRSD1YTEyM0tPTNXr0aDqjAADAZXENqYcaP368fHx8VL9+fatLAQAAyBeB1MMYY3Tq1Cndd999atasmdXlAAAAXBaB1IMYYzR27FiFhYXpiSeesLocAACAAuEaUg+yYsUK2Ww2wigAAHArdEg9gDFGc+fOVb9+/XT//fdbXQ4AAECh0CF1c8YYjRw5UklJSQoICLC6HAAAgEKjQ+rGjDFKSUnRjTfeqJ49e1pdDgAAQJHQIXVTxhg9//zz+uqrrwijAADArRFI3VRMTIxq1KihyMhIq0sBAAAoFqbs3YwxRt98842GDRumkJAQq8sBAAAoNjqkbsQYo+joaG3dupUwCgAAPAYdUjfy22+/6dprr9WQIUOsLgUAAKDE0CF1A8YYDR8+XCEhIYRRAADgcQikLs4YoyeffFL16tVTjRo1rC4HAACgxDFl78IyMzN18uRJDRw4UE2aNLG6HAAAgFJBh9RFZWZmatiwYVq9ejVhFAAAeDQCqYuKjY3VzTffrF69elldCgAAQKnyuCl7Y4zsdrvzcXJysoXVFF5mZqbefPNNPfHEE/L15e8FAADg+Twq8RhjFBERoQoVKjg/qlWrZnVZBZaZmanBgwcrJCSEMAoAALyGR3VI7Xa7Nm7cmOvnwsPDZbPZyriigsvMzFRycrI6duyo+++/3+pyAAAAyoxHBdKLJSYmKjg42PnYZrPJx8fHworylpGRoUGDBql///6EUQAA4HU8NpAGBwdnC6SubNSoUWrTpo1atWpldSkAAABlzmMDqTvIyMjQV199pXHjxrn05QQAAACliTtnLJKRkaFHH31UR44cIYwCAACvRofUIjt27FCHDh3UvXt3q0sBAACwFB3SMpaenq7HHntMderUIYwCAACIQFqmjDHq16+f2rZtq8qVK1tdDgAAgEtgyr6MpKen6+TJkxozZoyuv/56q8sBAABwGXRIy4DD4VCfPn30/fffE0YBAAAuQSAtA/Pnz9cDDzygTp06WV0KAACAy2HKvhQ5HA69/vrreu6551z2XaIAAACsRoe0lKSlpalXr1667rrrCKMAAAD5oENaChwOh+x2ux599FG1a9fO6nIAAABcGh3SEpaWlqaePXvqjz/+IIwCAAAUgFt3SI0xSklJUXJysvz9/ZWcnGx1SXr66afVu3dv3XjjjVaXAgAA4BbcNpAaY9S2bVtt2rTJ6lIkSampqfrqq680depUBQUFWV0OAACA23DbKXu73Z5nGA0PD5fNZiuzWlJTU9WzZ0+lp6cTRgEAAArJbTukFzt8+LBCQ0Odj202W5ne2b5lyxY9+uijuvvuu8vsnAAAAJ7CIwJpcHCwgoODy/y8KSkpGjx4sGbMmGHJ+QEAADyB207ZWy09PV3du3dXjx49CKMAAADF4BEd0rJ24cIFnT17VtOmTVO9evWsLgcAAMCt0SEtJLvdrm7dumn37t2EUQAAgBJAIC2kuXPn6oknnlCbNm2sLgUAAMAjMGVfQMnJyXrzzTc1cuRIq0sBAADwKHRICyA5OVndunVTq1atrC4FAADA49AhvYzU1FSlpKRo1KhRBFIAAIBSQIc0H+fPn9eDDz6os2fPEkYBAABKCYE0H8OGDdOIESNUv359q0sBAADwWEzZ5+LcuXPatGmT3nnnHfn7+1tdDgAAgEejQ3qJc+fOKSoqShUqVCCMAgAAlAE6pJf4/vvv9cILL3DNKAAAQBkhkP6fpKQkDR48WAsXLlRAQIDV5QAAAHgNpuwlpaSkqGvXrnrqqacIowAAAGXM6zukZ86cUWpqqubNm6datWpZXQ4AAIDX8eoO6ZkzZxQVFaU///yTMAoAAGARrw6kc+bM0aRJk3TLLbdYXQoAAIDX8sop+9OnT2v27NkaOXKk1aUAAAB4Pa/rkJ46dUpRUVGKjIy0uhQAAADIyzqkdrtd6enpmjJlim666SarywEAAIC8qEP6119/6f7771dGRgZhFAAAwIV4TSAdOnSoXnvtNdWoUcPqUgAAAHARj5+yP3nypLZu3apFixapXDmP/3IBAADcjkd3SE+cOKFu3bqpZs2ahFEAAAAX5bGB1BijLVu2aPr06WrSpInV5QAAACAPHhlIjx8/rm7duql9+/aEUQAAABfncfPY586dU48ePfTmm2/Kz8/P6nIAAABwGR4VSI8dOyY/Pz8tXrxY1apVs7ocAAAAFECRpuxnzJihunXrKigoSC1bttTmzZvz3f/DDz9Uw4YNFRQUpBtvvFErV64sUrH5OXr0qHr27KnTp08TRgEAANxIoQNpfHy8oqOjNW7cOG3dulU33XSTIiMjdfz48Vz337hxo7p3767+/ftr27Zt6ty5szp37qyff/652MVfbN68eZo5c6auu+66En1eAAAAlK5CB9Jp06ZpwIAB6tevnxo3bqzZs2fLZrNp/vz5ue7/xhtv6O6779Zzzz2nRo0aaeLEibrlllv09ttvF7v4LK+//rrGjBmj66+/vsSeEwAAAGWjUNeQpqWlacuWLRo5cqRzm6+vr9q1a6dNmzblesymTZsUHR2dbVtkZKQ+/vjjPM+Tmpqq1NRU5+OkpCRJksPhkMPhcP5/lnvvvTfbY3iO3MYbnodx9g6Ms+djjL1DXuNcnHEvVCA9efKkMjIyclyjWa1aNe3atSvXY44dO5br/seOHcvzPDExMRo/fnyO7WvWrJHNZpMkpaSkOLcfPHgw3+eD+0tISLC6BJQBxtk7MM6ejzH2DpeOs91uL/JzueRd9iNHjszWVU1KSlLt2rXVoUMHhYSESPp74fvjx49r3bp1uu+++xQQEGBVuShFDodDCQkJat++vfz9/a0uB6WEcfYOjLPnY4y9Q17jnDWjXRSFCqRVqlSRn5+fEhMTs21PTExU9erVcz2mevXqhdpfkgIDAxUYGJhju7+/f7YvPDQ0VEFBQQoICOCF7+EuHXt4JsbZOzDOno8x9g6XjnNxxrxQNzUFBASoWbNmWrt2rXNbZmam1q5dq1atWuV6TKtWrbLtL/3d4s1rfwAAAHiXQk/ZR0dHq0+fPmrevLlatGih6dOnKzk5Wf369ZMk9e7dW7Vq1VJMTIwk6cknn1SbNm00depUdezYUXFxcfrhhx80d+7ckv1KAAAA4JYKHUijoqJ04sQJjR07VseOHVPTpk21atUq541Lhw4dkq/v/2+83nbbbYqNjdWYMWM0atQoXXvttfr4448L9R7zxhhJOa9NcDgcstvtSkpKYmrAQzHG3oFx9g6Ms+djjL1DXuOcldOyclth+JiiHFXGDh8+rNq1a1tdBgAAAC7jjz/+0FVXXVWoY9wikGZmZurIkSOqWLGifHx8nNuz7r7/448/nHffw7Mwxt6BcfYOjLPnY4y9Q17jbIzRuXPnVLNmzWyz5QXhkss+XcrX1zffpB0SEsIL38Mxxt6BcfYOjLPnY4y9Q27jXKlSpSI9V6HfOhQAAAAoSQRSAAAAWMqtA2lgYKDGjRuX6yL68AyMsXdgnL0D4+z5GGPvUBrj7BY3NQEAAMBzuXWHFAAAAO6PQAoAAABLEUgBAABgKQIpAAAALOXygXTGjBmqW7eugoKC1LJlS23evDnf/T/88EM1bNhQQUFBuvHGG7Vy5coyqhRFVZgxfuedd9S6dWtVrlxZlStXVrt27S77moBrKOzPcpa4uDj5+Pioc+fOpVsgiq2wY3zmzBkNHTpUNWrUUGBgoK677jr+zXYDhR3n6dOn6/rrr1f58uVVu3ZtPf3000pJSSmjalFYX331lTp16qSaNWvKx8dHH3/88WWPWb9+vW655RYFBgbqmmuu0cKFCwt/YuPC4uLiTEBAgJk/f7755ZdfzIABA0xoaKhJTEzMdf9vvvnG+Pn5mVdffdX8+uuvZsyYMcbf39/s2LGjjCtHQRV2jHv06GFmzJhhtm3bZnbu3Gn69u1rKlWqZA4fPlzGlaMwCjvOWQ4cOGBq1aplWrdube6///6yKRZFUtgxTk1NNc2bNzf33nuv2bBhgzlw4IBZv3692b59exlXjsIo7DgvXrzYBAYGmsWLF5sDBw6Y1atXmxo1apinn366jCtHQa1cudKMHj3aLF++3EgyH330Ub7779+/39hsNhMdHW1+/fVX89Zbbxk/Pz+zatWqQp3XpQNpixYtzNChQ52PMzIyTM2aNU1MTEyu+3ft2tV07Ngx27aWLVuaQYMGlWqdKLrCjvGl0tPTTcWKFc17771XWiWiBBRlnNPT081tt91m3n33XdOnTx8CqYsr7BjPmjXL1K9f36SlpZVViSgBhR3noUOHmjvvvDPbtujoaBMeHl6qdaJkFCSQDh8+3Nxwww3ZtkVFRZnIyMhCnctlp+zT0tK0ZcsWtWvXzrnN19dX7dq106ZNm3I9ZtOmTdn2l6TIyMg894e1ijLGl7Lb7XI4HLriiitKq0wUU1HHecKECapatar69+9fFmWiGIoyxitWrFCrVq00dOhQVatWTU2aNNHLL7+sjIyMsiobhVSUcb7tttu0ZcsW57T+/v37tXLlSt17771lUjNKX0llr3IlWVRJOnnypDIyMlStWrVs26tVq6Zdu3blesyxY8dy3f/YsWOlVieKrihjfKnnn39eNWvWzPHDANdRlHHesGGD5s2bp+3bt5dBhSiuoozx/v37tW7dOvXs2VMrV67U3r17NWTIEDkcDo0bN64sykYhFWWce/TooZMnTyoiIkLGGKWnp2vw4MEaNWpUWZSMMpBX9kpKStKFCxdUvnz5Aj2Py3ZIgcuZPHmy4uLi9NFHHykoKMjqclBCzp07p169eumdd95RlSpVrC4HpSQzM1NVq1bV3Llz1axZM0VFRWn06NGaPXu21aWhBK1fv14vv/yyZs6cqa1bt2r58uX6/PPPNXHiRKtLg4tx2Q5plSpV5Ofnp8TExGzbExMTVb169VyPqV69eqH2h7WKMsZZXnvtNU2ePFlffPGF/vGPf5RmmSimwo7zvn37dPDgQXXq1Mm5LTMzU5JUrlw57d69Ww0aNCjdolEoRflZrlGjhvz9/eXn5+fc1qhRIx07dkxpaWkKCAgo1ZpReEUZ5xdeeEG9evXSo48+Kkm68cYblZycrIEDB2r06NHy9aUv5u7yyl4hISEF7o5KLtwhDQgIULNmzbR27VrntszMTK1du1atWrXK9ZhWrVpl21+SEhIS8twf1irKGEvSq6++qokTJ2rVqlVq3rx5WZSKYijsODds2FA7duzQ9u3bnR//+te/dMcdd2j79u2qXbt2WZaPAijKz3J4eLj27t3r/GNDkn777TfVqFGDMOqiijLOdrs9R+jM+iPk73tm4O5KLHsV7n6rshUXF2cCAwPNwoULza+//moGDhxoQkNDzbFjx4wxxvTq1cuMGDHCuf8333xjypUrZ1577TWzc+dOM27cOJZ9cnGFHePJkyebgIAAs2zZMnP06FHnx7lz56z6ElAAhR3nS3GXvesr7BgfOnTIVKxY0QwbNszs3r3bfPbZZ6Zq1armpZdesupLQAEUdpzHjRtnKlasaJYsWWL2799v1qxZYxo0aGC6du1q1ZeAyzh37pzZtm2b2bZtm5Fkpk2bZrZt22Z+//13Y4wxI0aMML169XLun7Xs03PPPWd27txpZsyY4XnLPhljzFtvvWWuvvpqExAQYFq0aGG+/fZb5+fatGlj+vTpk23/pUuXmuuuu84EBASYG264wXz++edlXDEKqzBjXKdOHSMpx8e4cePKvnAUSmF/li9GIHUPhR3jjRs3mpYtW5rAwEBTv359M2nSJJOenl7GVaOwCjPODofDvPjii6ZBgwYmKCjI1K5d2wwZMsScPn267AtHgXz55Ze5/p7NGtc+ffqYNm3a5DimadOmJiAgwNSvX98sWLCg0Of1MYaeOQAAAKzjsteQAgAAwDsQSAEAAGApAikAAAAsRSAFAACApQikAAAAsBSBFAAAAJYikAIAAMBSBFIAAABYikAKAAAASxFIAQAAYCkCKQAAACxFIAUAAICl/h+zY5Zfa1XnSgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "invalid-nevada",
      "metadata": {
        "id": "invalid-nevada"
      },
      "source": [
        " Plot the training loss and the validation loss over the different epochs and see how it looks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "hidden-physics",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hidden-physics",
        "outputId": "efa17e1a-6436-4fb7-c328-2da174a11946"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "run_hist_1.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "banned-spider",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "banned-spider",
        "outputId": "656e97f9-8cca-4b33-fd62-76195c6267a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f46672691b0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "german-cherry",
      "metadata": {
        "id": "german-cherry"
      },
      "source": [
        "#What is your interpretation about the result of the train and validation loss?\n",
        "- Both of the train and validation loss follows a similar curve closely and both converged to a low value indicating that the model is performing well, and the gap between the two curves indicates that it is not overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "involved-slovak",
      "metadata": {
        "id": "involved-slovak"
      },
      "source": [
        "#### Supplementary Activity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pending-publisher",
      "metadata": {
        "id": "pending-publisher"
      },
      "source": [
        "* Build a model with two hidden layers, each with 6 nodes\n",
        "* Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
        "* Use a learning rate of .003 and train for 1500 epochs\n",
        "* Graph the trajectory of the loss functions, accuracy on both train and test set\n",
        "* Plot the roc curve for the predictions\n",
        "* Use different learning rates, numbers of epochs, and network structures.\n",
        "* Plot the results of training and validation loss using different learning rates, number of epocgs and network structures\n",
        "* Interpret your result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Build a model with two hidden layers, each with 6 nodes\n",
        "#Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
        "model_1 = Sequential([\n",
        "    Dense(6, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(6, activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "tAv27JY5U7X-"
      },
      "id": "tAv27JY5U7X-",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hL2gQdgVJx9",
        "outputId": "734a5b18-63b8-4155-991b-d4e5eb4727d5"
      },
      "id": "4hL2gQdgVJx9",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 6)                 54        \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 6)                 42        \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 7         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 103 (412.00 Byte)\n",
            "Trainable params: 103 (412.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Use a learning rate of .003 and train for 1500 epochs\n",
        "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_2 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKlFROX5VNhW",
        "outputId": "cd9cdaaa-916d-429a-b3c7-cd71bca02634"
      },
      "id": "NKlFROX5VNhW",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1500\n",
            "18/18 [==============================] - 1s 20ms/step - loss: 0.7023 - accuracy: 0.5816 - val_loss: 0.7024 - val_accuracy: 0.6250\n",
            "Epoch 2/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6958 - accuracy: 0.6406 - val_loss: 0.6962 - val_accuracy: 0.6562\n",
            "Epoch 3/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6896 - accuracy: 0.6545 - val_loss: 0.6904 - val_accuracy: 0.6615\n",
            "Epoch 4/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6839 - accuracy: 0.6597 - val_loss: 0.6850 - val_accuracy: 0.6562\n",
            "Epoch 5/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.6784 - accuracy: 0.6667 - val_loss: 0.6798 - val_accuracy: 0.6458\n",
            "Epoch 6/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6732 - accuracy: 0.6615 - val_loss: 0.6750 - val_accuracy: 0.6458\n",
            "Epoch 7/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6681 - accuracy: 0.6597 - val_loss: 0.6703 - val_accuracy: 0.6406\n",
            "Epoch 8/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6632 - accuracy: 0.6615 - val_loss: 0.6657 - val_accuracy: 0.6406\n",
            "Epoch 9/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6583 - accuracy: 0.6615 - val_loss: 0.6614 - val_accuracy: 0.6406\n",
            "Epoch 10/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6537 - accuracy: 0.6580 - val_loss: 0.6572 - val_accuracy: 0.6406\n",
            "Epoch 11/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6492 - accuracy: 0.6580 - val_loss: 0.6531 - val_accuracy: 0.6406\n",
            "Epoch 12/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6448 - accuracy: 0.6580 - val_loss: 0.6491 - val_accuracy: 0.6406\n",
            "Epoch 13/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6405 - accuracy: 0.6562 - val_loss: 0.6452 - val_accuracy: 0.6406\n",
            "Epoch 14/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6361 - accuracy: 0.6562 - val_loss: 0.6413 - val_accuracy: 0.6406\n",
            "Epoch 15/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6318 - accuracy: 0.6545 - val_loss: 0.6375 - val_accuracy: 0.6406\n",
            "Epoch 16/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6275 - accuracy: 0.6545 - val_loss: 0.6337 - val_accuracy: 0.6406\n",
            "Epoch 17/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6234 - accuracy: 0.6510 - val_loss: 0.6301 - val_accuracy: 0.6406\n",
            "Epoch 18/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6191 - accuracy: 0.6510 - val_loss: 0.6264 - val_accuracy: 0.6406\n",
            "Epoch 19/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6148 - accuracy: 0.6510 - val_loss: 0.6227 - val_accuracy: 0.6406\n",
            "Epoch 20/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6107 - accuracy: 0.6510 - val_loss: 0.6190 - val_accuracy: 0.6406\n",
            "Epoch 21/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6063 - accuracy: 0.6510 - val_loss: 0.6153 - val_accuracy: 0.6406\n",
            "Epoch 22/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6021 - accuracy: 0.6510 - val_loss: 0.6117 - val_accuracy: 0.6406\n",
            "Epoch 23/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5979 - accuracy: 0.6510 - val_loss: 0.6082 - val_accuracy: 0.6406\n",
            "Epoch 24/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5935 - accuracy: 0.6545 - val_loss: 0.6046 - val_accuracy: 0.6406\n",
            "Epoch 25/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5893 - accuracy: 0.6545 - val_loss: 0.6010 - val_accuracy: 0.6406\n",
            "Epoch 26/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5849 - accuracy: 0.6580 - val_loss: 0.5975 - val_accuracy: 0.6406\n",
            "Epoch 27/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5806 - accuracy: 0.6615 - val_loss: 0.5940 - val_accuracy: 0.6406\n",
            "Epoch 28/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5762 - accuracy: 0.6615 - val_loss: 0.5905 - val_accuracy: 0.6406\n",
            "Epoch 29/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5718 - accuracy: 0.6632 - val_loss: 0.5871 - val_accuracy: 0.6406\n",
            "Epoch 30/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5675 - accuracy: 0.6701 - val_loss: 0.5836 - val_accuracy: 0.6406\n",
            "Epoch 31/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5631 - accuracy: 0.6736 - val_loss: 0.5802 - val_accuracy: 0.6562\n",
            "Epoch 32/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5589 - accuracy: 0.6771 - val_loss: 0.5768 - val_accuracy: 0.6510\n",
            "Epoch 33/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5548 - accuracy: 0.6875 - val_loss: 0.5736 - val_accuracy: 0.6667\n",
            "Epoch 34/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5508 - accuracy: 0.6927 - val_loss: 0.5705 - val_accuracy: 0.6771\n",
            "Epoch 35/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5469 - accuracy: 0.6979 - val_loss: 0.5675 - val_accuracy: 0.6719\n",
            "Epoch 36/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5430 - accuracy: 0.7049 - val_loss: 0.5645 - val_accuracy: 0.6823\n",
            "Epoch 37/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5393 - accuracy: 0.7101 - val_loss: 0.5616 - val_accuracy: 0.7031\n",
            "Epoch 38/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5358 - accuracy: 0.7135 - val_loss: 0.5589 - val_accuracy: 0.7031\n",
            "Epoch 39/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5323 - accuracy: 0.7188 - val_loss: 0.5562 - val_accuracy: 0.6927\n",
            "Epoch 40/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5290 - accuracy: 0.7188 - val_loss: 0.5537 - val_accuracy: 0.7031\n",
            "Epoch 41/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5258 - accuracy: 0.7274 - val_loss: 0.5513 - val_accuracy: 0.7240\n",
            "Epoch 42/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5227 - accuracy: 0.7274 - val_loss: 0.5491 - val_accuracy: 0.7240\n",
            "Epoch 43/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5198 - accuracy: 0.7292 - val_loss: 0.5469 - val_accuracy: 0.7344\n",
            "Epoch 44/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5169 - accuracy: 0.7292 - val_loss: 0.5449 - val_accuracy: 0.7396\n",
            "Epoch 45/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5141 - accuracy: 0.7361 - val_loss: 0.5430 - val_accuracy: 0.7396\n",
            "Epoch 46/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7361 - val_loss: 0.5412 - val_accuracy: 0.7448\n",
            "Epoch 47/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7396 - val_loss: 0.5395 - val_accuracy: 0.7500\n",
            "Epoch 48/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7396 - val_loss: 0.5379 - val_accuracy: 0.7448\n",
            "Epoch 49/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7378 - val_loss: 0.5364 - val_accuracy: 0.7500\n",
            "Epoch 50/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7413 - val_loss: 0.5351 - val_accuracy: 0.7500\n",
            "Epoch 51/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5007 - accuracy: 0.7378 - val_loss: 0.5338 - val_accuracy: 0.7604\n",
            "Epoch 52/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4989 - accuracy: 0.7344 - val_loss: 0.5327 - val_accuracy: 0.7760\n",
            "Epoch 53/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4971 - accuracy: 0.7344 - val_loss: 0.5316 - val_accuracy: 0.7656\n",
            "Epoch 54/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4955 - accuracy: 0.7396 - val_loss: 0.5307 - val_accuracy: 0.7552\n",
            "Epoch 55/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4938 - accuracy: 0.7396 - val_loss: 0.5298 - val_accuracy: 0.7552\n",
            "Epoch 56/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4924 - accuracy: 0.7431 - val_loss: 0.5290 - val_accuracy: 0.7552\n",
            "Epoch 57/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4911 - accuracy: 0.7448 - val_loss: 0.5283 - val_accuracy: 0.7552\n",
            "Epoch 58/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4897 - accuracy: 0.7413 - val_loss: 0.5276 - val_accuracy: 0.7448\n",
            "Epoch 59/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4886 - accuracy: 0.7465 - val_loss: 0.5270 - val_accuracy: 0.7344\n",
            "Epoch 60/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4874 - accuracy: 0.7500 - val_loss: 0.5264 - val_accuracy: 0.7344\n",
            "Epoch 61/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4863 - accuracy: 0.7517 - val_loss: 0.5258 - val_accuracy: 0.7448\n",
            "Epoch 62/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7535 - val_loss: 0.5254 - val_accuracy: 0.7396\n",
            "Epoch 63/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.7535 - val_loss: 0.5249 - val_accuracy: 0.7344\n",
            "Epoch 64/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4831 - accuracy: 0.7517 - val_loss: 0.5245 - val_accuracy: 0.7396\n",
            "Epoch 65/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4821 - accuracy: 0.7587 - val_loss: 0.5241 - val_accuracy: 0.7448\n",
            "Epoch 66/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4813 - accuracy: 0.7569 - val_loss: 0.5237 - val_accuracy: 0.7448\n",
            "Epoch 67/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.7604 - val_loss: 0.5234 - val_accuracy: 0.7448\n",
            "Epoch 68/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.7622 - val_loss: 0.5231 - val_accuracy: 0.7448\n",
            "Epoch 69/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4788 - accuracy: 0.7587 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
            "Epoch 70/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4779 - accuracy: 0.7587 - val_loss: 0.5225 - val_accuracy: 0.7448\n",
            "Epoch 71/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4771 - accuracy: 0.7587 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
            "Epoch 72/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4765 - accuracy: 0.7604 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
            "Epoch 73/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4757 - accuracy: 0.7622 - val_loss: 0.5218 - val_accuracy: 0.7552\n",
            "Epoch 74/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.7639 - val_loss: 0.5216 - val_accuracy: 0.7500\n",
            "Epoch 75/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.7604 - val_loss: 0.5214 - val_accuracy: 0.7500\n",
            "Epoch 76/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.7587 - val_loss: 0.5212 - val_accuracy: 0.7500\n",
            "Epoch 77/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4728 - accuracy: 0.7587 - val_loss: 0.5210 - val_accuracy: 0.7448\n",
            "Epoch 78/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.7587 - val_loss: 0.5209 - val_accuracy: 0.7448\n",
            "Epoch 79/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4715 - accuracy: 0.7622 - val_loss: 0.5208 - val_accuracy: 0.7448\n",
            "Epoch 80/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.7622 - val_loss: 0.5207 - val_accuracy: 0.7448\n",
            "Epoch 81/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7639 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
            "Epoch 82/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.7604 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
            "Epoch 83/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7622 - val_loss: 0.5204 - val_accuracy: 0.7448\n",
            "Epoch 84/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7622 - val_loss: 0.5203 - val_accuracy: 0.7448\n",
            "Epoch 85/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7622 - val_loss: 0.5202 - val_accuracy: 0.7448\n",
            "Epoch 86/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.7604 - val_loss: 0.5201 - val_accuracy: 0.7448\n",
            "Epoch 87/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7587 - val_loss: 0.5199 - val_accuracy: 0.7448\n",
            "Epoch 88/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.7639 - val_loss: 0.5198 - val_accuracy: 0.7448\n",
            "Epoch 89/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.7656 - val_loss: 0.5198 - val_accuracy: 0.7448\n",
            "Epoch 90/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4655 - accuracy: 0.7639 - val_loss: 0.5197 - val_accuracy: 0.7448\n",
            "Epoch 91/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7639 - val_loss: 0.5196 - val_accuracy: 0.7448\n",
            "Epoch 92/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4647 - accuracy: 0.7639 - val_loss: 0.5196 - val_accuracy: 0.7448\n",
            "Epoch 93/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4643 - accuracy: 0.7622 - val_loss: 0.5195 - val_accuracy: 0.7448\n",
            "Epoch 94/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4639 - accuracy: 0.7639 - val_loss: 0.5195 - val_accuracy: 0.7448\n",
            "Epoch 95/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4635 - accuracy: 0.7656 - val_loss: 0.5195 - val_accuracy: 0.7448\n",
            "Epoch 96/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4630 - accuracy: 0.7656 - val_loss: 0.5195 - val_accuracy: 0.7500\n",
            "Epoch 97/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4628 - accuracy: 0.7639 - val_loss: 0.5195 - val_accuracy: 0.7552\n",
            "Epoch 98/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4623 - accuracy: 0.7622 - val_loss: 0.5196 - val_accuracy: 0.7552\n",
            "Epoch 99/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4620 - accuracy: 0.7639 - val_loss: 0.5196 - val_accuracy: 0.7552\n",
            "Epoch 100/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4617 - accuracy: 0.7639 - val_loss: 0.5196 - val_accuracy: 0.7552\n",
            "Epoch 101/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4616 - accuracy: 0.7656 - val_loss: 0.5196 - val_accuracy: 0.7604\n",
            "Epoch 102/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4611 - accuracy: 0.7639 - val_loss: 0.5196 - val_accuracy: 0.7604\n",
            "Epoch 103/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4608 - accuracy: 0.7691 - val_loss: 0.5196 - val_accuracy: 0.7604\n",
            "Epoch 104/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4605 - accuracy: 0.7656 - val_loss: 0.5196 - val_accuracy: 0.7604\n",
            "Epoch 105/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4601 - accuracy: 0.7708 - val_loss: 0.5197 - val_accuracy: 0.7604\n",
            "Epoch 106/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4599 - accuracy: 0.7674 - val_loss: 0.5197 - val_accuracy: 0.7604\n",
            "Epoch 107/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4596 - accuracy: 0.7674 - val_loss: 0.5197 - val_accuracy: 0.7604\n",
            "Epoch 108/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7691 - val_loss: 0.5198 - val_accuracy: 0.7552\n",
            "Epoch 109/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4591 - accuracy: 0.7674 - val_loss: 0.5198 - val_accuracy: 0.7552\n",
            "Epoch 110/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4587 - accuracy: 0.7708 - val_loss: 0.5198 - val_accuracy: 0.7552\n",
            "Epoch 111/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4586 - accuracy: 0.7691 - val_loss: 0.5198 - val_accuracy: 0.7552\n",
            "Epoch 112/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4584 - accuracy: 0.7674 - val_loss: 0.5199 - val_accuracy: 0.7552\n",
            "Epoch 113/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4580 - accuracy: 0.7691 - val_loss: 0.5199 - val_accuracy: 0.7552\n",
            "Epoch 114/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7656 - val_loss: 0.5199 - val_accuracy: 0.7552\n",
            "Epoch 115/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7639 - val_loss: 0.5200 - val_accuracy: 0.7552\n",
            "Epoch 116/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7656 - val_loss: 0.5200 - val_accuracy: 0.7552\n",
            "Epoch 117/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4572 - accuracy: 0.7656 - val_loss: 0.5200 - val_accuracy: 0.7552\n",
            "Epoch 118/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7674 - val_loss: 0.5200 - val_accuracy: 0.7552\n",
            "Epoch 119/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7656 - val_loss: 0.5200 - val_accuracy: 0.7552\n",
            "Epoch 120/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7674 - val_loss: 0.5200 - val_accuracy: 0.7552\n",
            "Epoch 121/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7639 - val_loss: 0.5201 - val_accuracy: 0.7552\n",
            "Epoch 122/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7656 - val_loss: 0.5201 - val_accuracy: 0.7552\n",
            "Epoch 123/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7674 - val_loss: 0.5201 - val_accuracy: 0.7552\n",
            "Epoch 124/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7708 - val_loss: 0.5202 - val_accuracy: 0.7552\n",
            "Epoch 125/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7691 - val_loss: 0.5202 - val_accuracy: 0.7552\n",
            "Epoch 126/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.7691 - val_loss: 0.5202 - val_accuracy: 0.7552\n",
            "Epoch 127/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.7708 - val_loss: 0.5203 - val_accuracy: 0.7552\n",
            "Epoch 128/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.7674 - val_loss: 0.5203 - val_accuracy: 0.7552\n",
            "Epoch 129/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4546 - accuracy: 0.7691 - val_loss: 0.5203 - val_accuracy: 0.7552\n",
            "Epoch 130/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.7708 - val_loss: 0.5204 - val_accuracy: 0.7552\n",
            "Epoch 131/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7726 - val_loss: 0.5204 - val_accuracy: 0.7552\n",
            "Epoch 132/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.7691 - val_loss: 0.5204 - val_accuracy: 0.7552\n",
            "Epoch 133/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7726 - val_loss: 0.5204 - val_accuracy: 0.7552\n",
            "Epoch 134/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7691 - val_loss: 0.5205 - val_accuracy: 0.7552\n",
            "Epoch 135/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.7726 - val_loss: 0.5205 - val_accuracy: 0.7552\n",
            "Epoch 136/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4533 - accuracy: 0.7726 - val_loss: 0.5205 - val_accuracy: 0.7552\n",
            "Epoch 137/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4533 - accuracy: 0.7726 - val_loss: 0.5205 - val_accuracy: 0.7552\n",
            "Epoch 138/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.7726 - val_loss: 0.5206 - val_accuracy: 0.7552\n",
            "Epoch 139/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.7726 - val_loss: 0.5206 - val_accuracy: 0.7552\n",
            "Epoch 140/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7778 - val_loss: 0.5206 - val_accuracy: 0.7552\n",
            "Epoch 141/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7760 - val_loss: 0.5206 - val_accuracy: 0.7552\n",
            "Epoch 142/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7743 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
            "Epoch 143/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7778 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
            "Epoch 144/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7778 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
            "Epoch 145/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7760 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
            "Epoch 146/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.7760 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
            "Epoch 147/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7743 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
            "Epoch 148/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.7778 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
            "Epoch 149/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7760 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
            "Epoch 150/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7760 - val_loss: 0.5206 - val_accuracy: 0.7448\n",
            "Epoch 151/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7778 - val_loss: 0.5206 - val_accuracy: 0.7448\n",
            "Epoch 152/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.7778 - val_loss: 0.5206 - val_accuracy: 0.7448\n",
            "Epoch 153/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.7778 - val_loss: 0.5206 - val_accuracy: 0.7448\n",
            "Epoch 154/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.7778 - val_loss: 0.5206 - val_accuracy: 0.7448\n",
            "Epoch 155/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7778 - val_loss: 0.5206 - val_accuracy: 0.7448\n",
            "Epoch 156/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.7795 - val_loss: 0.5206 - val_accuracy: 0.7448\n",
            "Epoch 157/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4503 - accuracy: 0.7760 - val_loss: 0.5206 - val_accuracy: 0.7448\n",
            "Epoch 158/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7778 - val_loss: 0.5206 - val_accuracy: 0.7448\n",
            "Epoch 159/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7778 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
            "Epoch 160/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7795 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
            "Epoch 161/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7778 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
            "Epoch 162/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.7795 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
            "Epoch 163/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7795 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
            "Epoch 164/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.7795 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
            "Epoch 165/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.7778 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
            "Epoch 166/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7778 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
            "Epoch 167/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7830 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
            "Epoch 168/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.7760 - val_loss: 0.5205 - val_accuracy: 0.7552\n",
            "Epoch 169/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.7778 - val_loss: 0.5205 - val_accuracy: 0.7552\n",
            "Epoch 170/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7795 - val_loss: 0.5205 - val_accuracy: 0.7552\n",
            "Epoch 171/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7760 - val_loss: 0.5205 - val_accuracy: 0.7552\n",
            "Epoch 172/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7760 - val_loss: 0.5205 - val_accuracy: 0.7552\n",
            "Epoch 173/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.7760 - val_loss: 0.5205 - val_accuracy: 0.7552\n",
            "Epoch 174/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7812 - val_loss: 0.5205 - val_accuracy: 0.7552\n",
            "Epoch 175/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7795 - val_loss: 0.5204 - val_accuracy: 0.7552\n",
            "Epoch 176/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7812 - val_loss: 0.5204 - val_accuracy: 0.7552\n",
            "Epoch 177/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4482 - accuracy: 0.7812 - val_loss: 0.5204 - val_accuracy: 0.7552\n",
            "Epoch 178/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7812 - val_loss: 0.5204 - val_accuracy: 0.7552\n",
            "Epoch 179/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4481 - accuracy: 0.7795 - val_loss: 0.5204 - val_accuracy: 0.7552\n",
            "Epoch 180/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7830 - val_loss: 0.5203 - val_accuracy: 0.7552\n",
            "Epoch 181/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7778 - val_loss: 0.5204 - val_accuracy: 0.7552\n",
            "Epoch 182/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7865 - val_loss: 0.5203 - val_accuracy: 0.7552\n",
            "Epoch 183/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7830 - val_loss: 0.5203 - val_accuracy: 0.7552\n",
            "Epoch 184/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7830 - val_loss: 0.5202 - val_accuracy: 0.7552\n",
            "Epoch 185/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7830 - val_loss: 0.5201 - val_accuracy: 0.7552\n",
            "Epoch 186/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4475 - accuracy: 0.7830 - val_loss: 0.5201 - val_accuracy: 0.7552\n",
            "Epoch 187/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7778 - val_loss: 0.5200 - val_accuracy: 0.7552\n",
            "Epoch 188/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7847 - val_loss: 0.5200 - val_accuracy: 0.7552\n",
            "Epoch 189/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7812 - val_loss: 0.5200 - val_accuracy: 0.7552\n",
            "Epoch 190/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7830 - val_loss: 0.5198 - val_accuracy: 0.7552\n",
            "Epoch 191/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7795 - val_loss: 0.5199 - val_accuracy: 0.7552\n",
            "Epoch 192/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7847 - val_loss: 0.5198 - val_accuracy: 0.7552\n",
            "Epoch 193/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.7847 - val_loss: 0.5197 - val_accuracy: 0.7552\n",
            "Epoch 194/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7865 - val_loss: 0.5196 - val_accuracy: 0.7552\n",
            "Epoch 195/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7830 - val_loss: 0.5196 - val_accuracy: 0.7552\n",
            "Epoch 196/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7847 - val_loss: 0.5195 - val_accuracy: 0.7552\n",
            "Epoch 197/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.7812 - val_loss: 0.5195 - val_accuracy: 0.7552\n",
            "Epoch 198/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.7847 - val_loss: 0.5195 - val_accuracy: 0.7500\n",
            "Epoch 199/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7795 - val_loss: 0.5195 - val_accuracy: 0.7500\n",
            "Epoch 200/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7830 - val_loss: 0.5194 - val_accuracy: 0.7500\n",
            "Epoch 201/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7847 - val_loss: 0.5194 - val_accuracy: 0.7500\n",
            "Epoch 202/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7847 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
            "Epoch 203/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7847 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
            "Epoch 204/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7847 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
            "Epoch 205/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7865 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
            "Epoch 206/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7830 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
            "Epoch 207/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7830 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
            "Epoch 208/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7830 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
            "Epoch 209/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7812 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
            "Epoch 210/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4451 - accuracy: 0.7830 - val_loss: 0.5191 - val_accuracy: 0.7552\n",
            "Epoch 211/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4449 - accuracy: 0.7830 - val_loss: 0.5191 - val_accuracy: 0.7552\n",
            "Epoch 212/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7830 - val_loss: 0.5191 - val_accuracy: 0.7604\n",
            "Epoch 213/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7812 - val_loss: 0.5191 - val_accuracy: 0.7604\n",
            "Epoch 214/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7795 - val_loss: 0.5190 - val_accuracy: 0.7604\n",
            "Epoch 215/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7830 - val_loss: 0.5190 - val_accuracy: 0.7604\n",
            "Epoch 216/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7812 - val_loss: 0.5190 - val_accuracy: 0.7604\n",
            "Epoch 217/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7882 - val_loss: 0.5190 - val_accuracy: 0.7604\n",
            "Epoch 218/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7830 - val_loss: 0.5190 - val_accuracy: 0.7604\n",
            "Epoch 219/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.7795 - val_loss: 0.5189 - val_accuracy: 0.7604\n",
            "Epoch 220/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.7847 - val_loss: 0.5189 - val_accuracy: 0.7604\n",
            "Epoch 221/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7865 - val_loss: 0.5189 - val_accuracy: 0.7604\n",
            "Epoch 222/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7830 - val_loss: 0.5189 - val_accuracy: 0.7604\n",
            "Epoch 223/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7812 - val_loss: 0.5188 - val_accuracy: 0.7604\n",
            "Epoch 224/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7865 - val_loss: 0.5188 - val_accuracy: 0.7604\n",
            "Epoch 225/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7847 - val_loss: 0.5188 - val_accuracy: 0.7708\n",
            "Epoch 226/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.7847 - val_loss: 0.5188 - val_accuracy: 0.7708\n",
            "Epoch 227/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.7847 - val_loss: 0.5187 - val_accuracy: 0.7656\n",
            "Epoch 228/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7830 - val_loss: 0.5187 - val_accuracy: 0.7708\n",
            "Epoch 229/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7847 - val_loss: 0.5187 - val_accuracy: 0.7708\n",
            "Epoch 230/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7882 - val_loss: 0.5187 - val_accuracy: 0.7708\n",
            "Epoch 231/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7865 - val_loss: 0.5186 - val_accuracy: 0.7708\n",
            "Epoch 232/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7865 - val_loss: 0.5186 - val_accuracy: 0.7708\n",
            "Epoch 233/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7882 - val_loss: 0.5185 - val_accuracy: 0.7708\n",
            "Epoch 234/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7865 - val_loss: 0.5185 - val_accuracy: 0.7708\n",
            "Epoch 235/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.7847 - val_loss: 0.5185 - val_accuracy: 0.7708\n",
            "Epoch 236/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7865 - val_loss: 0.5185 - val_accuracy: 0.7708\n",
            "Epoch 237/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.7812 - val_loss: 0.5185 - val_accuracy: 0.7708\n",
            "Epoch 238/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.7865 - val_loss: 0.5185 - val_accuracy: 0.7708\n",
            "Epoch 239/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7865 - val_loss: 0.5185 - val_accuracy: 0.7708\n",
            "Epoch 240/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7830 - val_loss: 0.5184 - val_accuracy: 0.7708\n",
            "Epoch 241/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7865 - val_loss: 0.5184 - val_accuracy: 0.7760\n",
            "Epoch 242/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7865 - val_loss: 0.5184 - val_accuracy: 0.7760\n",
            "Epoch 243/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4425 - accuracy: 0.7865 - val_loss: 0.5184 - val_accuracy: 0.7812\n",
            "Epoch 244/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4424 - accuracy: 0.7830 - val_loss: 0.5183 - val_accuracy: 0.7812\n",
            "Epoch 245/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4424 - accuracy: 0.7847 - val_loss: 0.5183 - val_accuracy: 0.7812\n",
            "Epoch 246/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4424 - accuracy: 0.7847 - val_loss: 0.5183 - val_accuracy: 0.7760\n",
            "Epoch 247/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4422 - accuracy: 0.7847 - val_loss: 0.5183 - val_accuracy: 0.7865\n",
            "Epoch 248/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.7812 - val_loss: 0.5183 - val_accuracy: 0.7865\n",
            "Epoch 249/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4421 - accuracy: 0.7830 - val_loss: 0.5182 - val_accuracy: 0.7865\n",
            "Epoch 250/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.7812 - val_loss: 0.5183 - val_accuracy: 0.7865\n",
            "Epoch 251/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4419 - accuracy: 0.7812 - val_loss: 0.5183 - val_accuracy: 0.7865\n",
            "Epoch 252/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4418 - accuracy: 0.7830 - val_loss: 0.5183 - val_accuracy: 0.7865\n",
            "Epoch 253/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4419 - accuracy: 0.7812 - val_loss: 0.5182 - val_accuracy: 0.7865\n",
            "Epoch 254/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4417 - accuracy: 0.7830 - val_loss: 0.5182 - val_accuracy: 0.7865\n",
            "Epoch 255/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4416 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7865\n",
            "Epoch 256/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4416 - accuracy: 0.7847 - val_loss: 0.5181 - val_accuracy: 0.7865\n",
            "Epoch 257/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4414 - accuracy: 0.7847 - val_loss: 0.5181 - val_accuracy: 0.7812\n",
            "Epoch 258/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4414 - accuracy: 0.7830 - val_loss: 0.5181 - val_accuracy: 0.7760\n",
            "Epoch 259/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4413 - accuracy: 0.7830 - val_loss: 0.5181 - val_accuracy: 0.7760\n",
            "Epoch 260/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4412 - accuracy: 0.7778 - val_loss: 0.5181 - val_accuracy: 0.7760\n",
            "Epoch 261/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4413 - accuracy: 0.7830 - val_loss: 0.5181 - val_accuracy: 0.7760\n",
            "Epoch 262/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4412 - accuracy: 0.7795 - val_loss: 0.5181 - val_accuracy: 0.7760\n",
            "Epoch 263/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4411 - accuracy: 0.7830 - val_loss: 0.5181 - val_accuracy: 0.7760\n",
            "Epoch 264/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4411 - accuracy: 0.7812 - val_loss: 0.5181 - val_accuracy: 0.7760\n",
            "Epoch 265/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4410 - accuracy: 0.7830 - val_loss: 0.5181 - val_accuracy: 0.7760\n",
            "Epoch 266/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4411 - accuracy: 0.7830 - val_loss: 0.5180 - val_accuracy: 0.7760\n",
            "Epoch 267/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7778 - val_loss: 0.5180 - val_accuracy: 0.7760\n",
            "Epoch 268/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.7778 - val_loss: 0.5180 - val_accuracy: 0.7760\n",
            "Epoch 269/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7795 - val_loss: 0.5180 - val_accuracy: 0.7812\n",
            "Epoch 270/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7847 - val_loss: 0.5180 - val_accuracy: 0.7812\n",
            "Epoch 271/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7847 - val_loss: 0.5180 - val_accuracy: 0.7812\n",
            "Epoch 272/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7847 - val_loss: 0.5179 - val_accuracy: 0.7812\n",
            "Epoch 273/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7812 - val_loss: 0.5179 - val_accuracy: 0.7812\n",
            "Epoch 274/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7760 - val_loss: 0.5179 - val_accuracy: 0.7812\n",
            "Epoch 275/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7812 - val_loss: 0.5180 - val_accuracy: 0.7812\n",
            "Epoch 276/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7830 - val_loss: 0.5180 - val_accuracy: 0.7812\n",
            "Epoch 277/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7830 - val_loss: 0.5180 - val_accuracy: 0.7812\n",
            "Epoch 278/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7830 - val_loss: 0.5179 - val_accuracy: 0.7812\n",
            "Epoch 279/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7865 - val_loss: 0.5179 - val_accuracy: 0.7760\n",
            "Epoch 280/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7882 - val_loss: 0.5179 - val_accuracy: 0.7760\n",
            "Epoch 281/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7830 - val_loss: 0.5178 - val_accuracy: 0.7760\n",
            "Epoch 282/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7812 - val_loss: 0.5178 - val_accuracy: 0.7760\n",
            "Epoch 283/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7812 - val_loss: 0.5178 - val_accuracy: 0.7760\n",
            "Epoch 284/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7830 - val_loss: 0.5177 - val_accuracy: 0.7760\n",
            "Epoch 285/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7865 - val_loss: 0.5177 - val_accuracy: 0.7760\n",
            "Epoch 286/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7812 - val_loss: 0.5177 - val_accuracy: 0.7760\n",
            "Epoch 287/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7760\n",
            "Epoch 288/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7812 - val_loss: 0.5176 - val_accuracy: 0.7760\n",
            "Epoch 289/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7812 - val_loss: 0.5175 - val_accuracy: 0.7760\n",
            "Epoch 290/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7830 - val_loss: 0.5175 - val_accuracy: 0.7760\n",
            "Epoch 291/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7847 - val_loss: 0.5175 - val_accuracy: 0.7760\n",
            "Epoch 292/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4391 - accuracy: 0.7830 - val_loss: 0.5175 - val_accuracy: 0.7760\n",
            "Epoch 293/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7847 - val_loss: 0.5174 - val_accuracy: 0.7760\n",
            "Epoch 294/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7760\n",
            "Epoch 295/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4388 - accuracy: 0.7847 - val_loss: 0.5174 - val_accuracy: 0.7760\n",
            "Epoch 296/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7830 - val_loss: 0.5174 - val_accuracy: 0.7760\n",
            "Epoch 297/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7830 - val_loss: 0.5173 - val_accuracy: 0.7760\n",
            "Epoch 298/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7830 - val_loss: 0.5173 - val_accuracy: 0.7760\n",
            "Epoch 299/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4386 - accuracy: 0.7812 - val_loss: 0.5172 - val_accuracy: 0.7812\n",
            "Epoch 300/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7847 - val_loss: 0.5172 - val_accuracy: 0.7812\n",
            "Epoch 301/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7865 - val_loss: 0.5172 - val_accuracy: 0.7760\n",
            "Epoch 302/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7830 - val_loss: 0.5172 - val_accuracy: 0.7760\n",
            "Epoch 303/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7830 - val_loss: 0.5171 - val_accuracy: 0.7812\n",
            "Epoch 304/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7812\n",
            "Epoch 305/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4382 - accuracy: 0.7865 - val_loss: 0.5171 - val_accuracy: 0.7760\n",
            "Epoch 306/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4381 - accuracy: 0.7812 - val_loss: 0.5170 - val_accuracy: 0.7812\n",
            "Epoch 307/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4381 - accuracy: 0.7847 - val_loss: 0.5170 - val_accuracy: 0.7760\n",
            "Epoch 308/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7812\n",
            "Epoch 309/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4379 - accuracy: 0.7847 - val_loss: 0.5169 - val_accuracy: 0.7812\n",
            "Epoch 310/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7778 - val_loss: 0.5169 - val_accuracy: 0.7760\n",
            "Epoch 311/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4380 - accuracy: 0.7795 - val_loss: 0.5169 - val_accuracy: 0.7760\n",
            "Epoch 312/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7795 - val_loss: 0.5169 - val_accuracy: 0.7760\n",
            "Epoch 313/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7760\n",
            "Epoch 314/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7760\n",
            "Epoch 315/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7795 - val_loss: 0.5169 - val_accuracy: 0.7760\n",
            "Epoch 316/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7760\n",
            "Epoch 317/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7812 - val_loss: 0.5168 - val_accuracy: 0.7760\n",
            "Epoch 318/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7847 - val_loss: 0.5168 - val_accuracy: 0.7760\n",
            "Epoch 319/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4373 - accuracy: 0.7795 - val_loss: 0.5168 - val_accuracy: 0.7760\n",
            "Epoch 320/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4372 - accuracy: 0.7812 - val_loss: 0.5168 - val_accuracy: 0.7760\n",
            "Epoch 321/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7795 - val_loss: 0.5167 - val_accuracy: 0.7760\n",
            "Epoch 322/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7795 - val_loss: 0.5166 - val_accuracy: 0.7760\n",
            "Epoch 323/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7830 - val_loss: 0.5166 - val_accuracy: 0.7760\n",
            "Epoch 324/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7795 - val_loss: 0.5166 - val_accuracy: 0.7760\n",
            "Epoch 325/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7830 - val_loss: 0.5167 - val_accuracy: 0.7760\n",
            "Epoch 326/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7830 - val_loss: 0.5166 - val_accuracy: 0.7760\n",
            "Epoch 327/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7812 - val_loss: 0.5165 - val_accuracy: 0.7760\n",
            "Epoch 328/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7847 - val_loss: 0.5165 - val_accuracy: 0.7760\n",
            "Epoch 329/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7812 - val_loss: 0.5163 - val_accuracy: 0.7760\n",
            "Epoch 330/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7847 - val_loss: 0.5164 - val_accuracy: 0.7760\n",
            "Epoch 331/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7795 - val_loss: 0.5163 - val_accuracy: 0.7760\n",
            "Epoch 332/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7847 - val_loss: 0.5163 - val_accuracy: 0.7760\n",
            "Epoch 333/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7847 - val_loss: 0.5163 - val_accuracy: 0.7760\n",
            "Epoch 334/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7830 - val_loss: 0.5163 - val_accuracy: 0.7760\n",
            "Epoch 335/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7830 - val_loss: 0.5163 - val_accuracy: 0.7760\n",
            "Epoch 336/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7847 - val_loss: 0.5162 - val_accuracy: 0.7760\n",
            "Epoch 337/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4359 - accuracy: 0.7847 - val_loss: 0.5162 - val_accuracy: 0.7760\n",
            "Epoch 338/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7847 - val_loss: 0.5161 - val_accuracy: 0.7760\n",
            "Epoch 339/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7847 - val_loss: 0.5160 - val_accuracy: 0.7760\n",
            "Epoch 340/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7812 - val_loss: 0.5160 - val_accuracy: 0.7760\n",
            "Epoch 341/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7865 - val_loss: 0.5159 - val_accuracy: 0.7760\n",
            "Epoch 342/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7847 - val_loss: 0.5158 - val_accuracy: 0.7760\n",
            "Epoch 343/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7812 - val_loss: 0.5159 - val_accuracy: 0.7760\n",
            "Epoch 344/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7812 - val_loss: 0.5158 - val_accuracy: 0.7760\n",
            "Epoch 345/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4352 - accuracy: 0.7830 - val_loss: 0.5158 - val_accuracy: 0.7760\n",
            "Epoch 346/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4351 - accuracy: 0.7847 - val_loss: 0.5157 - val_accuracy: 0.7760\n",
            "Epoch 347/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.7830 - val_loss: 0.5156 - val_accuracy: 0.7760\n",
            "Epoch 348/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4349 - accuracy: 0.7830 - val_loss: 0.5156 - val_accuracy: 0.7760\n",
            "Epoch 349/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7847 - val_loss: 0.5155 - val_accuracy: 0.7760\n",
            "Epoch 350/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7847 - val_loss: 0.5155 - val_accuracy: 0.7760\n",
            "Epoch 351/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.7830 - val_loss: 0.5155 - val_accuracy: 0.7760\n",
            "Epoch 352/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4347 - accuracy: 0.7830 - val_loss: 0.5154 - val_accuracy: 0.7760\n",
            "Epoch 353/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7830 - val_loss: 0.5154 - val_accuracy: 0.7760\n",
            "Epoch 354/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7830 - val_loss: 0.5153 - val_accuracy: 0.7812\n",
            "Epoch 355/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7830 - val_loss: 0.5154 - val_accuracy: 0.7760\n",
            "Epoch 356/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7830 - val_loss: 0.5153 - val_accuracy: 0.7760\n",
            "Epoch 357/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4343 - accuracy: 0.7812 - val_loss: 0.5153 - val_accuracy: 0.7760\n",
            "Epoch 358/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7830 - val_loss: 0.5153 - val_accuracy: 0.7760\n",
            "Epoch 359/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4340 - accuracy: 0.7830 - val_loss: 0.5152 - val_accuracy: 0.7760\n",
            "Epoch 360/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7812 - val_loss: 0.5152 - val_accuracy: 0.7760\n",
            "Epoch 361/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7865 - val_loss: 0.5152 - val_accuracy: 0.7760\n",
            "Epoch 362/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7865 - val_loss: 0.5151 - val_accuracy: 0.7812\n",
            "Epoch 363/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7830 - val_loss: 0.5151 - val_accuracy: 0.7760\n",
            "Epoch 364/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.7847 - val_loss: 0.5150 - val_accuracy: 0.7865\n",
            "Epoch 365/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7847 - val_loss: 0.5149 - val_accuracy: 0.7865\n",
            "Epoch 366/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7830 - val_loss: 0.5150 - val_accuracy: 0.7865\n",
            "Epoch 367/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7847 - val_loss: 0.5149 - val_accuracy: 0.7865\n",
            "Epoch 368/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7795 - val_loss: 0.5149 - val_accuracy: 0.7865\n",
            "Epoch 369/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4332 - accuracy: 0.7865 - val_loss: 0.5149 - val_accuracy: 0.7865\n",
            "Epoch 370/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4330 - accuracy: 0.7830 - val_loss: 0.5149 - val_accuracy: 0.7865\n",
            "Epoch 371/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7882 - val_loss: 0.5149 - val_accuracy: 0.7865\n",
            "Epoch 372/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7865 - val_loss: 0.5148 - val_accuracy: 0.7865\n",
            "Epoch 373/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7865 - val_loss: 0.5148 - val_accuracy: 0.7865\n",
            "Epoch 374/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4327 - accuracy: 0.7847 - val_loss: 0.5148 - val_accuracy: 0.7865\n",
            "Epoch 375/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7847 - val_loss: 0.5148 - val_accuracy: 0.7865\n",
            "Epoch 376/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7865 - val_loss: 0.5148 - val_accuracy: 0.7865\n",
            "Epoch 377/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7847 - val_loss: 0.5147 - val_accuracy: 0.7865\n",
            "Epoch 378/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7882 - val_loss: 0.5148 - val_accuracy: 0.7865\n",
            "Epoch 379/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.5147 - val_accuracy: 0.7865\n",
            "Epoch 380/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7865 - val_loss: 0.5147 - val_accuracy: 0.7865\n",
            "Epoch 381/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.7882 - val_loss: 0.5147 - val_accuracy: 0.7865\n",
            "Epoch 382/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.5146 - val_accuracy: 0.7865\n",
            "Epoch 383/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7865 - val_loss: 0.5146 - val_accuracy: 0.7865\n",
            "Epoch 384/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.5146 - val_accuracy: 0.7865\n",
            "Epoch 385/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7882 - val_loss: 0.5146 - val_accuracy: 0.7865\n",
            "Epoch 386/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7847 - val_loss: 0.5145 - val_accuracy: 0.7865\n",
            "Epoch 387/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.7882 - val_loss: 0.5145 - val_accuracy: 0.7865\n",
            "Epoch 388/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.7812 - val_loss: 0.5145 - val_accuracy: 0.7865\n",
            "Epoch 389/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4314 - accuracy: 0.7847 - val_loss: 0.5145 - val_accuracy: 0.7865\n",
            "Epoch 390/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4312 - accuracy: 0.7882 - val_loss: 0.5145 - val_accuracy: 0.7865\n",
            "Epoch 391/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4313 - accuracy: 0.7865 - val_loss: 0.5144 - val_accuracy: 0.7865\n",
            "Epoch 392/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4313 - accuracy: 0.7847 - val_loss: 0.5145 - val_accuracy: 0.7865\n",
            "Epoch 393/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4312 - accuracy: 0.7865 - val_loss: 0.5145 - val_accuracy: 0.7865\n",
            "Epoch 394/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4310 - accuracy: 0.7865 - val_loss: 0.5145 - val_accuracy: 0.7865\n",
            "Epoch 395/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4310 - accuracy: 0.7899 - val_loss: 0.5145 - val_accuracy: 0.7865\n",
            "Epoch 396/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.7899 - val_loss: 0.5145 - val_accuracy: 0.7865\n",
            "Epoch 397/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.7882 - val_loss: 0.5144 - val_accuracy: 0.7865\n",
            "Epoch 398/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4307 - accuracy: 0.7882 - val_loss: 0.5145 - val_accuracy: 0.7865\n",
            "Epoch 399/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4307 - accuracy: 0.7882 - val_loss: 0.5145 - val_accuracy: 0.7865\n",
            "Epoch 400/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4305 - accuracy: 0.7882 - val_loss: 0.5145 - val_accuracy: 0.7865\n",
            "Epoch 401/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4305 - accuracy: 0.7847 - val_loss: 0.5145 - val_accuracy: 0.7865\n",
            "Epoch 402/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4304 - accuracy: 0.7865 - val_loss: 0.5145 - val_accuracy: 0.7865\n",
            "Epoch 403/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4305 - accuracy: 0.7899 - val_loss: 0.5144 - val_accuracy: 0.7865\n",
            "Epoch 404/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4304 - accuracy: 0.7865 - val_loss: 0.5144 - val_accuracy: 0.7865\n",
            "Epoch 405/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4304 - accuracy: 0.7865 - val_loss: 0.5143 - val_accuracy: 0.7865\n",
            "Epoch 406/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4303 - accuracy: 0.7847 - val_loss: 0.5143 - val_accuracy: 0.7865\n",
            "Epoch 407/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.7899 - val_loss: 0.5142 - val_accuracy: 0.7812\n",
            "Epoch 408/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.7830 - val_loss: 0.5141 - val_accuracy: 0.7812\n",
            "Epoch 409/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4300 - accuracy: 0.7882 - val_loss: 0.5141 - val_accuracy: 0.7812\n",
            "Epoch 410/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4300 - accuracy: 0.7865 - val_loss: 0.5141 - val_accuracy: 0.7812\n",
            "Epoch 411/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4300 - accuracy: 0.7847 - val_loss: 0.5141 - val_accuracy: 0.7812\n",
            "Epoch 412/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4298 - accuracy: 0.7882 - val_loss: 0.5141 - val_accuracy: 0.7812\n",
            "Epoch 413/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4298 - accuracy: 0.7865 - val_loss: 0.5141 - val_accuracy: 0.7812\n",
            "Epoch 414/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4298 - accuracy: 0.7865 - val_loss: 0.5140 - val_accuracy: 0.7812\n",
            "Epoch 415/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.7865 - val_loss: 0.5139 - val_accuracy: 0.7812\n",
            "Epoch 416/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7865 - val_loss: 0.5138 - val_accuracy: 0.7812\n",
            "Epoch 417/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7847 - val_loss: 0.5137 - val_accuracy: 0.7812\n",
            "Epoch 418/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4298 - accuracy: 0.7865 - val_loss: 0.5136 - val_accuracy: 0.7812\n",
            "Epoch 419/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.7847 - val_loss: 0.5136 - val_accuracy: 0.7812\n",
            "Epoch 420/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7830 - val_loss: 0.5136 - val_accuracy: 0.7812\n",
            "Epoch 421/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7830 - val_loss: 0.5135 - val_accuracy: 0.7812\n",
            "Epoch 422/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7882 - val_loss: 0.5135 - val_accuracy: 0.7812\n",
            "Epoch 423/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4291 - accuracy: 0.7830 - val_loss: 0.5135 - val_accuracy: 0.7812\n",
            "Epoch 424/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4291 - accuracy: 0.7812 - val_loss: 0.5134 - val_accuracy: 0.7812\n",
            "Epoch 425/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4292 - accuracy: 0.7847 - val_loss: 0.5134 - val_accuracy: 0.7812\n",
            "Epoch 426/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7865 - val_loss: 0.5133 - val_accuracy: 0.7812\n",
            "Epoch 427/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4288 - accuracy: 0.7882 - val_loss: 0.5133 - val_accuracy: 0.7812\n",
            "Epoch 428/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7847 - val_loss: 0.5132 - val_accuracy: 0.7812\n",
            "Epoch 429/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.7847 - val_loss: 0.5133 - val_accuracy: 0.7760\n",
            "Epoch 430/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.7865 - val_loss: 0.5133 - val_accuracy: 0.7760\n",
            "Epoch 431/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4285 - accuracy: 0.7882 - val_loss: 0.5133 - val_accuracy: 0.7760\n",
            "Epoch 432/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4284 - accuracy: 0.7847 - val_loss: 0.5132 - val_accuracy: 0.7760\n",
            "Epoch 433/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.7812 - val_loss: 0.5131 - val_accuracy: 0.7760\n",
            "Epoch 434/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.7865 - val_loss: 0.5128 - val_accuracy: 0.7760\n",
            "Epoch 435/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.7830 - val_loss: 0.5127 - val_accuracy: 0.7760\n",
            "Epoch 436/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7847 - val_loss: 0.5126 - val_accuracy: 0.7760\n",
            "Epoch 437/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.7865 - val_loss: 0.5126 - val_accuracy: 0.7760\n",
            "Epoch 438/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.7847 - val_loss: 0.5126 - val_accuracy: 0.7760\n",
            "Epoch 439/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.7882 - val_loss: 0.5125 - val_accuracy: 0.7760\n",
            "Epoch 440/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.7847 - val_loss: 0.5125 - val_accuracy: 0.7760\n",
            "Epoch 441/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7830 - val_loss: 0.5125 - val_accuracy: 0.7760\n",
            "Epoch 442/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7865 - val_loss: 0.5125 - val_accuracy: 0.7760\n",
            "Epoch 443/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7847 - val_loss: 0.5124 - val_accuracy: 0.7760\n",
            "Epoch 444/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.7882 - val_loss: 0.5123 - val_accuracy: 0.7760\n",
            "Epoch 445/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4274 - accuracy: 0.7882 - val_loss: 0.5123 - val_accuracy: 0.7760\n",
            "Epoch 446/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4274 - accuracy: 0.7899 - val_loss: 0.5124 - val_accuracy: 0.7760\n",
            "Epoch 447/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.7899 - val_loss: 0.5123 - val_accuracy: 0.7760\n",
            "Epoch 448/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.7865 - val_loss: 0.5124 - val_accuracy: 0.7760\n",
            "Epoch 449/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.7812 - val_loss: 0.5125 - val_accuracy: 0.7760\n",
            "Epoch 450/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.7899 - val_loss: 0.5125 - val_accuracy: 0.7812\n",
            "Epoch 451/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.7865 - val_loss: 0.5126 - val_accuracy: 0.7812\n",
            "Epoch 452/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.7899 - val_loss: 0.5126 - val_accuracy: 0.7812\n",
            "Epoch 453/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.7899 - val_loss: 0.5126 - val_accuracy: 0.7812\n",
            "Epoch 454/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.7865 - val_loss: 0.5127 - val_accuracy: 0.7812\n",
            "Epoch 455/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7934 - val_loss: 0.5126 - val_accuracy: 0.7812\n",
            "Epoch 456/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7882 - val_loss: 0.5127 - val_accuracy: 0.7812\n",
            "Epoch 457/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.7882 - val_loss: 0.5127 - val_accuracy: 0.7812\n",
            "Epoch 458/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.7917 - val_loss: 0.5126 - val_accuracy: 0.7812\n",
            "Epoch 459/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7899 - val_loss: 0.5127 - val_accuracy: 0.7812\n",
            "Epoch 460/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4264 - accuracy: 0.7899 - val_loss: 0.5127 - val_accuracy: 0.7812\n",
            "Epoch 461/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.7882 - val_loss: 0.5128 - val_accuracy: 0.7865\n",
            "Epoch 462/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.7882 - val_loss: 0.5127 - val_accuracy: 0.7812\n",
            "Epoch 463/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.7917 - val_loss: 0.5127 - val_accuracy: 0.7865\n",
            "Epoch 464/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4264 - accuracy: 0.7899 - val_loss: 0.5127 - val_accuracy: 0.7865\n",
            "Epoch 465/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4261 - accuracy: 0.7882 - val_loss: 0.5129 - val_accuracy: 0.7865\n",
            "Epoch 466/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7899 - val_loss: 0.5128 - val_accuracy: 0.7865\n",
            "Epoch 467/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.7899 - val_loss: 0.5128 - val_accuracy: 0.7865\n",
            "Epoch 468/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7899 - val_loss: 0.5128 - val_accuracy: 0.7865\n",
            "Epoch 469/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.7882 - val_loss: 0.5128 - val_accuracy: 0.7865\n",
            "Epoch 470/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7934 - val_loss: 0.5128 - val_accuracy: 0.7865\n",
            "Epoch 471/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.7899 - val_loss: 0.5128 - val_accuracy: 0.7865\n",
            "Epoch 472/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7882 - val_loss: 0.5128 - val_accuracy: 0.7865\n",
            "Epoch 473/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4255 - accuracy: 0.7882 - val_loss: 0.5129 - val_accuracy: 0.7865\n",
            "Epoch 474/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.7917 - val_loss: 0.5128 - val_accuracy: 0.7865\n",
            "Epoch 475/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.7899 - val_loss: 0.5128 - val_accuracy: 0.7865\n",
            "Epoch 476/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.7934 - val_loss: 0.5128 - val_accuracy: 0.7865\n",
            "Epoch 477/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7899 - val_loss: 0.5129 - val_accuracy: 0.7865\n",
            "Epoch 478/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7882 - val_loss: 0.5130 - val_accuracy: 0.7812\n",
            "Epoch 479/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.7899 - val_loss: 0.5130 - val_accuracy: 0.7812\n",
            "Epoch 480/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7899 - val_loss: 0.5130 - val_accuracy: 0.7812\n",
            "Epoch 481/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7899 - val_loss: 0.5130 - val_accuracy: 0.7865\n",
            "Epoch 482/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.7882 - val_loss: 0.5130 - val_accuracy: 0.7865\n",
            "Epoch 483/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.7899 - val_loss: 0.5132 - val_accuracy: 0.7812\n",
            "Epoch 484/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.7882 - val_loss: 0.5131 - val_accuracy: 0.7812\n",
            "Epoch 485/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.7899 - val_loss: 0.5131 - val_accuracy: 0.7812\n",
            "Epoch 486/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.7899 - val_loss: 0.5133 - val_accuracy: 0.7812\n",
            "Epoch 487/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.7917 - val_loss: 0.5134 - val_accuracy: 0.7812\n",
            "Epoch 488/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.7917 - val_loss: 0.5133 - val_accuracy: 0.7812\n",
            "Epoch 489/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.7882 - val_loss: 0.5134 - val_accuracy: 0.7812\n",
            "Epoch 490/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7812\n",
            "Epoch 491/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.7899 - val_loss: 0.5133 - val_accuracy: 0.7812\n",
            "Epoch 492/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.7917 - val_loss: 0.5133 - val_accuracy: 0.7812\n",
            "Epoch 493/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.7917 - val_loss: 0.5132 - val_accuracy: 0.7760\n",
            "Epoch 494/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.7934 - val_loss: 0.5133 - val_accuracy: 0.7812\n",
            "Epoch 495/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.7934 - val_loss: 0.5133 - val_accuracy: 0.7812\n",
            "Epoch 496/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.7934 - val_loss: 0.5133 - val_accuracy: 0.7812\n",
            "Epoch 497/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7917 - val_loss: 0.5133 - val_accuracy: 0.7760\n",
            "Epoch 498/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7812\n",
            "Epoch 499/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.7934 - val_loss: 0.5132 - val_accuracy: 0.7760\n",
            "Epoch 500/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4233 - accuracy: 0.7934 - val_loss: 0.5133 - val_accuracy: 0.7760\n",
            "Epoch 501/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.7917 - val_loss: 0.5133 - val_accuracy: 0.7760\n",
            "Epoch 502/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.7934 - val_loss: 0.5131 - val_accuracy: 0.7760\n",
            "Epoch 503/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.7917 - val_loss: 0.5132 - val_accuracy: 0.7760\n",
            "Epoch 504/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.7934 - val_loss: 0.5133 - val_accuracy: 0.7708\n",
            "Epoch 505/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.7934 - val_loss: 0.5133 - val_accuracy: 0.7708\n",
            "Epoch 506/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.7934 - val_loss: 0.5134 - val_accuracy: 0.7708\n",
            "Epoch 507/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7760\n",
            "Epoch 508/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7899 - val_loss: 0.5135 - val_accuracy: 0.7708\n",
            "Epoch 509/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7899 - val_loss: 0.5133 - val_accuracy: 0.7760\n",
            "Epoch 510/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7917 - val_loss: 0.5133 - val_accuracy: 0.7760\n",
            "Epoch 511/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4224 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7708\n",
            "Epoch 512/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7934 - val_loss: 0.5135 - val_accuracy: 0.7708\n",
            "Epoch 513/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.7934 - val_loss: 0.5134 - val_accuracy: 0.7708\n",
            "Epoch 514/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.7969 - val_loss: 0.5135 - val_accuracy: 0.7708\n",
            "Epoch 515/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7708\n",
            "Epoch 516/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7708\n",
            "Epoch 517/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7708\n",
            "Epoch 518/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.7934 - val_loss: 0.5133 - val_accuracy: 0.7708\n",
            "Epoch 519/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7969 - val_loss: 0.5132 - val_accuracy: 0.7708\n",
            "Epoch 520/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7934 - val_loss: 0.5131 - val_accuracy: 0.7708\n",
            "Epoch 521/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.7934 - val_loss: 0.5131 - val_accuracy: 0.7708\n",
            "Epoch 522/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.7934 - val_loss: 0.5130 - val_accuracy: 0.7708\n",
            "Epoch 523/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.7951 - val_loss: 0.5130 - val_accuracy: 0.7708\n",
            "Epoch 524/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.7951 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
            "Epoch 525/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
            "Epoch 526/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.7917 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
            "Epoch 527/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
            "Epoch 528/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.7951 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
            "Epoch 529/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7951 - val_loss: 0.5127 - val_accuracy: 0.7708\n",
            "Epoch 530/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7951 - val_loss: 0.5126 - val_accuracy: 0.7708\n",
            "Epoch 531/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4202 - accuracy: 0.7951 - val_loss: 0.5126 - val_accuracy: 0.7708\n",
            "Epoch 532/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.7969 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 533/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.7951 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 534/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4200 - accuracy: 0.7951 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 535/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4197 - accuracy: 0.7969 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 536/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4197 - accuracy: 0.7969 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 537/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.7951 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 538/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4194 - accuracy: 0.7951 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 539/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.7934 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 540/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4192 - accuracy: 0.7969 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 541/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4193 - accuracy: 0.7934 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 542/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.7951 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
            "Epoch 543/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4191 - accuracy: 0.7969 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 544/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4188 - accuracy: 0.7951 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
            "Epoch 545/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.7986 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 546/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.7917 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 547/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4185 - accuracy: 0.7934 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 548/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4186 - accuracy: 0.7969 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 549/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4183 - accuracy: 0.7969 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
            "Epoch 550/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4182 - accuracy: 0.7951 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
            "Epoch 551/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4184 - accuracy: 0.7882 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
            "Epoch 552/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4181 - accuracy: 0.7969 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
            "Epoch 553/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4180 - accuracy: 0.7934 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
            "Epoch 554/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4179 - accuracy: 0.7951 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
            "Epoch 555/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.7951 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
            "Epoch 556/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.7934 - val_loss: 0.5126 - val_accuracy: 0.7604\n",
            "Epoch 557/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4175 - accuracy: 0.7934 - val_loss: 0.5126 - val_accuracy: 0.7604\n",
            "Epoch 558/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4176 - accuracy: 0.7917 - val_loss: 0.5127 - val_accuracy: 0.7604\n",
            "Epoch 559/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4177 - accuracy: 0.7934 - val_loss: 0.5129 - val_accuracy: 0.7604\n",
            "Epoch 560/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4174 - accuracy: 0.7934 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
            "Epoch 561/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4175 - accuracy: 0.7917 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
            "Epoch 562/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4171 - accuracy: 0.7917 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
            "Epoch 563/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4171 - accuracy: 0.7899 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
            "Epoch 564/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.7882 - val_loss: 0.5127 - val_accuracy: 0.7552\n",
            "Epoch 565/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4169 - accuracy: 0.7934 - val_loss: 0.5127 - val_accuracy: 0.7552\n",
            "Epoch 566/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4168 - accuracy: 0.7917 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
            "Epoch 567/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.7917 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 568/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.7934 - val_loss: 0.5126 - val_accuracy: 0.7604\n",
            "Epoch 569/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4169 - accuracy: 0.7969 - val_loss: 0.5127 - val_accuracy: 0.7552\n",
            "Epoch 570/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.7882 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
            "Epoch 571/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.7917 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 572/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.7917 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 573/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4162 - accuracy: 0.7934 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 574/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.7882 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 575/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4161 - accuracy: 0.7899 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 576/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.7882 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 577/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4161 - accuracy: 0.7882 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 578/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4157 - accuracy: 0.7865 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
            "Epoch 579/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4158 - accuracy: 0.7899 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 580/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4157 - accuracy: 0.7934 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 581/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.7917 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 582/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.7865 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
            "Epoch 583/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4154 - accuracy: 0.7917 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
            "Epoch 584/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.7882 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
            "Epoch 585/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4152 - accuracy: 0.7899 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
            "Epoch 586/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.7882 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
            "Epoch 587/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.7882 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 588/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.7865 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 589/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4150 - accuracy: 0.7882 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 590/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.7882 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 591/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4148 - accuracy: 0.7882 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 592/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.7865 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
            "Epoch 593/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.7865 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
            "Epoch 594/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.7865 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
            "Epoch 595/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.7865 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
            "Epoch 596/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.7899 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
            "Epoch 597/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.7899 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
            "Epoch 598/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.7882 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
            "Epoch 599/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4139 - accuracy: 0.7917 - val_loss: 0.5121 - val_accuracy: 0.7604\n",
            "Epoch 600/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.7917 - val_loss: 0.5121 - val_accuracy: 0.7604\n",
            "Epoch 601/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.7934 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
            "Epoch 602/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4138 - accuracy: 0.7882 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
            "Epoch 603/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4137 - accuracy: 0.7865 - val_loss: 0.5121 - val_accuracy: 0.7604\n",
            "Epoch 604/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4135 - accuracy: 0.7847 - val_loss: 0.5121 - val_accuracy: 0.7604\n",
            "Epoch 605/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.7847 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
            "Epoch 606/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4133 - accuracy: 0.7847 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
            "Epoch 607/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.7917 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
            "Epoch 608/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4133 - accuracy: 0.7899 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
            "Epoch 609/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.7934 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
            "Epoch 610/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4129 - accuracy: 0.7986 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
            "Epoch 611/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4130 - accuracy: 0.7917 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
            "Epoch 612/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.7917 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
            "Epoch 613/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.7899 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
            "Epoch 614/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.7882 - val_loss: 0.5117 - val_accuracy: 0.7604\n",
            "Epoch 615/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4126 - accuracy: 0.7951 - val_loss: 0.5118 - val_accuracy: 0.7656\n",
            "Epoch 616/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4126 - accuracy: 0.7969 - val_loss: 0.5120 - val_accuracy: 0.7656\n",
            "Epoch 617/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4124 - accuracy: 0.7917 - val_loss: 0.5118 - val_accuracy: 0.7656\n",
            "Epoch 618/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.7934 - val_loss: 0.5119 - val_accuracy: 0.7656\n",
            "Epoch 619/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4122 - accuracy: 0.7951 - val_loss: 0.5117 - val_accuracy: 0.7656\n",
            "Epoch 620/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.7934 - val_loss: 0.5115 - val_accuracy: 0.7656\n",
            "Epoch 621/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.7917 - val_loss: 0.5114 - val_accuracy: 0.7656\n",
            "Epoch 622/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.7934 - val_loss: 0.5114 - val_accuracy: 0.7656\n",
            "Epoch 623/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.7934 - val_loss: 0.5114 - val_accuracy: 0.7656\n",
            "Epoch 624/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7656\n",
            "Epoch 625/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.7934 - val_loss: 0.5111 - val_accuracy: 0.7656\n",
            "Epoch 626/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.7899 - val_loss: 0.5111 - val_accuracy: 0.7656\n",
            "Epoch 627/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4115 - accuracy: 0.7934 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
            "Epoch 628/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4114 - accuracy: 0.7986 - val_loss: 0.5111 - val_accuracy: 0.7656\n",
            "Epoch 629/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.7934 - val_loss: 0.5111 - val_accuracy: 0.7656\n",
            "Epoch 630/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.7951 - val_loss: 0.5111 - val_accuracy: 0.7656\n",
            "Epoch 631/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.7951 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
            "Epoch 632/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.7917 - val_loss: 0.5110 - val_accuracy: 0.7604\n",
            "Epoch 633/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.7951 - val_loss: 0.5110 - val_accuracy: 0.7552\n",
            "Epoch 634/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.7934 - val_loss: 0.5110 - val_accuracy: 0.7552\n",
            "Epoch 635/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.7951 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
            "Epoch 636/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4110 - accuracy: 0.7951 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
            "Epoch 637/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.7969 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
            "Epoch 638/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.7951 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
            "Epoch 639/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.7969 - val_loss: 0.5109 - val_accuracy: 0.7604\n",
            "Epoch 640/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.7934 - val_loss: 0.5109 - val_accuracy: 0.7604\n",
            "Epoch 641/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.7934 - val_loss: 0.5107 - val_accuracy: 0.7604\n",
            "Epoch 642/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7604\n",
            "Epoch 643/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4102 - accuracy: 0.7969 - val_loss: 0.5105 - val_accuracy: 0.7552\n",
            "Epoch 644/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.7951 - val_loss: 0.5104 - val_accuracy: 0.7552\n",
            "Epoch 645/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4100 - accuracy: 0.7951 - val_loss: 0.5103 - val_accuracy: 0.7604\n",
            "Epoch 646/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.7917 - val_loss: 0.5103 - val_accuracy: 0.7604\n",
            "Epoch 647/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.7934 - val_loss: 0.5104 - val_accuracy: 0.7604\n",
            "Epoch 648/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.7899 - val_loss: 0.5103 - val_accuracy: 0.7604\n",
            "Epoch 649/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.7917 - val_loss: 0.5104 - val_accuracy: 0.7604\n",
            "Epoch 650/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.7917 - val_loss: 0.5102 - val_accuracy: 0.7604\n",
            "Epoch 651/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.7899 - val_loss: 0.5101 - val_accuracy: 0.7604\n",
            "Epoch 652/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.7899 - val_loss: 0.5099 - val_accuracy: 0.7604\n",
            "Epoch 653/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.7882 - val_loss: 0.5097 - val_accuracy: 0.7604\n",
            "Epoch 654/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.7882 - val_loss: 0.5097 - val_accuracy: 0.7604\n",
            "Epoch 655/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.7899 - val_loss: 0.5096 - val_accuracy: 0.7604\n",
            "Epoch 656/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.7917 - val_loss: 0.5097 - val_accuracy: 0.7604\n",
            "Epoch 657/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.7917 - val_loss: 0.5096 - val_accuracy: 0.7604\n",
            "Epoch 658/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.7899 - val_loss: 0.5097 - val_accuracy: 0.7604\n",
            "Epoch 659/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4092 - accuracy: 0.7934 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
            "Epoch 660/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4088 - accuracy: 0.7899 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
            "Epoch 661/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.7882 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
            "Epoch 662/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.7899 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
            "Epoch 663/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.7899 - val_loss: 0.5093 - val_accuracy: 0.7604\n",
            "Epoch 664/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.7899 - val_loss: 0.5092 - val_accuracy: 0.7604\n",
            "Epoch 665/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.7917 - val_loss: 0.5091 - val_accuracy: 0.7604\n",
            "Epoch 666/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.7865 - val_loss: 0.5091 - val_accuracy: 0.7604\n",
            "Epoch 667/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.7882 - val_loss: 0.5090 - val_accuracy: 0.7604\n",
            "Epoch 668/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4081 - accuracy: 0.7899 - val_loss: 0.5091 - val_accuracy: 0.7604\n",
            "Epoch 669/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.7899 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
            "Epoch 670/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.7917 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
            "Epoch 671/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4081 - accuracy: 0.7882 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
            "Epoch 672/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.7899 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
            "Epoch 673/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4079 - accuracy: 0.7882 - val_loss: 0.5088 - val_accuracy: 0.7656\n",
            "Epoch 674/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.7917 - val_loss: 0.5087 - val_accuracy: 0.7656\n",
            "Epoch 675/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.7917 - val_loss: 0.5086 - val_accuracy: 0.7552\n",
            "Epoch 676/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7604\n",
            "Epoch 677/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4079 - accuracy: 0.7899 - val_loss: 0.5084 - val_accuracy: 0.7604\n",
            "Epoch 678/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4078 - accuracy: 0.7882 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
            "Epoch 679/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4075 - accuracy: 0.7899 - val_loss: 0.5086 - val_accuracy: 0.7604\n",
            "Epoch 680/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4074 - accuracy: 0.7917 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
            "Epoch 681/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4074 - accuracy: 0.7899 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
            "Epoch 682/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.7899 - val_loss: 0.5085 - val_accuracy: 0.7604\n",
            "Epoch 683/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4074 - accuracy: 0.7934 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
            "Epoch 684/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.7917 - val_loss: 0.5084 - val_accuracy: 0.7656\n",
            "Epoch 685/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4072 - accuracy: 0.7882 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
            "Epoch 686/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.7882 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
            "Epoch 687/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4072 - accuracy: 0.7917 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
            "Epoch 688/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4071 - accuracy: 0.7917 - val_loss: 0.5085 - val_accuracy: 0.7656\n",
            "Epoch 689/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4071 - accuracy: 0.7917 - val_loss: 0.5085 - val_accuracy: 0.7656\n",
            "Epoch 690/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4072 - accuracy: 0.7917 - val_loss: 0.5085 - val_accuracy: 0.7656\n",
            "Epoch 691/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4068 - accuracy: 0.7899 - val_loss: 0.5085 - val_accuracy: 0.7656\n",
            "Epoch 692/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.7899 - val_loss: 0.5082 - val_accuracy: 0.7656\n",
            "Epoch 693/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4069 - accuracy: 0.7899 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
            "Epoch 694/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4067 - accuracy: 0.7934 - val_loss: 0.5083 - val_accuracy: 0.7708\n",
            "Epoch 695/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4064 - accuracy: 0.7917 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
            "Epoch 696/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4068 - accuracy: 0.7917 - val_loss: 0.5084 - val_accuracy: 0.7708\n",
            "Epoch 697/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4066 - accuracy: 0.7899 - val_loss: 0.5083 - val_accuracy: 0.7708\n",
            "Epoch 698/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4064 - accuracy: 0.7917 - val_loss: 0.5082 - val_accuracy: 0.7708\n",
            "Epoch 699/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4065 - accuracy: 0.7899 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
            "Epoch 700/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4063 - accuracy: 0.7899 - val_loss: 0.5079 - val_accuracy: 0.7656\n",
            "Epoch 701/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4064 - accuracy: 0.7917 - val_loss: 0.5078 - val_accuracy: 0.7656\n",
            "Epoch 702/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4065 - accuracy: 0.7934 - val_loss: 0.5079 - val_accuracy: 0.7656\n",
            "Epoch 703/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4062 - accuracy: 0.7899 - val_loss: 0.5078 - val_accuracy: 0.7656\n",
            "Epoch 704/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.7882 - val_loss: 0.5077 - val_accuracy: 0.7604\n",
            "Epoch 705/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.7917 - val_loss: 0.5078 - val_accuracy: 0.7708\n",
            "Epoch 706/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.7899 - val_loss: 0.5076 - val_accuracy: 0.7656\n",
            "Epoch 707/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4059 - accuracy: 0.7934 - val_loss: 0.5077 - val_accuracy: 0.7708\n",
            "Epoch 708/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4060 - accuracy: 0.7917 - val_loss: 0.5078 - val_accuracy: 0.7708\n",
            "Epoch 709/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.7899 - val_loss: 0.5075 - val_accuracy: 0.7708\n",
            "Epoch 710/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4057 - accuracy: 0.7899 - val_loss: 0.5074 - val_accuracy: 0.7656\n",
            "Epoch 711/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.7917 - val_loss: 0.5076 - val_accuracy: 0.7760\n",
            "Epoch 712/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4057 - accuracy: 0.7882 - val_loss: 0.5076 - val_accuracy: 0.7708\n",
            "Epoch 713/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4057 - accuracy: 0.7917 - val_loss: 0.5075 - val_accuracy: 0.7708\n",
            "Epoch 714/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4057 - accuracy: 0.7882 - val_loss: 0.5074 - val_accuracy: 0.7656\n",
            "Epoch 715/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.7934 - val_loss: 0.5076 - val_accuracy: 0.7760\n",
            "Epoch 716/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.7934 - val_loss: 0.5076 - val_accuracy: 0.7760\n",
            "Epoch 717/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4054 - accuracy: 0.7917 - val_loss: 0.5077 - val_accuracy: 0.7760\n",
            "Epoch 718/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4052 - accuracy: 0.7917 - val_loss: 0.5076 - val_accuracy: 0.7760\n",
            "Epoch 719/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.7917 - val_loss: 0.5079 - val_accuracy: 0.7760\n",
            "Epoch 720/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4052 - accuracy: 0.7882 - val_loss: 0.5080 - val_accuracy: 0.7760\n",
            "Epoch 721/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.7917 - val_loss: 0.5079 - val_accuracy: 0.7760\n",
            "Epoch 722/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.7917 - val_loss: 0.5080 - val_accuracy: 0.7760\n",
            "Epoch 723/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4053 - accuracy: 0.7882 - val_loss: 0.5076 - val_accuracy: 0.7760\n",
            "Epoch 724/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4052 - accuracy: 0.7899 - val_loss: 0.5075 - val_accuracy: 0.7760\n",
            "Epoch 725/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.7899 - val_loss: 0.5076 - val_accuracy: 0.7760\n",
            "Epoch 726/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4049 - accuracy: 0.7934 - val_loss: 0.5075 - val_accuracy: 0.7708\n",
            "Epoch 727/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.7934 - val_loss: 0.5076 - val_accuracy: 0.7760\n",
            "Epoch 728/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.7882 - val_loss: 0.5076 - val_accuracy: 0.7760\n",
            "Epoch 729/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.7882 - val_loss: 0.5075 - val_accuracy: 0.7760\n",
            "Epoch 730/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4049 - accuracy: 0.7917 - val_loss: 0.5074 - val_accuracy: 0.7760\n",
            "Epoch 731/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4046 - accuracy: 0.7882 - val_loss: 0.5075 - val_accuracy: 0.7760\n",
            "Epoch 732/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4047 - accuracy: 0.7899 - val_loss: 0.5074 - val_accuracy: 0.7760\n",
            "Epoch 733/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4046 - accuracy: 0.7899 - val_loss: 0.5074 - val_accuracy: 0.7760\n",
            "Epoch 734/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.7917 - val_loss: 0.5077 - val_accuracy: 0.7760\n",
            "Epoch 735/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4047 - accuracy: 0.7917 - val_loss: 0.5073 - val_accuracy: 0.7760\n",
            "Epoch 736/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.7899 - val_loss: 0.5075 - val_accuracy: 0.7760\n",
            "Epoch 737/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.7899 - val_loss: 0.5075 - val_accuracy: 0.7760\n",
            "Epoch 738/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.7882 - val_loss: 0.5076 - val_accuracy: 0.7760\n",
            "Epoch 739/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.7899 - val_loss: 0.5075 - val_accuracy: 0.7760\n",
            "Epoch 740/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.7865 - val_loss: 0.5074 - val_accuracy: 0.7760\n",
            "Epoch 741/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.7899 - val_loss: 0.5075 - val_accuracy: 0.7760\n",
            "Epoch 742/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.7899 - val_loss: 0.5074 - val_accuracy: 0.7760\n",
            "Epoch 743/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.7899 - val_loss: 0.5075 - val_accuracy: 0.7760\n",
            "Epoch 744/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.7917 - val_loss: 0.5074 - val_accuracy: 0.7760\n",
            "Epoch 745/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.7882 - val_loss: 0.5073 - val_accuracy: 0.7760\n",
            "Epoch 746/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4041 - accuracy: 0.7899 - val_loss: 0.5075 - val_accuracy: 0.7760\n",
            "Epoch 747/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.7865 - val_loss: 0.5074 - val_accuracy: 0.7760\n",
            "Epoch 748/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.7882 - val_loss: 0.5074 - val_accuracy: 0.7760\n",
            "Epoch 749/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4038 - accuracy: 0.7899 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
            "Epoch 750/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.7917 - val_loss: 0.5072 - val_accuracy: 0.7760\n",
            "Epoch 751/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4038 - accuracy: 0.7882 - val_loss: 0.5072 - val_accuracy: 0.7708\n",
            "Epoch 752/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4037 - accuracy: 0.7917 - val_loss: 0.5074 - val_accuracy: 0.7760\n",
            "Epoch 753/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.7882 - val_loss: 0.5074 - val_accuracy: 0.7760\n",
            "Epoch 754/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4037 - accuracy: 0.7917 - val_loss: 0.5076 - val_accuracy: 0.7760\n",
            "Epoch 755/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.7899 - val_loss: 0.5076 - val_accuracy: 0.7760\n",
            "Epoch 756/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4037 - accuracy: 0.7882 - val_loss: 0.5075 - val_accuracy: 0.7760\n",
            "Epoch 757/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.7882 - val_loss: 0.5072 - val_accuracy: 0.7760\n",
            "Epoch 758/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.7899 - val_loss: 0.5074 - val_accuracy: 0.7760\n",
            "Epoch 759/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4036 - accuracy: 0.7899 - val_loss: 0.5073 - val_accuracy: 0.7760\n",
            "Epoch 760/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7760\n",
            "Epoch 761/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4035 - accuracy: 0.7882 - val_loss: 0.5069 - val_accuracy: 0.7656\n",
            "Epoch 762/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.7934 - val_loss: 0.5072 - val_accuracy: 0.7760\n",
            "Epoch 763/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.7899 - val_loss: 0.5069 - val_accuracy: 0.7708\n",
            "Epoch 764/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4033 - accuracy: 0.7917 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
            "Epoch 765/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4032 - accuracy: 0.7917 - val_loss: 0.5068 - val_accuracy: 0.7708\n",
            "Epoch 766/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4033 - accuracy: 0.7934 - val_loss: 0.5072 - val_accuracy: 0.7708\n",
            "Epoch 767/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4030 - accuracy: 0.7934 - val_loss: 0.5072 - val_accuracy: 0.7708\n",
            "Epoch 768/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.7917 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
            "Epoch 769/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4030 - accuracy: 0.7899 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
            "Epoch 770/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.7934 - val_loss: 0.5073 - val_accuracy: 0.7760\n",
            "Epoch 771/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4031 - accuracy: 0.7917 - val_loss: 0.5075 - val_accuracy: 0.7760\n",
            "Epoch 772/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4028 - accuracy: 0.7917 - val_loss: 0.5074 - val_accuracy: 0.7708\n",
            "Epoch 773/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.7917 - val_loss: 0.5074 - val_accuracy: 0.7760\n",
            "Epoch 774/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4028 - accuracy: 0.7934 - val_loss: 0.5076 - val_accuracy: 0.7760\n",
            "Epoch 775/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4028 - accuracy: 0.7917 - val_loss: 0.5079 - val_accuracy: 0.7760\n",
            "Epoch 776/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4028 - accuracy: 0.7917 - val_loss: 0.5079 - val_accuracy: 0.7760\n",
            "Epoch 777/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.7986 - val_loss: 0.5077 - val_accuracy: 0.7760\n",
            "Epoch 778/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4030 - accuracy: 0.7899 - val_loss: 0.5075 - val_accuracy: 0.7708\n",
            "Epoch 779/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4026 - accuracy: 0.7951 - val_loss: 0.5077 - val_accuracy: 0.7760\n",
            "Epoch 780/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.7934 - val_loss: 0.5080 - val_accuracy: 0.7760\n",
            "Epoch 781/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4027 - accuracy: 0.7934 - val_loss: 0.5079 - val_accuracy: 0.7760\n",
            "Epoch 782/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4025 - accuracy: 0.7917 - val_loss: 0.5078 - val_accuracy: 0.7760\n",
            "Epoch 783/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4030 - accuracy: 0.7951 - val_loss: 0.5080 - val_accuracy: 0.7760\n",
            "Epoch 784/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4028 - accuracy: 0.7951 - val_loss: 0.5080 - val_accuracy: 0.7760\n",
            "Epoch 785/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.7917 - val_loss: 0.5078 - val_accuracy: 0.7708\n",
            "Epoch 786/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.7986 - val_loss: 0.5080 - val_accuracy: 0.7760\n",
            "Epoch 787/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4024 - accuracy: 0.7934 - val_loss: 0.5082 - val_accuracy: 0.7760\n",
            "Epoch 788/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.7969 - val_loss: 0.5081 - val_accuracy: 0.7760\n",
            "Epoch 789/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4024 - accuracy: 0.7882 - val_loss: 0.5081 - val_accuracy: 0.7760\n",
            "Epoch 790/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.7934 - val_loss: 0.5082 - val_accuracy: 0.7760\n",
            "Epoch 791/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.7951 - val_loss: 0.5084 - val_accuracy: 0.7760\n",
            "Epoch 792/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4024 - accuracy: 0.7917 - val_loss: 0.5083 - val_accuracy: 0.7760\n",
            "Epoch 793/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.7934 - val_loss: 0.5083 - val_accuracy: 0.7760\n",
            "Epoch 794/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.7951 - val_loss: 0.5084 - val_accuracy: 0.7760\n",
            "Epoch 795/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7760\n",
            "Epoch 796/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4022 - accuracy: 0.7934 - val_loss: 0.5083 - val_accuracy: 0.7760\n",
            "Epoch 797/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.7917 - val_loss: 0.5081 - val_accuracy: 0.7708\n",
            "Epoch 798/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.7951 - val_loss: 0.5082 - val_accuracy: 0.7760\n",
            "Epoch 799/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4020 - accuracy: 0.7951 - val_loss: 0.5082 - val_accuracy: 0.7760\n",
            "Epoch 800/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.7969 - val_loss: 0.5084 - val_accuracy: 0.7760\n",
            "Epoch 801/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.8003 - val_loss: 0.5085 - val_accuracy: 0.7760\n",
            "Epoch 802/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.7899 - val_loss: 0.5083 - val_accuracy: 0.7760\n",
            "Epoch 803/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4019 - accuracy: 0.7951 - val_loss: 0.5084 - val_accuracy: 0.7760\n",
            "Epoch 804/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4017 - accuracy: 0.7986 - val_loss: 0.5086 - val_accuracy: 0.7760\n",
            "Epoch 805/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.7986 - val_loss: 0.5087 - val_accuracy: 0.7760\n",
            "Epoch 806/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.7951 - val_loss: 0.5085 - val_accuracy: 0.7760\n",
            "Epoch 807/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.7934 - val_loss: 0.5087 - val_accuracy: 0.7760\n",
            "Epoch 808/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4017 - accuracy: 0.7951 - val_loss: 0.5088 - val_accuracy: 0.7760\n",
            "Epoch 809/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4018 - accuracy: 0.7986 - val_loss: 0.5085 - val_accuracy: 0.7760\n",
            "Epoch 810/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4017 - accuracy: 0.7917 - val_loss: 0.5086 - val_accuracy: 0.7708\n",
            "Epoch 811/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4016 - accuracy: 0.7934 - val_loss: 0.5086 - val_accuracy: 0.7760\n",
            "Epoch 812/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4018 - accuracy: 0.7986 - val_loss: 0.5089 - val_accuracy: 0.7760\n",
            "Epoch 813/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.7969 - val_loss: 0.5089 - val_accuracy: 0.7760\n",
            "Epoch 814/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4017 - accuracy: 0.7969 - val_loss: 0.5089 - val_accuracy: 0.7760\n",
            "Epoch 815/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4018 - accuracy: 0.7969 - val_loss: 0.5090 - val_accuracy: 0.7760\n",
            "Epoch 816/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4015 - accuracy: 0.7986 - val_loss: 0.5089 - val_accuracy: 0.7760\n",
            "Epoch 817/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4016 - accuracy: 0.7934 - val_loss: 0.5090 - val_accuracy: 0.7760\n",
            "Epoch 818/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4014 - accuracy: 0.7969 - val_loss: 0.5093 - val_accuracy: 0.7760\n",
            "Epoch 819/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4016 - accuracy: 0.7951 - val_loss: 0.5095 - val_accuracy: 0.7760\n",
            "Epoch 820/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4015 - accuracy: 0.7934 - val_loss: 0.5094 - val_accuracy: 0.7760\n",
            "Epoch 821/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4015 - accuracy: 0.7986 - val_loss: 0.5095 - val_accuracy: 0.7760\n",
            "Epoch 822/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4015 - accuracy: 0.7934 - val_loss: 0.5092 - val_accuracy: 0.7760\n",
            "Epoch 823/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4014 - accuracy: 0.7951 - val_loss: 0.5094 - val_accuracy: 0.7760\n",
            "Epoch 824/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4015 - accuracy: 0.7986 - val_loss: 0.5097 - val_accuracy: 0.7760\n",
            "Epoch 825/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4013 - accuracy: 0.7969 - val_loss: 0.5094 - val_accuracy: 0.7760\n",
            "Epoch 826/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4015 - accuracy: 0.7969 - val_loss: 0.5094 - val_accuracy: 0.7760\n",
            "Epoch 827/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4015 - accuracy: 0.7951 - val_loss: 0.5095 - val_accuracy: 0.7760\n",
            "Epoch 828/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4013 - accuracy: 0.7934 - val_loss: 0.5094 - val_accuracy: 0.7760\n",
            "Epoch 829/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4013 - accuracy: 0.7934 - val_loss: 0.5096 - val_accuracy: 0.7760\n",
            "Epoch 830/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4015 - accuracy: 0.7969 - val_loss: 0.5093 - val_accuracy: 0.7760\n",
            "Epoch 831/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4012 - accuracy: 0.8021 - val_loss: 0.5094 - val_accuracy: 0.7760\n",
            "Epoch 832/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4011 - accuracy: 0.7969 - val_loss: 0.5095 - val_accuracy: 0.7760\n",
            "Epoch 833/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4013 - accuracy: 0.7969 - val_loss: 0.5096 - val_accuracy: 0.7760\n",
            "Epoch 834/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4012 - accuracy: 0.8003 - val_loss: 0.5095 - val_accuracy: 0.7760\n",
            "Epoch 835/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4013 - accuracy: 0.7934 - val_loss: 0.5093 - val_accuracy: 0.7760\n",
            "Epoch 836/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4011 - accuracy: 0.7951 - val_loss: 0.5091 - val_accuracy: 0.7760\n",
            "Epoch 837/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4012 - accuracy: 0.8021 - val_loss: 0.5093 - val_accuracy: 0.7760\n",
            "Epoch 838/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4010 - accuracy: 0.8003 - val_loss: 0.5095 - val_accuracy: 0.7760\n",
            "Epoch 839/1500\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.4011 - accuracy: 0.7951 - val_loss: 0.5095 - val_accuracy: 0.7760\n",
            "Epoch 840/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4011 - accuracy: 0.8003 - val_loss: 0.5098 - val_accuracy: 0.7760\n",
            "Epoch 841/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4011 - accuracy: 0.7951 - val_loss: 0.5100 - val_accuracy: 0.7760\n",
            "Epoch 842/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4012 - accuracy: 0.8021 - val_loss: 0.5097 - val_accuracy: 0.7760\n",
            "Epoch 843/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4011 - accuracy: 0.8038 - val_loss: 0.5096 - val_accuracy: 0.7760\n",
            "Epoch 844/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4010 - accuracy: 0.7986 - val_loss: 0.5098 - val_accuracy: 0.7760\n",
            "Epoch 845/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4013 - accuracy: 0.8003 - val_loss: 0.5099 - val_accuracy: 0.7760\n",
            "Epoch 846/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4013 - accuracy: 0.7969 - val_loss: 0.5097 - val_accuracy: 0.7760\n",
            "Epoch 847/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4009 - accuracy: 0.8021 - val_loss: 0.5100 - val_accuracy: 0.7760\n",
            "Epoch 848/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4008 - accuracy: 0.7969 - val_loss: 0.5096 - val_accuracy: 0.7760\n",
            "Epoch 849/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8021 - val_loss: 0.5098 - val_accuracy: 0.7760\n",
            "Epoch 850/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4012 - accuracy: 0.7986 - val_loss: 0.5099 - val_accuracy: 0.7760\n",
            "Epoch 851/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4010 - accuracy: 0.8003 - val_loss: 0.5098 - val_accuracy: 0.7760\n",
            "Epoch 852/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4012 - accuracy: 0.8021 - val_loss: 0.5097 - val_accuracy: 0.7760\n",
            "Epoch 853/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4008 - accuracy: 0.8021 - val_loss: 0.5100 - val_accuracy: 0.7760\n",
            "Epoch 854/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4006 - accuracy: 0.8038 - val_loss: 0.5099 - val_accuracy: 0.7760\n",
            "Epoch 855/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4007 - accuracy: 0.7951 - val_loss: 0.5097 - val_accuracy: 0.7760\n",
            "Epoch 856/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4007 - accuracy: 0.8056 - val_loss: 0.5098 - val_accuracy: 0.7760\n",
            "Epoch 857/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4007 - accuracy: 0.7969 - val_loss: 0.5100 - val_accuracy: 0.7760\n",
            "Epoch 858/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4007 - accuracy: 0.8003 - val_loss: 0.5103 - val_accuracy: 0.7760\n",
            "Epoch 859/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4005 - accuracy: 0.8021 - val_loss: 0.5102 - val_accuracy: 0.7760\n",
            "Epoch 860/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8021 - val_loss: 0.5101 - val_accuracy: 0.7760\n",
            "Epoch 861/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8038 - val_loss: 0.5099 - val_accuracy: 0.7760\n",
            "Epoch 862/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8021 - val_loss: 0.5098 - val_accuracy: 0.7760\n",
            "Epoch 863/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4005 - accuracy: 0.8038 - val_loss: 0.5099 - val_accuracy: 0.7760\n",
            "Epoch 864/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4006 - accuracy: 0.8021 - val_loss: 0.5102 - val_accuracy: 0.7760\n",
            "Epoch 865/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8038 - val_loss: 0.5100 - val_accuracy: 0.7760\n",
            "Epoch 866/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4006 - accuracy: 0.8038 - val_loss: 0.5104 - val_accuracy: 0.7760\n",
            "Epoch 867/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4007 - accuracy: 0.8056 - val_loss: 0.5106 - val_accuracy: 0.7760\n",
            "Epoch 868/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.7969 - val_loss: 0.5106 - val_accuracy: 0.7760\n",
            "Epoch 869/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4005 - accuracy: 0.7969 - val_loss: 0.5104 - val_accuracy: 0.7760\n",
            "Epoch 870/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4006 - accuracy: 0.8021 - val_loss: 0.5106 - val_accuracy: 0.7760\n",
            "Epoch 871/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4006 - accuracy: 0.8021 - val_loss: 0.5106 - val_accuracy: 0.7760\n",
            "Epoch 872/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4004 - accuracy: 0.8056 - val_loss: 0.5104 - val_accuracy: 0.7760\n",
            "Epoch 873/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4004 - accuracy: 0.8038 - val_loss: 0.5103 - val_accuracy: 0.7760\n",
            "Epoch 874/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4006 - accuracy: 0.8056 - val_loss: 0.5104 - val_accuracy: 0.7760\n",
            "Epoch 875/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.8090 - val_loss: 0.5105 - val_accuracy: 0.7760\n",
            "Epoch 876/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4005 - accuracy: 0.8021 - val_loss: 0.5107 - val_accuracy: 0.7760\n",
            "Epoch 877/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4004 - accuracy: 0.8021 - val_loss: 0.5105 - val_accuracy: 0.7760\n",
            "Epoch 878/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4007 - accuracy: 0.8073 - val_loss: 0.5105 - val_accuracy: 0.7760\n",
            "Epoch 879/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4006 - accuracy: 0.8056 - val_loss: 0.5107 - val_accuracy: 0.7760\n",
            "Epoch 880/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8038 - val_loss: 0.5105 - val_accuracy: 0.7760\n",
            "Epoch 881/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8038 - val_loss: 0.5105 - val_accuracy: 0.7760\n",
            "Epoch 882/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.8056 - val_loss: 0.5105 - val_accuracy: 0.7760\n",
            "Epoch 883/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.8090 - val_loss: 0.5109 - val_accuracy: 0.7760\n",
            "Epoch 884/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.7969 - val_loss: 0.5107 - val_accuracy: 0.7760\n",
            "Epoch 885/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4002 - accuracy: 0.8073 - val_loss: 0.5105 - val_accuracy: 0.7760\n",
            "Epoch 886/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.8021 - val_loss: 0.5109 - val_accuracy: 0.7760\n",
            "Epoch 887/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4000 - accuracy: 0.8003 - val_loss: 0.5107 - val_accuracy: 0.7760\n",
            "Epoch 888/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4001 - accuracy: 0.8021 - val_loss: 0.5104 - val_accuracy: 0.7708\n",
            "Epoch 889/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4002 - accuracy: 0.8073 - val_loss: 0.5106 - val_accuracy: 0.7708\n",
            "Epoch 890/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.8021 - val_loss: 0.5105 - val_accuracy: 0.7708\n",
            "Epoch 891/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8056 - val_loss: 0.5104 - val_accuracy: 0.7708\n",
            "Epoch 892/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.8056 - val_loss: 0.5105 - val_accuracy: 0.7708\n",
            "Epoch 893/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8073 - val_loss: 0.5106 - val_accuracy: 0.7708\n",
            "Epoch 894/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4000 - accuracy: 0.8021 - val_loss: 0.5108 - val_accuracy: 0.7708\n",
            "Epoch 895/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8038 - val_loss: 0.5111 - val_accuracy: 0.7708\n",
            "Epoch 896/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4002 - accuracy: 0.8056 - val_loss: 0.5108 - val_accuracy: 0.7708\n",
            "Epoch 897/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4000 - accuracy: 0.8003 - val_loss: 0.5104 - val_accuracy: 0.7656\n",
            "Epoch 898/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4000 - accuracy: 0.8038 - val_loss: 0.5107 - val_accuracy: 0.7656\n",
            "Epoch 899/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8038 - val_loss: 0.5108 - val_accuracy: 0.7656\n",
            "Epoch 900/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3997 - accuracy: 0.8073 - val_loss: 0.5110 - val_accuracy: 0.7708\n",
            "Epoch 901/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3998 - accuracy: 0.8038 - val_loss: 0.5111 - val_accuracy: 0.7656\n",
            "Epoch 902/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4000 - accuracy: 0.8038 - val_loss: 0.5112 - val_accuracy: 0.7656\n",
            "Epoch 903/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8073 - val_loss: 0.5112 - val_accuracy: 0.7656\n",
            "Epoch 904/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8056 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
            "Epoch 905/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8003 - val_loss: 0.5108 - val_accuracy: 0.7656\n",
            "Epoch 906/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8021 - val_loss: 0.5113 - val_accuracy: 0.7708\n",
            "Epoch 907/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8056 - val_loss: 0.5111 - val_accuracy: 0.7656\n",
            "Epoch 908/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8056 - val_loss: 0.5112 - val_accuracy: 0.7656\n",
            "Epoch 909/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3998 - accuracy: 0.8056 - val_loss: 0.5113 - val_accuracy: 0.7656\n",
            "Epoch 910/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8056 - val_loss: 0.5112 - val_accuracy: 0.7656\n",
            "Epoch 911/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3997 - accuracy: 0.8056 - val_loss: 0.5114 - val_accuracy: 0.7708\n",
            "Epoch 912/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3997 - accuracy: 0.8073 - val_loss: 0.5115 - val_accuracy: 0.7708\n",
            "Epoch 913/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3997 - accuracy: 0.8021 - val_loss: 0.5111 - val_accuracy: 0.7656\n",
            "Epoch 914/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.8073 - val_loss: 0.5109 - val_accuracy: 0.7656\n",
            "Epoch 915/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3996 - accuracy: 0.8073 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
            "Epoch 916/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3997 - accuracy: 0.8003 - val_loss: 0.5109 - val_accuracy: 0.7656\n",
            "Epoch 917/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3995 - accuracy: 0.8056 - val_loss: 0.5113 - val_accuracy: 0.7656\n",
            "Epoch 918/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8056 - val_loss: 0.5113 - val_accuracy: 0.7656\n",
            "Epoch 919/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3997 - accuracy: 0.8038 - val_loss: 0.5113 - val_accuracy: 0.7656\n",
            "Epoch 920/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8038 - val_loss: 0.5114 - val_accuracy: 0.7656\n",
            "Epoch 921/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3995 - accuracy: 0.8021 - val_loss: 0.5112 - val_accuracy: 0.7656\n",
            "Epoch 922/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3997 - accuracy: 0.8038 - val_loss: 0.5113 - val_accuracy: 0.7656\n",
            "Epoch 923/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.7986 - val_loss: 0.5109 - val_accuracy: 0.7656\n",
            "Epoch 924/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8038 - val_loss: 0.5111 - val_accuracy: 0.7656\n",
            "Epoch 925/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8038 - val_loss: 0.5114 - val_accuracy: 0.7656\n",
            "Epoch 926/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3995 - accuracy: 0.8038 - val_loss: 0.5115 - val_accuracy: 0.7656\n",
            "Epoch 927/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3994 - accuracy: 0.8003 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
            "Epoch 928/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3995 - accuracy: 0.8073 - val_loss: 0.5112 - val_accuracy: 0.7656\n",
            "Epoch 929/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3992 - accuracy: 0.8056 - val_loss: 0.5118 - val_accuracy: 0.7656\n",
            "Epoch 930/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3995 - accuracy: 0.8056 - val_loss: 0.5119 - val_accuracy: 0.7656\n",
            "Epoch 931/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3993 - accuracy: 0.8073 - val_loss: 0.5116 - val_accuracy: 0.7656\n",
            "Epoch 932/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8056 - val_loss: 0.5117 - val_accuracy: 0.7656\n",
            "Epoch 933/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8038 - val_loss: 0.5117 - val_accuracy: 0.7656\n",
            "Epoch 934/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8056 - val_loss: 0.5116 - val_accuracy: 0.7656\n",
            "Epoch 935/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8073 - val_loss: 0.5121 - val_accuracy: 0.7656\n",
            "Epoch 936/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8038 - val_loss: 0.5119 - val_accuracy: 0.7656\n",
            "Epoch 937/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8073 - val_loss: 0.5115 - val_accuracy: 0.7656\n",
            "Epoch 938/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8073 - val_loss: 0.5118 - val_accuracy: 0.7656\n",
            "Epoch 939/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8003 - val_loss: 0.5116 - val_accuracy: 0.7656\n",
            "Epoch 940/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3993 - accuracy: 0.8090 - val_loss: 0.5118 - val_accuracy: 0.7656\n",
            "Epoch 941/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3992 - accuracy: 0.8073 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
            "Epoch 942/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3992 - accuracy: 0.8038 - val_loss: 0.5116 - val_accuracy: 0.7656\n",
            "Epoch 943/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3994 - accuracy: 0.8073 - val_loss: 0.5119 - val_accuracy: 0.7656\n",
            "Epoch 944/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3992 - accuracy: 0.8021 - val_loss: 0.5116 - val_accuracy: 0.7656\n",
            "Epoch 945/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3992 - accuracy: 0.8056 - val_loss: 0.5116 - val_accuracy: 0.7656\n",
            "Epoch 946/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3993 - accuracy: 0.8038 - val_loss: 0.5115 - val_accuracy: 0.7656\n",
            "Epoch 947/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8073 - val_loss: 0.5118 - val_accuracy: 0.7656\n",
            "Epoch 948/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.8073 - val_loss: 0.5120 - val_accuracy: 0.7656\n",
            "Epoch 949/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3990 - accuracy: 0.8056 - val_loss: 0.5121 - val_accuracy: 0.7656\n",
            "Epoch 950/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3990 - accuracy: 0.8056 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
            "Epoch 951/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8038 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
            "Epoch 952/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.8003 - val_loss: 0.5119 - val_accuracy: 0.7656\n",
            "Epoch 953/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.8073 - val_loss: 0.5118 - val_accuracy: 0.7656\n",
            "Epoch 954/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3990 - accuracy: 0.8056 - val_loss: 0.5116 - val_accuracy: 0.7656\n",
            "Epoch 955/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8090 - val_loss: 0.5118 - val_accuracy: 0.7656\n",
            "Epoch 956/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3989 - accuracy: 0.8108 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
            "Epoch 957/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3991 - accuracy: 0.8073 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 958/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3989 - accuracy: 0.8108 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
            "Epoch 959/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8038 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
            "Epoch 960/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3988 - accuracy: 0.8038 - val_loss: 0.5126 - val_accuracy: 0.7604\n",
            "Epoch 961/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8056 - val_loss: 0.5126 - val_accuracy: 0.7604\n",
            "Epoch 962/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3991 - accuracy: 0.7986 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
            "Epoch 963/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8038 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
            "Epoch 964/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3990 - accuracy: 0.8073 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
            "Epoch 965/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3988 - accuracy: 0.8021 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
            "Epoch 966/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3990 - accuracy: 0.8021 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
            "Epoch 967/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3991 - accuracy: 0.8038 - val_loss: 0.5120 - val_accuracy: 0.7656\n",
            "Epoch 968/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3990 - accuracy: 0.8073 - val_loss: 0.5121 - val_accuracy: 0.7656\n",
            "Epoch 969/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8021 - val_loss: 0.5120 - val_accuracy: 0.7656\n",
            "Epoch 970/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.8073 - val_loss: 0.5118 - val_accuracy: 0.7656\n",
            "Epoch 971/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3988 - accuracy: 0.8056 - val_loss: 0.5119 - val_accuracy: 0.7656\n",
            "Epoch 972/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3988 - accuracy: 0.8056 - val_loss: 0.5120 - val_accuracy: 0.7656\n",
            "Epoch 973/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3988 - accuracy: 0.8090 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 974/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3986 - accuracy: 0.8056 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 975/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3988 - accuracy: 0.8090 - val_loss: 0.5127 - val_accuracy: 0.7604\n",
            "Epoch 976/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3988 - accuracy: 0.8056 - val_loss: 0.5128 - val_accuracy: 0.7604\n",
            "Epoch 977/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3987 - accuracy: 0.8056 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
            "Epoch 978/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8038 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
            "Epoch 979/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8056 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
            "Epoch 980/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8038 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
            "Epoch 981/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3988 - accuracy: 0.8056 - val_loss: 0.5127 - val_accuracy: 0.7604\n",
            "Epoch 982/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8056 - val_loss: 0.5127 - val_accuracy: 0.7604\n",
            "Epoch 983/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3985 - accuracy: 0.8056 - val_loss: 0.5127 - val_accuracy: 0.7604\n",
            "Epoch 984/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8038 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
            "Epoch 985/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.8038 - val_loss: 0.5123 - val_accuracy: 0.7604\n",
            "Epoch 986/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8038 - val_loss: 0.5123 - val_accuracy: 0.7604\n",
            "Epoch 987/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8090 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
            "Epoch 988/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3986 - accuracy: 0.8090 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
            "Epoch 989/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3983 - accuracy: 0.8073 - val_loss: 0.5121 - val_accuracy: 0.7604\n",
            "Epoch 990/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.8056 - val_loss: 0.5118 - val_accuracy: 0.7656\n",
            "Epoch 991/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8125 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
            "Epoch 992/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3986 - accuracy: 0.8056 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
            "Epoch 993/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8021 - val_loss: 0.5116 - val_accuracy: 0.7656\n",
            "Epoch 994/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3986 - accuracy: 0.8056 - val_loss: 0.5119 - val_accuracy: 0.7656\n",
            "Epoch 995/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8056 - val_loss: 0.5119 - val_accuracy: 0.7656\n",
            "Epoch 996/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8056 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
            "Epoch 997/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8090 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
            "Epoch 998/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3985 - accuracy: 0.8108 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
            "Epoch 999/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3985 - accuracy: 0.8038 - val_loss: 0.5123 - val_accuracy: 0.7604\n",
            "Epoch 1000/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8038 - val_loss: 0.5123 - val_accuracy: 0.7604\n",
            "Epoch 1001/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8073 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
            "Epoch 1002/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8021 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
            "Epoch 1003/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8021 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
            "Epoch 1004/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.8056 - val_loss: 0.5123 - val_accuracy: 0.7604\n",
            "Epoch 1005/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8021 - val_loss: 0.5121 - val_accuracy: 0.7604\n",
            "Epoch 1006/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8073 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
            "Epoch 1007/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8073 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
            "Epoch 1008/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8073 - val_loss: 0.5123 - val_accuracy: 0.7604\n",
            "Epoch 1009/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8021 - val_loss: 0.5123 - val_accuracy: 0.7604\n",
            "Epoch 1010/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3983 - accuracy: 0.8073 - val_loss: 0.5121 - val_accuracy: 0.7604\n",
            "Epoch 1011/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8021 - val_loss: 0.5123 - val_accuracy: 0.7604\n",
            "Epoch 1012/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3982 - accuracy: 0.8056 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
            "Epoch 1013/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8056 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
            "Epoch 1014/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8073 - val_loss: 0.5128 - val_accuracy: 0.7604\n",
            "Epoch 1015/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8038 - val_loss: 0.5123 - val_accuracy: 0.7604\n",
            "Epoch 1016/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8038 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
            "Epoch 1017/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8003 - val_loss: 0.5121 - val_accuracy: 0.7604\n",
            "Epoch 1018/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8038 - val_loss: 0.5121 - val_accuracy: 0.7604\n",
            "Epoch 1019/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8073 - val_loss: 0.5121 - val_accuracy: 0.7604\n",
            "Epoch 1020/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8073 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
            "Epoch 1021/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8021 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
            "Epoch 1022/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8056 - val_loss: 0.5117 - val_accuracy: 0.7604\n",
            "Epoch 1023/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3981 - accuracy: 0.8038 - val_loss: 0.5121 - val_accuracy: 0.7604\n",
            "Epoch 1024/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8038 - val_loss: 0.5121 - val_accuracy: 0.7604\n",
            "Epoch 1025/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3980 - accuracy: 0.8073 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
            "Epoch 1026/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8108 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
            "Epoch 1027/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8038 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
            "Epoch 1028/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8038 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
            "Epoch 1029/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8073 - val_loss: 0.5127 - val_accuracy: 0.7604\n",
            "Epoch 1030/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8073 - val_loss: 0.5127 - val_accuracy: 0.7604\n",
            "Epoch 1031/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8038 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
            "Epoch 1032/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8038 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 1033/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8038 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
            "Epoch 1034/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8056 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
            "Epoch 1035/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3979 - accuracy: 0.8056 - val_loss: 0.5127 - val_accuracy: 0.7604\n",
            "Epoch 1036/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3980 - accuracy: 0.8038 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
            "Epoch 1037/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8073 - val_loss: 0.5121 - val_accuracy: 0.7604\n",
            "Epoch 1038/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8056 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
            "Epoch 1039/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8056 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
            "Epoch 1040/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8038 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
            "Epoch 1041/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3979 - accuracy: 0.8073 - val_loss: 0.5126 - val_accuracy: 0.7604\n",
            "Epoch 1042/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8073 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
            "Epoch 1043/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3978 - accuracy: 0.8056 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
            "Epoch 1044/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3978 - accuracy: 0.8056 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
            "Epoch 1045/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8056 - val_loss: 0.5123 - val_accuracy: 0.7604\n",
            "Epoch 1046/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3976 - accuracy: 0.8056 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
            "Epoch 1047/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8056 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
            "Epoch 1048/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8038 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
            "Epoch 1049/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8073 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
            "Epoch 1050/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3975 - accuracy: 0.8056 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
            "Epoch 1051/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
            "Epoch 1052/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8073 - val_loss: 0.5126 - val_accuracy: 0.7604\n",
            "Epoch 1053/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8021 - val_loss: 0.5121 - val_accuracy: 0.7656\n",
            "Epoch 1054/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8056 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
            "Epoch 1055/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8021 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
            "Epoch 1056/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8038 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
            "Epoch 1057/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8090 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
            "Epoch 1058/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8056 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
            "Epoch 1059/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3977 - accuracy: 0.8073 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
            "Epoch 1060/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8090 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
            "Epoch 1061/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8056 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
            "Epoch 1062/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8073 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
            "Epoch 1063/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8056 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
            "Epoch 1064/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8056 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
            "Epoch 1065/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8073 - val_loss: 0.5126 - val_accuracy: 0.7604\n",
            "Epoch 1066/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8056 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
            "Epoch 1067/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8056 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
            "Epoch 1068/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3975 - accuracy: 0.8021 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
            "Epoch 1069/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8056 - val_loss: 0.5127 - val_accuracy: 0.7708\n",
            "Epoch 1070/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3975 - accuracy: 0.8056 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
            "Epoch 1071/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8090 - val_loss: 0.5130 - val_accuracy: 0.7708\n",
            "Epoch 1072/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8056 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
            "Epoch 1073/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8056 - val_loss: 0.5124 - val_accuracy: 0.7708\n",
            "Epoch 1074/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8056 - val_loss: 0.5124 - val_accuracy: 0.7708\n",
            "Epoch 1075/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8038 - val_loss: 0.5122 - val_accuracy: 0.7708\n",
            "Epoch 1076/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3974 - accuracy: 0.8073 - val_loss: 0.5122 - val_accuracy: 0.7708\n",
            "Epoch 1077/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8056 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 1078/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8056 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 1079/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3972 - accuracy: 0.8056 - val_loss: 0.5126 - val_accuracy: 0.7708\n",
            "Epoch 1080/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8056 - val_loss: 0.5130 - val_accuracy: 0.7708\n",
            "Epoch 1081/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3973 - accuracy: 0.8056 - val_loss: 0.5131 - val_accuracy: 0.7708\n",
            "Epoch 1082/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3972 - accuracy: 0.8073 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
            "Epoch 1083/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3972 - accuracy: 0.8056 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
            "Epoch 1084/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3971 - accuracy: 0.8056 - val_loss: 0.5127 - val_accuracy: 0.7708\n",
            "Epoch 1085/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3973 - accuracy: 0.8038 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 1086/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3973 - accuracy: 0.8056 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
            "Epoch 1087/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3971 - accuracy: 0.8056 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
            "Epoch 1088/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3970 - accuracy: 0.8056 - val_loss: 0.5130 - val_accuracy: 0.7708\n",
            "Epoch 1089/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3974 - accuracy: 0.8038 - val_loss: 0.5131 - val_accuracy: 0.7708\n",
            "Epoch 1090/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3973 - accuracy: 0.8038 - val_loss: 0.5131 - val_accuracy: 0.7708\n",
            "Epoch 1091/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8056 - val_loss: 0.5131 - val_accuracy: 0.7708\n",
            "Epoch 1092/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3972 - accuracy: 0.8056 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
            "Epoch 1093/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8056 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
            "Epoch 1094/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3970 - accuracy: 0.8090 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
            "Epoch 1095/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3970 - accuracy: 0.8056 - val_loss: 0.5127 - val_accuracy: 0.7708\n",
            "Epoch 1096/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3968 - accuracy: 0.8073 - val_loss: 0.5131 - val_accuracy: 0.7708\n",
            "Epoch 1097/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3972 - accuracy: 0.8090 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
            "Epoch 1098/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3971 - accuracy: 0.8090 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
            "Epoch 1099/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3969 - accuracy: 0.8056 - val_loss: 0.5126 - val_accuracy: 0.7708\n",
            "Epoch 1100/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3970 - accuracy: 0.8073 - val_loss: 0.5127 - val_accuracy: 0.7708\n",
            "Epoch 1101/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3968 - accuracy: 0.8056 - val_loss: 0.5127 - val_accuracy: 0.7708\n",
            "Epoch 1102/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3968 - accuracy: 0.8056 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
            "Epoch 1103/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8038 - val_loss: 0.5126 - val_accuracy: 0.7708\n",
            "Epoch 1104/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3972 - accuracy: 0.8056 - val_loss: 0.5127 - val_accuracy: 0.7708\n",
            "Epoch 1105/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3968 - accuracy: 0.8038 - val_loss: 0.5127 - val_accuracy: 0.7708\n",
            "Epoch 1106/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3970 - accuracy: 0.8056 - val_loss: 0.5126 - val_accuracy: 0.7708\n",
            "Epoch 1107/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3968 - accuracy: 0.8056 - val_loss: 0.5127 - val_accuracy: 0.7708\n",
            "Epoch 1108/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3968 - accuracy: 0.8038 - val_loss: 0.5131 - val_accuracy: 0.7708\n",
            "Epoch 1109/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8038 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
            "Epoch 1110/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8021 - val_loss: 0.5131 - val_accuracy: 0.7708\n",
            "Epoch 1111/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3967 - accuracy: 0.8038 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
            "Epoch 1112/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8056 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
            "Epoch 1113/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8073 - val_loss: 0.5127 - val_accuracy: 0.7708\n",
            "Epoch 1114/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8038 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
            "Epoch 1115/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7708\n",
            "Epoch 1116/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8021 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
            "Epoch 1117/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8073 - val_loss: 0.5127 - val_accuracy: 0.7708\n",
            "Epoch 1118/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8038 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
            "Epoch 1119/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8038 - val_loss: 0.5126 - val_accuracy: 0.7708\n",
            "Epoch 1120/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3964 - accuracy: 0.8038 - val_loss: 0.5121 - val_accuracy: 0.7708\n",
            "Epoch 1121/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8038 - val_loss: 0.5120 - val_accuracy: 0.7708\n",
            "Epoch 1122/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8056 - val_loss: 0.5126 - val_accuracy: 0.7708\n",
            "Epoch 1123/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8038 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
            "Epoch 1124/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8056 - val_loss: 0.5126 - val_accuracy: 0.7708\n",
            "Epoch 1125/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8021 - val_loss: 0.5124 - val_accuracy: 0.7708\n",
            "Epoch 1126/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8038 - val_loss: 0.5123 - val_accuracy: 0.7708\n",
            "Epoch 1127/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3963 - accuracy: 0.8038 - val_loss: 0.5127 - val_accuracy: 0.7708\n",
            "Epoch 1128/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8056 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
            "Epoch 1129/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7708\n",
            "Epoch 1130/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8056 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
            "Epoch 1131/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8073 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
            "Epoch 1132/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8038 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
            "Epoch 1133/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8056 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
            "Epoch 1134/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8056 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
            "Epoch 1135/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8090 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
            "Epoch 1136/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3959 - accuracy: 0.8038 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
            "Epoch 1137/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8056 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 1138/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8038 - val_loss: 0.5121 - val_accuracy: 0.7656\n",
            "Epoch 1139/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8056 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
            "Epoch 1140/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8003 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 1141/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.8003 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 1142/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3957 - accuracy: 0.8056 - val_loss: 0.5121 - val_accuracy: 0.7656\n",
            "Epoch 1143/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3957 - accuracy: 0.8021 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
            "Epoch 1144/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8038 - val_loss: 0.5121 - val_accuracy: 0.7656\n",
            "Epoch 1145/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8038 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
            "Epoch 1146/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8038 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 1147/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8003 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
            "Epoch 1148/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.7986 - val_loss: 0.5121 - val_accuracy: 0.7656\n",
            "Epoch 1149/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3954 - accuracy: 0.8038 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
            "Epoch 1150/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8038 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
            "Epoch 1151/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3954 - accuracy: 0.8038 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 1152/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8003 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
            "Epoch 1153/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8056 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
            "Epoch 1154/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8056 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
            "Epoch 1155/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8003 - val_loss: 0.5117 - val_accuracy: 0.7656\n",
            "Epoch 1156/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8038 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
            "Epoch 1157/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8003 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
            "Epoch 1158/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8021 - val_loss: 0.5118 - val_accuracy: 0.7656\n",
            "Epoch 1159/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8021 - val_loss: 0.5118 - val_accuracy: 0.7656\n",
            "Epoch 1160/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.7986 - val_loss: 0.5115 - val_accuracy: 0.7656\n",
            "Epoch 1161/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3950 - accuracy: 0.8003 - val_loss: 0.5119 - val_accuracy: 0.7656\n",
            "Epoch 1162/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8003 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 1163/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8003 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 1164/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8021 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 1165/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3948 - accuracy: 0.8021 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 1166/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8038 - val_loss: 0.5121 - val_accuracy: 0.7656\n",
            "Epoch 1167/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3948 - accuracy: 0.8038 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 1168/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8056 - val_loss: 0.5118 - val_accuracy: 0.7656\n",
            "Epoch 1169/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3948 - accuracy: 0.8021 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 1170/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8003 - val_loss: 0.5117 - val_accuracy: 0.7656\n",
            "Epoch 1171/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3948 - accuracy: 0.8021 - val_loss: 0.5119 - val_accuracy: 0.7656\n",
            "Epoch 1172/1500\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.3947 - accuracy: 0.8003 - val_loss: 0.5120 - val_accuracy: 0.7656\n",
            "Epoch 1173/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3948 - accuracy: 0.8021 - val_loss: 0.5121 - val_accuracy: 0.7656\n",
            "Epoch 1174/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3946 - accuracy: 0.8038 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 1175/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8038 - val_loss: 0.5117 - val_accuracy: 0.7656\n",
            "Epoch 1176/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3948 - accuracy: 0.8038 - val_loss: 0.5121 - val_accuracy: 0.7656\n",
            "Epoch 1177/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3948 - accuracy: 0.8021 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
            "Epoch 1178/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8003 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 1179/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3948 - accuracy: 0.8021 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
            "Epoch 1180/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8003 - val_loss: 0.5119 - val_accuracy: 0.7656\n",
            "Epoch 1181/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8038 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
            "Epoch 1182/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8021 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
            "Epoch 1183/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8090 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 1184/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8021 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
            "Epoch 1185/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3944 - accuracy: 0.8021 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 1186/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3943 - accuracy: 0.8021 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
            "Epoch 1187/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8021 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 1188/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8038 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 1189/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8021 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 1190/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3943 - accuracy: 0.8038 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
            "Epoch 1191/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8021 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
            "Epoch 1192/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8021 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
            "Epoch 1193/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3943 - accuracy: 0.8003 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
            "Epoch 1194/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
            "Epoch 1195/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3940 - accuracy: 0.8021 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
            "Epoch 1196/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8003 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
            "Epoch 1197/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3939 - accuracy: 0.8021 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
            "Epoch 1198/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
            "Epoch 1199/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3939 - accuracy: 0.8003 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
            "Epoch 1200/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3939 - accuracy: 0.8021 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
            "Epoch 1201/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3939 - accuracy: 0.8021 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
            "Epoch 1202/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.7986 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
            "Epoch 1203/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3939 - accuracy: 0.8021 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 1204/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3937 - accuracy: 0.8021 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
            "Epoch 1205/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3939 - accuracy: 0.8021 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
            "Epoch 1206/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3941 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
            "Epoch 1207/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
            "Epoch 1208/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3935 - accuracy: 0.8038 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
            "Epoch 1209/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.8021 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
            "Epoch 1210/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3935 - accuracy: 0.8021 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
            "Epoch 1211/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3935 - accuracy: 0.7986 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
            "Epoch 1212/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
            "Epoch 1213/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3938 - accuracy: 0.8038 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
            "Epoch 1214/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3936 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
            "Epoch 1215/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3935 - accuracy: 0.8038 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
            "Epoch 1216/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3936 - accuracy: 0.8021 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 1217/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3934 - accuracy: 0.7986 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
            "Epoch 1218/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3936 - accuracy: 0.8021 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
            "Epoch 1219/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3934 - accuracy: 0.8021 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
            "Epoch 1220/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3934 - accuracy: 0.8003 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
            "Epoch 1221/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.8038 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
            "Epoch 1222/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3934 - accuracy: 0.8003 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
            "Epoch 1223/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3932 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
            "Epoch 1224/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3934 - accuracy: 0.8021 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
            "Epoch 1225/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3933 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
            "Epoch 1226/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3931 - accuracy: 0.8038 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
            "Epoch 1227/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3933 - accuracy: 0.8038 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
            "Epoch 1228/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3931 - accuracy: 0.8003 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
            "Epoch 1229/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3934 - accuracy: 0.8021 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
            "Epoch 1230/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3932 - accuracy: 0.8090 - val_loss: 0.5137 - val_accuracy: 0.7656\n",
            "Epoch 1231/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3933 - accuracy: 0.8003 - val_loss: 0.5137 - val_accuracy: 0.7656\n",
            "Epoch 1232/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3932 - accuracy: 0.8021 - val_loss: 0.5137 - val_accuracy: 0.7656\n",
            "Epoch 1233/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3931 - accuracy: 0.8003 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
            "Epoch 1234/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3929 - accuracy: 0.8003 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
            "Epoch 1235/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3931 - accuracy: 0.8038 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
            "Epoch 1236/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.8003 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
            "Epoch 1237/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3930 - accuracy: 0.8003 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
            "Epoch 1238/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3929 - accuracy: 0.8003 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
            "Epoch 1239/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3930 - accuracy: 0.8003 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
            "Epoch 1240/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3929 - accuracy: 0.8003 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
            "Epoch 1241/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3929 - accuracy: 0.8003 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
            "Epoch 1242/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3931 - accuracy: 0.8021 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
            "Epoch 1243/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3930 - accuracy: 0.8021 - val_loss: 0.5137 - val_accuracy: 0.7656\n",
            "Epoch 1244/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3928 - accuracy: 0.8003 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
            "Epoch 1245/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3929 - accuracy: 0.8038 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
            "Epoch 1246/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3929 - accuracy: 0.8056 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
            "Epoch 1247/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3928 - accuracy: 0.8021 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
            "Epoch 1248/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3927 - accuracy: 0.8021 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
            "Epoch 1249/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3931 - accuracy: 0.8038 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
            "Epoch 1250/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3927 - accuracy: 0.8038 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
            "Epoch 1251/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3925 - accuracy: 0.8056 - val_loss: 0.5127 - val_accuracy: 0.7604\n",
            "Epoch 1252/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3928 - accuracy: 0.8021 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
            "Epoch 1253/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3926 - accuracy: 0.8038 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
            "Epoch 1254/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3925 - accuracy: 0.8021 - val_loss: 0.5142 - val_accuracy: 0.7656\n",
            "Epoch 1255/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3927 - accuracy: 0.8003 - val_loss: 0.5145 - val_accuracy: 0.7656\n",
            "Epoch 1256/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3926 - accuracy: 0.8038 - val_loss: 0.5141 - val_accuracy: 0.7656\n",
            "Epoch 1257/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3926 - accuracy: 0.8021 - val_loss: 0.5144 - val_accuracy: 0.7656\n",
            "Epoch 1258/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3923 - accuracy: 0.8038 - val_loss: 0.5142 - val_accuracy: 0.7656\n",
            "Epoch 1259/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3923 - accuracy: 0.8003 - val_loss: 0.5140 - val_accuracy: 0.7656\n",
            "Epoch 1260/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3925 - accuracy: 0.8021 - val_loss: 0.5141 - val_accuracy: 0.7656\n",
            "Epoch 1261/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3924 - accuracy: 0.8021 - val_loss: 0.5145 - val_accuracy: 0.7656\n",
            "Epoch 1262/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3924 - accuracy: 0.8021 - val_loss: 0.5142 - val_accuracy: 0.7656\n",
            "Epoch 1263/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3921 - accuracy: 0.8038 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
            "Epoch 1264/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3922 - accuracy: 0.8073 - val_loss: 0.5140 - val_accuracy: 0.7656\n",
            "Epoch 1265/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3923 - accuracy: 0.8003 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
            "Epoch 1266/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3920 - accuracy: 0.8003 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
            "Epoch 1267/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3923 - accuracy: 0.8038 - val_loss: 0.5141 - val_accuracy: 0.7656\n",
            "Epoch 1268/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3922 - accuracy: 0.8003 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
            "Epoch 1269/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3920 - accuracy: 0.8021 - val_loss: 0.5143 - val_accuracy: 0.7656\n",
            "Epoch 1270/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3919 - accuracy: 0.8021 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
            "Epoch 1271/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3917 - accuracy: 0.8056 - val_loss: 0.5144 - val_accuracy: 0.7656\n",
            "Epoch 1272/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3920 - accuracy: 0.8021 - val_loss: 0.5147 - val_accuracy: 0.7656\n",
            "Epoch 1273/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3925 - accuracy: 0.8003 - val_loss: 0.5140 - val_accuracy: 0.7656\n",
            "Epoch 1274/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3921 - accuracy: 0.8021 - val_loss: 0.5140 - val_accuracy: 0.7656\n",
            "Epoch 1275/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3921 - accuracy: 0.8038 - val_loss: 0.5142 - val_accuracy: 0.7656\n",
            "Epoch 1276/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3919 - accuracy: 0.8021 - val_loss: 0.5141 - val_accuracy: 0.7656\n",
            "Epoch 1277/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3919 - accuracy: 0.8038 - val_loss: 0.5141 - val_accuracy: 0.7656\n",
            "Epoch 1278/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3918 - accuracy: 0.8021 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
            "Epoch 1279/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3918 - accuracy: 0.8021 - val_loss: 0.5142 - val_accuracy: 0.7656\n",
            "Epoch 1280/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3918 - accuracy: 0.8021 - val_loss: 0.5148 - val_accuracy: 0.7656\n",
            "Epoch 1281/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3916 - accuracy: 0.8038 - val_loss: 0.5147 - val_accuracy: 0.7656\n",
            "Epoch 1282/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3917 - accuracy: 0.8021 - val_loss: 0.5149 - val_accuracy: 0.7656\n",
            "Epoch 1283/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3921 - accuracy: 0.8021 - val_loss: 0.5145 - val_accuracy: 0.7656\n",
            "Epoch 1284/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3916 - accuracy: 0.8003 - val_loss: 0.5142 - val_accuracy: 0.7656\n",
            "Epoch 1285/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3915 - accuracy: 0.8021 - val_loss: 0.5143 - val_accuracy: 0.7656\n",
            "Epoch 1286/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3916 - accuracy: 0.8038 - val_loss: 0.5149 - val_accuracy: 0.7656\n",
            "Epoch 1287/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3913 - accuracy: 0.8021 - val_loss: 0.5152 - val_accuracy: 0.7656\n",
            "Epoch 1288/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3917 - accuracy: 0.8038 - val_loss: 0.5151 - val_accuracy: 0.7656\n",
            "Epoch 1289/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3915 - accuracy: 0.8003 - val_loss: 0.5147 - val_accuracy: 0.7656\n",
            "Epoch 1290/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3916 - accuracy: 0.8038 - val_loss: 0.5157 - val_accuracy: 0.7656\n",
            "Epoch 1291/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3912 - accuracy: 0.8056 - val_loss: 0.5157 - val_accuracy: 0.7656\n",
            "Epoch 1292/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3915 - accuracy: 0.8021 - val_loss: 0.5149 - val_accuracy: 0.7656\n",
            "Epoch 1293/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3912 - accuracy: 0.8021 - val_loss: 0.5145 - val_accuracy: 0.7604\n",
            "Epoch 1294/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3913 - accuracy: 0.8073 - val_loss: 0.5146 - val_accuracy: 0.7604\n",
            "Epoch 1295/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3914 - accuracy: 0.8021 - val_loss: 0.5153 - val_accuracy: 0.7656\n",
            "Epoch 1296/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3913 - accuracy: 0.8038 - val_loss: 0.5149 - val_accuracy: 0.7656\n",
            "Epoch 1297/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3915 - accuracy: 0.8038 - val_loss: 0.5152 - val_accuracy: 0.7656\n",
            "Epoch 1298/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3911 - accuracy: 0.8073 - val_loss: 0.5159 - val_accuracy: 0.7656\n",
            "Epoch 1299/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3914 - accuracy: 0.8038 - val_loss: 0.5155 - val_accuracy: 0.7656\n",
            "Epoch 1300/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3911 - accuracy: 0.8038 - val_loss: 0.5156 - val_accuracy: 0.7656\n",
            "Epoch 1301/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3913 - accuracy: 0.8038 - val_loss: 0.5159 - val_accuracy: 0.7656\n",
            "Epoch 1302/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3913 - accuracy: 0.8021 - val_loss: 0.5154 - val_accuracy: 0.7656\n",
            "Epoch 1303/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3913 - accuracy: 0.8056 - val_loss: 0.5155 - val_accuracy: 0.7656\n",
            "Epoch 1304/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3910 - accuracy: 0.8021 - val_loss: 0.5154 - val_accuracy: 0.7656\n",
            "Epoch 1305/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3910 - accuracy: 0.8038 - val_loss: 0.5152 - val_accuracy: 0.7604\n",
            "Epoch 1306/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3912 - accuracy: 0.8038 - val_loss: 0.5157 - val_accuracy: 0.7656\n",
            "Epoch 1307/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3909 - accuracy: 0.8090 - val_loss: 0.5158 - val_accuracy: 0.7604\n",
            "Epoch 1308/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3912 - accuracy: 0.8021 - val_loss: 0.5158 - val_accuracy: 0.7656\n",
            "Epoch 1309/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3909 - accuracy: 0.8003 - val_loss: 0.5154 - val_accuracy: 0.7604\n",
            "Epoch 1310/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3908 - accuracy: 0.8056 - val_loss: 0.5155 - val_accuracy: 0.7604\n",
            "Epoch 1311/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3908 - accuracy: 0.8056 - val_loss: 0.5159 - val_accuracy: 0.7656\n",
            "Epoch 1312/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3911 - accuracy: 0.8021 - val_loss: 0.5154 - val_accuracy: 0.7604\n",
            "Epoch 1313/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3910 - accuracy: 0.8021 - val_loss: 0.5152 - val_accuracy: 0.7604\n",
            "Epoch 1314/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3909 - accuracy: 0.8073 - val_loss: 0.5158 - val_accuracy: 0.7604\n",
            "Epoch 1315/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3909 - accuracy: 0.8038 - val_loss: 0.5157 - val_accuracy: 0.7604\n",
            "Epoch 1316/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3908 - accuracy: 0.8073 - val_loss: 0.5165 - val_accuracy: 0.7656\n",
            "Epoch 1317/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3911 - accuracy: 0.8038 - val_loss: 0.5171 - val_accuracy: 0.7604\n",
            "Epoch 1318/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3908 - accuracy: 0.8021 - val_loss: 0.5166 - val_accuracy: 0.7656\n",
            "Epoch 1319/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3909 - accuracy: 0.8021 - val_loss: 0.5168 - val_accuracy: 0.7656\n",
            "Epoch 1320/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3907 - accuracy: 0.8038 - val_loss: 0.5167 - val_accuracy: 0.7656\n",
            "Epoch 1321/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3907 - accuracy: 0.8056 - val_loss: 0.5166 - val_accuracy: 0.7656\n",
            "Epoch 1322/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3906 - accuracy: 0.8038 - val_loss: 0.5171 - val_accuracy: 0.7656\n",
            "Epoch 1323/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3908 - accuracy: 0.8073 - val_loss: 0.5174 - val_accuracy: 0.7656\n",
            "Epoch 1324/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3905 - accuracy: 0.8056 - val_loss: 0.5169 - val_accuracy: 0.7656\n",
            "Epoch 1325/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3907 - accuracy: 0.8021 - val_loss: 0.5164 - val_accuracy: 0.7604\n",
            "Epoch 1326/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3905 - accuracy: 0.8038 - val_loss: 0.5164 - val_accuracy: 0.7604\n",
            "Epoch 1327/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3904 - accuracy: 0.8056 - val_loss: 0.5165 - val_accuracy: 0.7604\n",
            "Epoch 1328/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3904 - accuracy: 0.8056 - val_loss: 0.5172 - val_accuracy: 0.7656\n",
            "Epoch 1329/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3904 - accuracy: 0.8056 - val_loss: 0.5174 - val_accuracy: 0.7656\n",
            "Epoch 1330/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3907 - accuracy: 0.8003 - val_loss: 0.5168 - val_accuracy: 0.7656\n",
            "Epoch 1331/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3908 - accuracy: 0.8056 - val_loss: 0.5166 - val_accuracy: 0.7604\n",
            "Epoch 1332/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3905 - accuracy: 0.8056 - val_loss: 0.5171 - val_accuracy: 0.7656\n",
            "Epoch 1333/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3904 - accuracy: 0.8073 - val_loss: 0.5167 - val_accuracy: 0.7656\n",
            "Epoch 1334/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3906 - accuracy: 0.8056 - val_loss: 0.5169 - val_accuracy: 0.7656\n",
            "Epoch 1335/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3905 - accuracy: 0.8003 - val_loss: 0.5164 - val_accuracy: 0.7604\n",
            "Epoch 1336/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3903 - accuracy: 0.8073 - val_loss: 0.5167 - val_accuracy: 0.7656\n",
            "Epoch 1337/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3903 - accuracy: 0.8038 - val_loss: 0.5169 - val_accuracy: 0.7656\n",
            "Epoch 1338/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3903 - accuracy: 0.8090 - val_loss: 0.5164 - val_accuracy: 0.7656\n",
            "Epoch 1339/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3903 - accuracy: 0.8003 - val_loss: 0.5160 - val_accuracy: 0.7656\n",
            "Epoch 1340/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3904 - accuracy: 0.8073 - val_loss: 0.5162 - val_accuracy: 0.7604\n",
            "Epoch 1341/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3904 - accuracy: 0.8073 - val_loss: 0.5165 - val_accuracy: 0.7604\n",
            "Epoch 1342/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3903 - accuracy: 0.8056 - val_loss: 0.5167 - val_accuracy: 0.7604\n",
            "Epoch 1343/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3902 - accuracy: 0.8073 - val_loss: 0.5177 - val_accuracy: 0.7604\n",
            "Epoch 1344/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3903 - accuracy: 0.8003 - val_loss: 0.5173 - val_accuracy: 0.7604\n",
            "Epoch 1345/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3902 - accuracy: 0.8038 - val_loss: 0.5167 - val_accuracy: 0.7604\n",
            "Epoch 1346/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3903 - accuracy: 0.8073 - val_loss: 0.5171 - val_accuracy: 0.7656\n",
            "Epoch 1347/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3904 - accuracy: 0.8038 - val_loss: 0.5171 - val_accuracy: 0.7656\n",
            "Epoch 1348/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3903 - accuracy: 0.8056 - val_loss: 0.5175 - val_accuracy: 0.7604\n",
            "Epoch 1349/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3904 - accuracy: 0.8056 - val_loss: 0.5177 - val_accuracy: 0.7604\n",
            "Epoch 1350/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3899 - accuracy: 0.8038 - val_loss: 0.5172 - val_accuracy: 0.7656\n",
            "Epoch 1351/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3902 - accuracy: 0.8056 - val_loss: 0.5172 - val_accuracy: 0.7656\n",
            "Epoch 1352/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3901 - accuracy: 0.8056 - val_loss: 0.5174 - val_accuracy: 0.7656\n",
            "Epoch 1353/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3903 - accuracy: 0.8056 - val_loss: 0.5176 - val_accuracy: 0.7656\n",
            "Epoch 1354/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3900 - accuracy: 0.8038 - val_loss: 0.5175 - val_accuracy: 0.7656\n",
            "Epoch 1355/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3904 - accuracy: 0.8038 - val_loss: 0.5173 - val_accuracy: 0.7656\n",
            "Epoch 1356/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3901 - accuracy: 0.8038 - val_loss: 0.5178 - val_accuracy: 0.7656\n",
            "Epoch 1357/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3904 - accuracy: 0.8108 - val_loss: 0.5180 - val_accuracy: 0.7656\n",
            "Epoch 1358/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3901 - accuracy: 0.8021 - val_loss: 0.5179 - val_accuracy: 0.7656\n",
            "Epoch 1359/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3901 - accuracy: 0.8056 - val_loss: 0.5180 - val_accuracy: 0.7656\n",
            "Epoch 1360/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3899 - accuracy: 0.8056 - val_loss: 0.5176 - val_accuracy: 0.7656\n",
            "Epoch 1361/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3900 - accuracy: 0.8056 - val_loss: 0.5177 - val_accuracy: 0.7656\n",
            "Epoch 1362/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3901 - accuracy: 0.8056 - val_loss: 0.5176 - val_accuracy: 0.7656\n",
            "Epoch 1363/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3900 - accuracy: 0.8056 - val_loss: 0.5176 - val_accuracy: 0.7656\n",
            "Epoch 1364/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3899 - accuracy: 0.8056 - val_loss: 0.5177 - val_accuracy: 0.7656\n",
            "Epoch 1365/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3899 - accuracy: 0.8073 - val_loss: 0.5175 - val_accuracy: 0.7656\n",
            "Epoch 1366/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3899 - accuracy: 0.8021 - val_loss: 0.5170 - val_accuracy: 0.7604\n",
            "Epoch 1367/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3902 - accuracy: 0.8056 - val_loss: 0.5170 - val_accuracy: 0.7604\n",
            "Epoch 1368/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3899 - accuracy: 0.8073 - val_loss: 0.5175 - val_accuracy: 0.7656\n",
            "Epoch 1369/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3899 - accuracy: 0.8073 - val_loss: 0.5175 - val_accuracy: 0.7656\n",
            "Epoch 1370/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3898 - accuracy: 0.8073 - val_loss: 0.5179 - val_accuracy: 0.7656\n",
            "Epoch 1371/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3897 - accuracy: 0.8038 - val_loss: 0.5174 - val_accuracy: 0.7604\n",
            "Epoch 1372/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3899 - accuracy: 0.8056 - val_loss: 0.5175 - val_accuracy: 0.7656\n",
            "Epoch 1373/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3900 - accuracy: 0.8038 - val_loss: 0.5174 - val_accuracy: 0.7656\n",
            "Epoch 1374/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3900 - accuracy: 0.8038 - val_loss: 0.5177 - val_accuracy: 0.7604\n",
            "Epoch 1375/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3899 - accuracy: 0.8056 - val_loss: 0.5177 - val_accuracy: 0.7604\n",
            "Epoch 1376/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3899 - accuracy: 0.8056 - val_loss: 0.5180 - val_accuracy: 0.7604\n",
            "Epoch 1377/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3898 - accuracy: 0.8056 - val_loss: 0.5179 - val_accuracy: 0.7604\n",
            "Epoch 1378/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3897 - accuracy: 0.8038 - val_loss: 0.5177 - val_accuracy: 0.7604\n",
            "Epoch 1379/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3897 - accuracy: 0.8090 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
            "Epoch 1380/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3898 - accuracy: 0.8108 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
            "Epoch 1381/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3894 - accuracy: 0.8038 - val_loss: 0.5175 - val_accuracy: 0.7604\n",
            "Epoch 1382/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3897 - accuracy: 0.8090 - val_loss: 0.5172 - val_accuracy: 0.7656\n",
            "Epoch 1383/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3895 - accuracy: 0.8056 - val_loss: 0.5178 - val_accuracy: 0.7604\n",
            "Epoch 1384/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3894 - accuracy: 0.8038 - val_loss: 0.5182 - val_accuracy: 0.7552\n",
            "Epoch 1385/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3898 - accuracy: 0.8038 - val_loss: 0.5179 - val_accuracy: 0.7552\n",
            "Epoch 1386/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3897 - accuracy: 0.8090 - val_loss: 0.5182 - val_accuracy: 0.7552\n",
            "Epoch 1387/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3895 - accuracy: 0.8038 - val_loss: 0.5180 - val_accuracy: 0.7552\n",
            "Epoch 1388/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3896 - accuracy: 0.8038 - val_loss: 0.5178 - val_accuracy: 0.7552\n",
            "Epoch 1389/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3896 - accuracy: 0.8021 - val_loss: 0.5175 - val_accuracy: 0.7656\n",
            "Epoch 1390/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3896 - accuracy: 0.8021 - val_loss: 0.5171 - val_accuracy: 0.7656\n",
            "Epoch 1391/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3894 - accuracy: 0.8021 - val_loss: 0.5176 - val_accuracy: 0.7604\n",
            "Epoch 1392/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3896 - accuracy: 0.8073 - val_loss: 0.5170 - val_accuracy: 0.7656\n",
            "Epoch 1393/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3896 - accuracy: 0.8021 - val_loss: 0.5171 - val_accuracy: 0.7656\n",
            "Epoch 1394/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3897 - accuracy: 0.8056 - val_loss: 0.5177 - val_accuracy: 0.7656\n",
            "Epoch 1395/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3893 - accuracy: 0.8056 - val_loss: 0.5185 - val_accuracy: 0.7552\n",
            "Epoch 1396/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3893 - accuracy: 0.8021 - val_loss: 0.5186 - val_accuracy: 0.7552\n",
            "Epoch 1397/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3895 - accuracy: 0.8038 - val_loss: 0.5181 - val_accuracy: 0.7552\n",
            "Epoch 1398/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3895 - accuracy: 0.8056 - val_loss: 0.5181 - val_accuracy: 0.7552\n",
            "Epoch 1399/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3895 - accuracy: 0.8056 - val_loss: 0.5172 - val_accuracy: 0.7656\n",
            "Epoch 1400/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3898 - accuracy: 0.8090 - val_loss: 0.5178 - val_accuracy: 0.7552\n",
            "Epoch 1401/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3894 - accuracy: 0.8073 - val_loss: 0.5178 - val_accuracy: 0.7552\n",
            "Epoch 1402/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3896 - accuracy: 0.8038 - val_loss: 0.5179 - val_accuracy: 0.7552\n",
            "Epoch 1403/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3895 - accuracy: 0.8038 - val_loss: 0.5180 - val_accuracy: 0.7552\n",
            "Epoch 1404/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3892 - accuracy: 0.8038 - val_loss: 0.5185 - val_accuracy: 0.7552\n",
            "Epoch 1405/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3896 - accuracy: 0.8038 - val_loss: 0.5177 - val_accuracy: 0.7604\n",
            "Epoch 1406/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.8073 - val_loss: 0.5180 - val_accuracy: 0.7604\n",
            "Epoch 1407/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.7986 - val_loss: 0.5181 - val_accuracy: 0.7604\n",
            "Epoch 1408/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3892 - accuracy: 0.8056 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
            "Epoch 1409/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3896 - accuracy: 0.8038 - val_loss: 0.5183 - val_accuracy: 0.7552\n",
            "Epoch 1410/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3892 - accuracy: 0.8038 - val_loss: 0.5183 - val_accuracy: 0.7552\n",
            "Epoch 1411/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3894 - accuracy: 0.8073 - val_loss: 0.5187 - val_accuracy: 0.7552\n",
            "Epoch 1412/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3893 - accuracy: 0.8056 - val_loss: 0.5180 - val_accuracy: 0.7604\n",
            "Epoch 1413/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3892 - accuracy: 0.8073 - val_loss: 0.5183 - val_accuracy: 0.7604\n",
            "Epoch 1414/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.8073 - val_loss: 0.5178 - val_accuracy: 0.7656\n",
            "Epoch 1415/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3891 - accuracy: 0.8090 - val_loss: 0.5181 - val_accuracy: 0.7656\n",
            "Epoch 1416/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3892 - accuracy: 0.8073 - val_loss: 0.5173 - val_accuracy: 0.7656\n",
            "Epoch 1417/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3893 - accuracy: 0.8073 - val_loss: 0.5172 - val_accuracy: 0.7656\n",
            "Epoch 1418/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3894 - accuracy: 0.8090 - val_loss: 0.5179 - val_accuracy: 0.7604\n",
            "Epoch 1419/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.8056 - val_loss: 0.5174 - val_accuracy: 0.7656\n",
            "Epoch 1420/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3888 - accuracy: 0.8038 - val_loss: 0.5178 - val_accuracy: 0.7656\n",
            "Epoch 1421/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.8090 - val_loss: 0.5181 - val_accuracy: 0.7604\n",
            "Epoch 1422/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3889 - accuracy: 0.8073 - val_loss: 0.5183 - val_accuracy: 0.7604\n",
            "Epoch 1423/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.8090 - val_loss: 0.5180 - val_accuracy: 0.7656\n",
            "Epoch 1424/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3890 - accuracy: 0.8056 - val_loss: 0.5175 - val_accuracy: 0.7656\n",
            "Epoch 1425/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3891 - accuracy: 0.8073 - val_loss: 0.5186 - val_accuracy: 0.7604\n",
            "Epoch 1426/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.8090 - val_loss: 0.5184 - val_accuracy: 0.7604\n",
            "Epoch 1427/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3889 - accuracy: 0.8038 - val_loss: 0.5178 - val_accuracy: 0.7604\n",
            "Epoch 1428/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3889 - accuracy: 0.8038 - val_loss: 0.5184 - val_accuracy: 0.7604\n",
            "Epoch 1429/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3889 - accuracy: 0.8056 - val_loss: 0.5184 - val_accuracy: 0.7604\n",
            "Epoch 1430/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3889 - accuracy: 0.8073 - val_loss: 0.5180 - val_accuracy: 0.7604\n",
            "Epoch 1431/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3890 - accuracy: 0.8056 - val_loss: 0.5176 - val_accuracy: 0.7656\n",
            "Epoch 1432/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3890 - accuracy: 0.8038 - val_loss: 0.5174 - val_accuracy: 0.7656\n",
            "Epoch 1433/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3888 - accuracy: 0.8056 - val_loss: 0.5180 - val_accuracy: 0.7604\n",
            "Epoch 1434/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3888 - accuracy: 0.8073 - val_loss: 0.5181 - val_accuracy: 0.7604\n",
            "Epoch 1435/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3888 - accuracy: 0.8073 - val_loss: 0.5180 - val_accuracy: 0.7604\n",
            "Epoch 1436/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3887 - accuracy: 0.8056 - val_loss: 0.5181 - val_accuracy: 0.7604\n",
            "Epoch 1437/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3890 - accuracy: 0.8090 - val_loss: 0.5180 - val_accuracy: 0.7604\n",
            "Epoch 1438/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3888 - accuracy: 0.8056 - val_loss: 0.5179 - val_accuracy: 0.7604\n",
            "Epoch 1439/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3888 - accuracy: 0.8073 - val_loss: 0.5179 - val_accuracy: 0.7604\n",
            "Epoch 1440/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3887 - accuracy: 0.8038 - val_loss: 0.5183 - val_accuracy: 0.7604\n",
            "Epoch 1441/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8038 - val_loss: 0.5180 - val_accuracy: 0.7604\n",
            "Epoch 1442/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3888 - accuracy: 0.8038 - val_loss: 0.5179 - val_accuracy: 0.7604\n",
            "Epoch 1443/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3886 - accuracy: 0.8073 - val_loss: 0.5181 - val_accuracy: 0.7604\n",
            "Epoch 1444/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8090 - val_loss: 0.5192 - val_accuracy: 0.7656\n",
            "Epoch 1445/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8038 - val_loss: 0.5182 - val_accuracy: 0.7604\n",
            "Epoch 1446/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3888 - accuracy: 0.8073 - val_loss: 0.5180 - val_accuracy: 0.7604\n",
            "Epoch 1447/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3884 - accuracy: 0.8073 - val_loss: 0.5181 - val_accuracy: 0.7604\n",
            "Epoch 1448/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8090 - val_loss: 0.5191 - val_accuracy: 0.7604\n",
            "Epoch 1449/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3884 - accuracy: 0.8056 - val_loss: 0.5183 - val_accuracy: 0.7604\n",
            "Epoch 1450/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3887 - accuracy: 0.8073 - val_loss: 0.5182 - val_accuracy: 0.7604\n",
            "Epoch 1451/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3885 - accuracy: 0.8073 - val_loss: 0.5183 - val_accuracy: 0.7604\n",
            "Epoch 1452/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3888 - accuracy: 0.8073 - val_loss: 0.5184 - val_accuracy: 0.7604\n",
            "Epoch 1453/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3883 - accuracy: 0.8056 - val_loss: 0.5184 - val_accuracy: 0.7604\n",
            "Epoch 1454/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8090 - val_loss: 0.5189 - val_accuracy: 0.7656\n",
            "Epoch 1455/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3884 - accuracy: 0.8073 - val_loss: 0.5182 - val_accuracy: 0.7604\n",
            "Epoch 1456/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3884 - accuracy: 0.8073 - val_loss: 0.5182 - val_accuracy: 0.7656\n",
            "Epoch 1457/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3884 - accuracy: 0.8073 - val_loss: 0.5186 - val_accuracy: 0.7656\n",
            "Epoch 1458/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3882 - accuracy: 0.8056 - val_loss: 0.5178 - val_accuracy: 0.7656\n",
            "Epoch 1459/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3883 - accuracy: 0.8073 - val_loss: 0.5176 - val_accuracy: 0.7656\n",
            "Epoch 1460/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3882 - accuracy: 0.8090 - val_loss: 0.5182 - val_accuracy: 0.7656\n",
            "Epoch 1461/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3886 - accuracy: 0.8038 - val_loss: 0.5179 - val_accuracy: 0.7656\n",
            "Epoch 1462/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3885 - accuracy: 0.8056 - val_loss: 0.5183 - val_accuracy: 0.7656\n",
            "Epoch 1463/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8073 - val_loss: 0.5187 - val_accuracy: 0.7656\n",
            "Epoch 1464/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3881 - accuracy: 0.8056 - val_loss: 0.5189 - val_accuracy: 0.7656\n",
            "Epoch 1465/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3880 - accuracy: 0.8056 - val_loss: 0.5190 - val_accuracy: 0.7656\n",
            "Epoch 1466/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3882 - accuracy: 0.8090 - val_loss: 0.5190 - val_accuracy: 0.7656\n",
            "Epoch 1467/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3881 - accuracy: 0.8073 - val_loss: 0.5184 - val_accuracy: 0.7656\n",
            "Epoch 1468/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3882 - accuracy: 0.8073 - val_loss: 0.5186 - val_accuracy: 0.7656\n",
            "Epoch 1469/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3885 - accuracy: 0.8038 - val_loss: 0.5190 - val_accuracy: 0.7656\n",
            "Epoch 1470/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3883 - accuracy: 0.8073 - val_loss: 0.5189 - val_accuracy: 0.7656\n",
            "Epoch 1471/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3882 - accuracy: 0.8038 - val_loss: 0.5184 - val_accuracy: 0.7708\n",
            "Epoch 1472/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3881 - accuracy: 0.8056 - val_loss: 0.5184 - val_accuracy: 0.7656\n",
            "Epoch 1473/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3885 - accuracy: 0.8056 - val_loss: 0.5181 - val_accuracy: 0.7656\n",
            "Epoch 1474/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3880 - accuracy: 0.8073 - val_loss: 0.5183 - val_accuracy: 0.7656\n",
            "Epoch 1475/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3880 - accuracy: 0.8038 - val_loss: 0.5187 - val_accuracy: 0.7708\n",
            "Epoch 1476/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3880 - accuracy: 0.8090 - val_loss: 0.5191 - val_accuracy: 0.7708\n",
            "Epoch 1477/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3880 - accuracy: 0.8073 - val_loss: 0.5191 - val_accuracy: 0.7708\n",
            "Epoch 1478/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3879 - accuracy: 0.8056 - val_loss: 0.5189 - val_accuracy: 0.7708\n",
            "Epoch 1479/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3878 - accuracy: 0.8038 - val_loss: 0.5197 - val_accuracy: 0.7708\n",
            "Epoch 1480/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3881 - accuracy: 0.8056 - val_loss: 0.5195 - val_accuracy: 0.7708\n",
            "Epoch 1481/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3882 - accuracy: 0.8056 - val_loss: 0.5197 - val_accuracy: 0.7708\n",
            "Epoch 1482/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3881 - accuracy: 0.8125 - val_loss: 0.5195 - val_accuracy: 0.7708\n",
            "Epoch 1483/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3877 - accuracy: 0.8090 - val_loss: 0.5199 - val_accuracy: 0.7708\n",
            "Epoch 1484/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3878 - accuracy: 0.8021 - val_loss: 0.5200 - val_accuracy: 0.7708\n",
            "Epoch 1485/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3881 - accuracy: 0.8073 - val_loss: 0.5195 - val_accuracy: 0.7708\n",
            "Epoch 1486/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3880 - accuracy: 0.8073 - val_loss: 0.5186 - val_accuracy: 0.7760\n",
            "Epoch 1487/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3879 - accuracy: 0.8090 - val_loss: 0.5189 - val_accuracy: 0.7760\n",
            "Epoch 1488/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3878 - accuracy: 0.8073 - val_loss: 0.5192 - val_accuracy: 0.7708\n",
            "Epoch 1489/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3876 - accuracy: 0.8056 - val_loss: 0.5194 - val_accuracy: 0.7760\n",
            "Epoch 1490/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3878 - accuracy: 0.8056 - val_loss: 0.5195 - val_accuracy: 0.7708\n",
            "Epoch 1491/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3876 - accuracy: 0.8073 - val_loss: 0.5201 - val_accuracy: 0.7708\n",
            "Epoch 1492/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3882 - accuracy: 0.8056 - val_loss: 0.5192 - val_accuracy: 0.7708\n",
            "Epoch 1493/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3878 - accuracy: 0.8073 - val_loss: 0.5194 - val_accuracy: 0.7708\n",
            "Epoch 1494/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3876 - accuracy: 0.8090 - val_loss: 0.5184 - val_accuracy: 0.7708\n",
            "Epoch 1495/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3876 - accuracy: 0.8056 - val_loss: 0.5190 - val_accuracy: 0.7760\n",
            "Epoch 1496/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3876 - accuracy: 0.8056 - val_loss: 0.5201 - val_accuracy: 0.7708\n",
            "Epoch 1497/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3875 - accuracy: 0.8073 - val_loss: 0.5197 - val_accuracy: 0.7760\n",
            "Epoch 1498/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3876 - accuracy: 0.8056 - val_loss: 0.5189 - val_accuracy: 0.7760\n",
            "Epoch 1499/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3875 - accuracy: 0.8073 - val_loss: 0.5199 - val_accuracy: 0.7760\n",
            "Epoch 1500/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3876 - accuracy: 0.8038 - val_loss: 0.5197 - val_accuracy: 0.7760\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Like we did for the Random Forest, we generate two kinds of predictions\n",
        "#  One is a hard decision, the other is a probabilitistic score.\n",
        "\n",
        "y_pred_prob_nn_2 = model_1.predict(X_test_norm)\n",
        "y_pred_class_nn_2 = (model_1.predict(X_test_norm) > 0.5).astype('int32')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2vhX8JdWWNW",
        "outputId": "f28e3930-a7e5-404c-ce28-48987161fb58"
      },
      "id": "Z2vhX8JdWWNW",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 6ms/step\n",
            "6/6 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's check out the outputs to get a feel for how keras apis work.\n",
        "y_pred_class_nn_2[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4s4IyRMWU8d",
        "outputId": "54e775da-757b-49d8-ac9f-d9d3bef52a19"
      },
      "id": "D4s4IyRMWU8d",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob_nn_2[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJVkSL9SWasP",
        "outputId": "dcf0b669-e339-445c-9d1d-8349583167e7"
      },
      "id": "kJVkSL9SWasP",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.57646066],\n",
              "       [0.9737168 ],\n",
              "       [0.43822086],\n",
              "       [0.15268312],\n",
              "       [0.25701326],\n",
              "       [0.46917868],\n",
              "       [0.00518095],\n",
              "       [0.29124966],\n",
              "       [0.95190877],\n",
              "       [0.09765764]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_hist_2.history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-SL0qiHWdnH",
        "outputId": "732108fe-c617-4662-e8a5-f0e314c14cf8"
      },
      "id": "F-SL0qiHWdnH",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Graph the trajectory of the loss functions, accuracy on both train and test set\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_2.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_2.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "WpspDhp9WfTq",
        "outputId": "ee01903c-515e-4316-808d-f791c3acd267"
      },
      "id": "WpspDhp9WfTq",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f46670b5e10>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the roc curve for the predictions\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
        "plot_roc(y_test, y_pred_prob_nn_2, 'NN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "6hYxXVUkWmYa",
        "outputId": "2522152e-1c47-4ee8-d2df-299f759f2492"
      },
      "id": "6hYxXVUkWmYa",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.776\n",
            "roc-auc is 0.816\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation: As seen on the first graph above, both of the train and test sets descents similarly at the first 100 epochs but both went different ways after. The curve of the validation test indicates that the model is starting to overfit after approximately 100 epochs and not generalizing well to new data. For the accuracy and the ROC-AUC, it indicates that the model is having an acceptable performance with an accuracy of 77.6% and an ROC-AUC of 0.816 indicates that the model is effective in distinguishing people with diabetes and those without."
      ],
      "metadata": {
        "id": "Rq43trgYXf8a"
      },
      "id": "Rq43trgYXf8a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using different learning rates, number of epochs, and network structures."
      ],
      "metadata": {
        "id": "Da1J4lkKbrsG"
      },
      "id": "Da1J4lkKbrsG"
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = Sequential([\n",
        "    Dense(10, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(15, activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "5kzvGPdZb246"
      },
      "id": "5kzvGPdZb246",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNSdc3Peb6Fl",
        "outputId": "9e48665f-5de3-400c-f96f-e70cdbb92e15"
      },
      "id": "NNSdc3Peb6Fl",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_11 (Dense)            (None, 10)                90        \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 15)                165       \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 16        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 271 (1.06 KB)\n",
            "Trainable params: 271 (1.06 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "e_s = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "qpAnSyiSb9RJ"
      },
      "id": "qpAnSyiSb9RJ",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation: I used early stopping to prevent overfitting and ensure that the training and validation losses do not diverge significantly. By monitoring the validation loss during training and stopping the training process when the validation loss stops improving or starts deteriorating, early stopping helps to achieve a model that generalizes well to unseen data. This regularization technique enhances the model's ability to learn general patterns in the data while avoiding the memorization of noise in the training data."
      ],
      "metadata": {
        "id": "I-LqchGcb-zy"
      },
      "id": "I-LqchGcb-zy"
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_3 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200, callbacks=[e_s])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qA250954cCGT",
        "outputId": "cd00df25-fd20-4fcc-a798-4fd4ba1b8850"
      },
      "id": "qA250954cCGT",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "18/18 [==============================] - 1s 22ms/step - loss: 0.7008 - accuracy: 0.4774 - val_loss: 0.7054 - val_accuracy: 0.5260\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6836 - accuracy: 0.5625 - val_loss: 0.6924 - val_accuracy: 0.5781\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6689 - accuracy: 0.6215 - val_loss: 0.6808 - val_accuracy: 0.6198\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6561 - accuracy: 0.6701 - val_loss: 0.6705 - val_accuracy: 0.6510\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6445 - accuracy: 0.6858 - val_loss: 0.6610 - val_accuracy: 0.6562\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6338 - accuracy: 0.6979 - val_loss: 0.6521 - val_accuracy: 0.6562\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6240 - accuracy: 0.6997 - val_loss: 0.6438 - val_accuracy: 0.6615\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6148 - accuracy: 0.7066 - val_loss: 0.6361 - val_accuracy: 0.6562\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6062 - accuracy: 0.7049 - val_loss: 0.6288 - val_accuracy: 0.6510\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5979 - accuracy: 0.7118 - val_loss: 0.6217 - val_accuracy: 0.6562\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5901 - accuracy: 0.7049 - val_loss: 0.6149 - val_accuracy: 0.6667\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5826 - accuracy: 0.7101 - val_loss: 0.6084 - val_accuracy: 0.6771\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5755 - accuracy: 0.7135 - val_loss: 0.6021 - val_accuracy: 0.6823\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5686 - accuracy: 0.7118 - val_loss: 0.5959 - val_accuracy: 0.6823\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5620 - accuracy: 0.7135 - val_loss: 0.5899 - val_accuracy: 0.6823\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5556 - accuracy: 0.7188 - val_loss: 0.5842 - val_accuracy: 0.6875\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5494 - accuracy: 0.7205 - val_loss: 0.5786 - val_accuracy: 0.6875\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5435 - accuracy: 0.7240 - val_loss: 0.5733 - val_accuracy: 0.6823\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5380 - accuracy: 0.7292 - val_loss: 0.5682 - val_accuracy: 0.6875\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5327 - accuracy: 0.7292 - val_loss: 0.5634 - val_accuracy: 0.7031\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5277 - accuracy: 0.7309 - val_loss: 0.5588 - val_accuracy: 0.7031\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5231 - accuracy: 0.7292 - val_loss: 0.5545 - val_accuracy: 0.7188\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5186 - accuracy: 0.7257 - val_loss: 0.5503 - val_accuracy: 0.7188\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5144 - accuracy: 0.7240 - val_loss: 0.5464 - val_accuracy: 0.7240\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5102 - accuracy: 0.7309 - val_loss: 0.5427 - val_accuracy: 0.7240\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5064 - accuracy: 0.7344 - val_loss: 0.5393 - val_accuracy: 0.7188\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5028 - accuracy: 0.7326 - val_loss: 0.5360 - val_accuracy: 0.7135\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4993 - accuracy: 0.7413 - val_loss: 0.5330 - val_accuracy: 0.7188\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4960 - accuracy: 0.7448 - val_loss: 0.5301 - val_accuracy: 0.7292\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4930 - accuracy: 0.7535 - val_loss: 0.5274 - val_accuracy: 0.7292\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4901 - accuracy: 0.7587 - val_loss: 0.5249 - val_accuracy: 0.7292\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4875 - accuracy: 0.7604 - val_loss: 0.5225 - val_accuracy: 0.7396\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4850 - accuracy: 0.7656 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4827 - accuracy: 0.7674 - val_loss: 0.5181 - val_accuracy: 0.7552\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4804 - accuracy: 0.7708 - val_loss: 0.5162 - val_accuracy: 0.7500\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4784 - accuracy: 0.7691 - val_loss: 0.5144 - val_accuracy: 0.7448\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4764 - accuracy: 0.7708 - val_loss: 0.5127 - val_accuracy: 0.7448\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4745 - accuracy: 0.7743 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4727 - accuracy: 0.7778 - val_loss: 0.5097 - val_accuracy: 0.7604\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4710 - accuracy: 0.7778 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7830 - val_loss: 0.5073 - val_accuracy: 0.7604\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4681 - accuracy: 0.7812 - val_loss: 0.5062 - val_accuracy: 0.7656\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4666 - accuracy: 0.7830 - val_loss: 0.5054 - val_accuracy: 0.7604\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7830 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7830 - val_loss: 0.5032 - val_accuracy: 0.7604\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7830 - val_loss: 0.5026 - val_accuracy: 0.7552\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7812 - val_loss: 0.5016 - val_accuracy: 0.7604\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7795 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7812 - val_loss: 0.5007 - val_accuracy: 0.7604\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7604\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7847 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7865 - val_loss: 0.4997 - val_accuracy: 0.7552\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7865 - val_loss: 0.4995 - val_accuracy: 0.7552\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.7865 - val_loss: 0.4993 - val_accuracy: 0.7552\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.7882 - val_loss: 0.4992 - val_accuracy: 0.7552\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.7917 - val_loss: 0.4991 - val_accuracy: 0.7552\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.7951 - val_loss: 0.4990 - val_accuracy: 0.7604\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7951 - val_loss: 0.4989 - val_accuracy: 0.7604\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7951 - val_loss: 0.4988 - val_accuracy: 0.7604\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7951 - val_loss: 0.4988 - val_accuracy: 0.7604\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.7951 - val_loss: 0.4987 - val_accuracy: 0.7604\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7951 - val_loss: 0.4986 - val_accuracy: 0.7656\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.7951 - val_loss: 0.4986 - val_accuracy: 0.7656\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7951 - val_loss: 0.4986 - val_accuracy: 0.7656\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7951 - val_loss: 0.4986 - val_accuracy: 0.7656\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4485 - accuracy: 0.7951 - val_loss: 0.4985 - val_accuracy: 0.7656\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7951 - val_loss: 0.4986 - val_accuracy: 0.7656\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7951 - val_loss: 0.4986 - val_accuracy: 0.7656\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7951 - val_loss: 0.4987 - val_accuracy: 0.7656\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7951 - val_loss: 0.4987 - val_accuracy: 0.7656\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7934 - val_loss: 0.4988 - val_accuracy: 0.7656\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7986 - val_loss: 0.4988 - val_accuracy: 0.7656\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7986 - val_loss: 0.4988 - val_accuracy: 0.7656\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7969 - val_loss: 0.4988 - val_accuracy: 0.7656\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7969 - val_loss: 0.4989 - val_accuracy: 0.7656\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7969 - val_loss: 0.4989 - val_accuracy: 0.7656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation: Due to EarlyStopping, the training is terminated at 78 epochs since there is no more improvement in the validation loss."
      ],
      "metadata": {
        "id": "o7PTON0TflTc"
      },
      "id": "o7PTON0TflTc"
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob_nn_3 = model_2.predict(X_test_norm)\n",
        "y_pred_class_nn_3 = (model_2.predict(X_test_norm) > 0.5).astype('int32')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSgWuLl5cR4q",
        "outputId": "0667067e-54c7-44ab-ea7c-7acfd48f4495"
      },
      "id": "zSgWuLl5cR4q",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 2ms/step\n",
            "6/6 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_class_nn_3[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9OctiOOcbWK",
        "outputId": "7b24b6a7-e739-4079-de58-fce87ef7bdc2"
      },
      "id": "m9OctiOOcbWK",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob_nn_3[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ul3xVbfHccjC",
        "outputId": "616751e9-5e60-4c27-d020-f41599cde959"
      },
      "id": "Ul3xVbfHccjC",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.6669828 ],\n",
              "       [0.6361151 ],\n",
              "       [0.42134437],\n",
              "       [0.32733962],\n",
              "       [0.1880226 ],\n",
              "       [0.5743976 ],\n",
              "       [0.03201353],\n",
              "       [0.34402087],\n",
              "       [0.7677489 ],\n",
              "       [0.12922247]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_hist_3.history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jH-N1X9ceaj",
        "outputId": "4a1b28ca-07a5-4e18-e8e3-9d77f6f99222"
      },
      "id": "6jH-N1X9ceaj",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_3.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_3.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "ZLkNe0Y5cf0V",
        "outputId": "2ab0e358-6af9-474e-d454-10954e78b39b"
      },
      "id": "ZLkNe0Y5cf0V",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f4666fbcf40>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_3)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_3)))\n",
        "plot_roc(y_test, y_pred_prob_nn_3, 'NN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "LTO_Et6gckOQ",
        "outputId": "6b3f3591-cba0-4659-a482-48454ce79309"
      },
      "id": "LTO_Et6gckOQ",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.766\n",
            "roc-auc is 0.821\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation: As seen on the first graph, it is much more acceptable compared to the first one, as both of the curves descent similarly and with less gap in between indicating that the model is learning well without overfitting. As for the accuracy and roc curve, the accuracy of 76.6% indicates that the model is performing similarly with the first training (77.6% accuracy) but is notably better than the second training. The ROC-AUC of 0.821 is also similar to the first training which indicates that the second model is also effective at distinguishing between people that has diabetes and those without.\n",
        "\n"
      ],
      "metadata": {
        "id": "sHQ7CEIAcnJ0"
      },
      "id": "sHQ7CEIAcnJ0"
    },
    {
      "cell_type": "markdown",
      "id": "intimate-factory",
      "metadata": {
        "id": "intimate-factory"
      },
      "source": [
        "#Conclusion\n",
        "\n",
        "- After performing this activity, I conclude that the second neural network model trained with an architecture comprising two hidden layers of 10 and 15 nodes, respectively, along with early stopping applied, yielded a slightly lower accuracy compared to the first model. Specifically, the second model achieved an accuracy of 0.766, while the first model achieved an accuracy of 0.776. Although the difference in accuracy between the two models is relatively small (0.01), it suggests a minor decline in performance in the second model. Additionally, the ROC-AUC score for the second model was 0.821, indicating its good discrimination ability between positive and negative classes. While this metric provides valuable insight into the model's classification performance, it's essential to note that accuracy is a more direct measure of correct classification. Overall, while the second model exhibited slightly inferior accuracy compared to the first model, its performance, as indicated by the ROC-AUC score, remained robust. Further analysis may be warranted to understand the factors contributing to the discrepancy in accuracy and to assess the practical significance of the observed difference in performance."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}